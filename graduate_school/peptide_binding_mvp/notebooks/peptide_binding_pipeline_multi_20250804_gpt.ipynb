{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9073b5d5",
   "metadata": {},
   "source": [
    "# ğŸ§¬ ë‹¤ì¤‘ í©íƒ€ì´ë“œ í›„ë³´ ê¸°ë°˜ ë‹¨ë°±ì§ˆ ê²°í•©ë ¥ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸\n",
    "Multi Peptideâ€“Protein Binding Prediction Pipeline\n",
    "\n",
    "ProtGPT2ë¡œ ì—¬ëŸ¬ í©íƒ€ì´ë“œ í›„ë³´ë¥¼ ìƒì„±í•˜ê³ , ê° í›„ë³´ì— ëŒ€í•´ êµ¬ì¡° ì˜ˆì¸¡, ë„í‚¹, ìƒí˜¸ì‘ìš© ë¶„ì„ ë° ê²°í•©ë ¥ ì˜ˆì¸¡(Pafnucy)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ProtGPT2 í©íƒ€ì´ë“œ ìƒì„± â†’ ë³µí•©ì²´ FASTA ìƒì„± â†’ êµ¬ì¡° ì˜ˆì¸¡(ColabFold) â†’ ë„í‚¹/PLIP/Pafnucy ê²°í•©ë ¥ í‰ê°€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16333f63",
   "metadata": {},
   "source": [
    "## 0. Google Drive ë§ˆìš´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c32314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "work_dir = \"/content/drive/MyDrive/peptide_docking_pipeline_multi\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "print(f\"Working directory: {work_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c2ccc0",
   "metadata": {},
   "source": [
    "## 1. ProtGPT2ë¡œ í©íƒ€ì´ë“œ í›„ë³´ ë‹¤ì¤‘ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentencepiece\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nferruz/ProtGPT2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"nferruz/ProtGPT2\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "N = 5  # ìƒì„±í•  í›„ë³´ ìˆ˜ (í•„ìš”ì‹œ ë³€ê²½)\n",
    "peptides = []\n",
    "\n",
    "for _ in range(N):\n",
    "    input_ids = tokenizer(\"generate:\", return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    output = model.generate(input_ids, max_length=30, num_return_sequences=1, do_sample=True, top_k=950, top_p=0.96)\n",
    "    sequence = tokenizer.decode(output[0], skip_special_tokens=True).replace(\"generate:\", \"\").strip()\n",
    "    peptides.append(sequence)\n",
    "\n",
    "# í©íƒ€ì´ë“œ FASTA íŒŒì¼ ì €ì¥\n",
    "for i, pep in enumerate(peptides):\n",
    "    with open(f\"peptide_{i}.fasta\", \"w\") as f:\n",
    "        f.write(f\">pep{i}\\n{pep}\\n\")\n",
    "\n",
    "print(\"âœ… ìƒì„±ëœ í©íƒ€ì´ë“œ í›„ë³´:\")\n",
    "for i, seq in enumerate(peptides):\n",
    "    print(f\"[{i}] {seq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580523f8",
   "metadata": {},
   "source": [
    "## 2. ë‹¨ë°±ì§ˆ ì„œì—´ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c574531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ìê°€ ë‹¨ë°±ì§ˆ ì„œì—´ì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "protein_sequence = \"MTMKQLNDLENRLLGFLGNTILADATKSTQAKLEKELLGTTFGAEA\"\n",
    "with open(\"protein.fasta\", \"w\") as f:\n",
    "    f.write(\">protein\\n\" + protein_sequence)\n",
    "\n",
    "print(\"âœ… ë‹¨ë°±ì§ˆ ì„œì—´ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c213d8",
   "metadata": {},
   "source": [
    "## 3. êµ¬ì¡° ì˜ˆì¸¡ (ColabFold/AlphaFold-Multimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ab938",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_files = []\n",
    "pred_dirs = []\n",
    "\n",
    "for i in range(N):\n",
    "    fname = f\"complex_{i}.fasta\"\n",
    "    with open(fname, \"w\") as out, open(\"protein.fasta\") as pro, open(f\"peptide_{i}.fasta\") as pep:\n",
    "        out.writelines(pro.readlines())\n",
    "        out.writelines(pep.readlines())\n",
    "    merged_files.append(fname)\n",
    "    pred_dirs.append(f\"prediction_complex_{i}\")\n",
    "\n",
    "print(\"âœ… ë³µí•©ì²´ FASTA íŒŒì¼ ë° ì˜ˆì¸¡ í´ë” ì¤€ë¹„:\")\n",
    "for f, d in zip(merged_files, pred_dirs):\n",
    "    print(f\"- {f} â†’ {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe618c",
   "metadata": {},
   "source": [
    "## 4. êµ¬ì¡° ì˜ˆì¸¡ ê²°ê³¼ ì¤€ë¹„ ë° í‰ê°€ìš© ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import colabfold\n",
    "except ImportError:\n",
    "    !pip install -q colabfold\n",
    "\n",
    "for fasta_file, out_dir in zip(merged_files, pred_dirs):\n",
    "    print(f\"Running colabfold_batch for {fasta_file} â†’ {out_dir}\")\n",
    "    !colabfold_batch {fasta_file} {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaefbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pdb_paths = []\n",
    "for i, pred_dir in enumerate(pred_dirs):\n",
    "    pdb_file = f\"{pred_dir}/complex_{i}_0.pdb\"\n",
    "    if os.path.exists(pdb_file):\n",
    "        print(f\"[{i}] êµ¬ì¡° ì˜ˆì¸¡ ì™„ë£Œ: {pdb_file}\")\n",
    "        pdb_paths.append(pdb_file)\n",
    "    else:\n",
    "        print(f\"[{i}] âŒ ì˜ˆì¸¡ ì‹¤íŒ¨ ë˜ëŠ” ëˆ„ë½: {pdb_file}\")\n",
    "\n",
    "if len(pdb_paths) == 0:\n",
    "    raise RuntimeError(\"â›” ì˜ˆì¸¡ëœ êµ¬ì¡° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! ColabFold ì˜ˆì¸¡ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e765395",
   "metadata": {},
   "source": [
    "## 5. ë„í‚¹, PLIP, Pafnucyë¥¼ í†µí•œ ê²°í•©ë ¥ í‰ê°€ ë° ì ìˆ˜ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efded5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y openbabel\n",
    "!pip install -q plip\n",
    "!git clone https://github.com/oddt/pafnucy.git\n",
    "%cd pafnucy\n",
    "!pip install -q -r requirements.txt\n",
    "%cd ..\n",
    "\n",
    "from plip.structure.preparation import PDBComplex\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, pred_pdb in enumerate(pdb_paths):\n",
    "    os.system(f\"obabel {pred_pdb} -O receptor_{i}.pdbqt\")\n",
    "    os.system(f\"cp receptor_{i}.pdbqt ligand_{i}.pdbqt\")\n",
    "\n",
    "    # AutoDock Vina ì„¤ì¹˜ ë° ì‹¤í–‰\n",
    "    if not os.path.exists(\"vina_1.2.3_linux_x86_64/vina\"):\n",
    "        !wget -q https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip\n",
    "        !unzip -q vina_1.2.3_linux_x86_64.zip\n",
    "        !chmod +x vina_1.2.3_linux_x86_64/vina\n",
    "\n",
    "    vina_cmd = f\"./vina_1.2.3_linux_x86_64/vina --receptor receptor_{i}.pdbqt --ligand ligand_{i}.pdbqt --center_x 0 --center_y 0 --center_z 0 --size_x 20 --size_y 20 --size_z 20 --out output_{i}.pdbqt --log log_{i}.txt\"\n",
    "    os.system(vina_cmd)\n",
    "\n",
    "    vina_score = None\n",
    "    with open(f\"log_{i}.txt\") as f:\n",
    "        for line in f:\n",
    "            if \"REMARK VINA RESULT\" in line:\n",
    "                vina_score = float(line.strip().split()[3])\n",
    "                break\n",
    "\n",
    "    # PLIP ìƒí˜¸ì‘ìš© ë¶„ì„\n",
    "    structure = PDBComplex()\n",
    "    structure.load_pdb(f\"output_{i}.pdbqt\")\n",
    "    structure.analyze()\n",
    "    interaction_count = 0\n",
    "    for ligand in structure.ligands:\n",
    "        inter = structure.interaction_sets[ligand]\n",
    "        interaction_count += len(inter.hbonds) + len(inter.hydrophobic_contacts) + len(inter.saltbridge_ligands)\n",
    "\n",
    "    # Pafnucy í‰ê°€\n",
    "    os.system(f\"obabel output_{i}.pdbqt -O complex_final_{i}.pdb\")\n",
    "    os.system(f\"python pafnucy/predict.py --pdb complex_final_{i}.pdb --out affinity_{i}.csv\")\n",
    "    pafnucy_df = pd.read_csv(f\"affinity_{i}.csv\")\n",
    "    pafnucy_affinity = float(pafnucy_df['predicted_affinity'].iloc[0])\n",
    "\n",
    "    final_score = (-1 * vina_score) + (-1 * pafnucy_affinity) + (0.5 * interaction_count)\n",
    "    results.append({\n",
    "        \"index\": i,\n",
    "        \"peptide\": peptides[i],\n",
    "        \"vina_score\": vina_score,\n",
    "        \"pafnucy\": pafnucy_affinity,\n",
    "        \"interaction\": interaction_count,\n",
    "        \"final_score\": final_score\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df_sorted = df.sort_values(\"final_score\", ascending=False)\n",
    "df_sorted.to_csv(\"peptide_binding_rank.csv\", index=False)\n",
    "print(\"âœ… ë­í‚¹ ê²°ê³¼ (ìƒìœ„ 5ê°œ):\")\n",
    "display(df_sorted.head())\n",
    "\n",
    "print(\"ì „ì²´ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: peptide_binding_rank.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
