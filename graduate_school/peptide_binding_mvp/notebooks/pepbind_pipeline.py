#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
pepbind_pipeline.py - WSL/ì˜¤í”„ë¼ì¸ í™˜ê²½ìš© í†µí•© íŒŒì´í”„ë¼ì¸ (ì •ë¦¬ ë²„ì „)

êµ¬ì„±:
- STEP 2: PepMLM(ESM-2)ë¡œ í©íƒ€ì´ë“œ í›„ë³´ ìƒì„± (GPU ì‚¬ìš©)
- STEP 3: ColabFold ë©€í‹°ë¨¸ë¡œ íƒ€ê¹ƒ-í©íƒ€ì´ë“œ ë³µí•©ì²´ êµ¬ì¡° ì˜ˆì¸¡ (ì§„í–‰ ìƒí™© í‘œì‹œ)
- STEP 4: AutoDock Vina ë„í‚¹ (CPU, stdout íŒŒì‹±)
- STEP 5: PLIP ìƒí˜¸ì‘ìš© ë¶„ì„
- STEP 6: PRODIGY ê²°í•© ììœ ì—ë„ˆì§€ í‰ê°€
- STEP 7: ìµœì¢… í‰ê°€(Aì•ˆ ê°€ì¤‘ì¹˜) + ì—‘ì…€ íŒŒì¼ ìƒì„± + rank_001 PDB zip ì••ì¶•

Aì•ˆ ê°€ì¤‘ì¹˜:
  PRODIGY 0.35
  Vina    0.20
  PLIP    0.25
  ipTM    0.20
"""

import os
import time
import csv
import re
import json
import zipfile
import shutil
import subprocess
from pathlib import Path
from datetime import datetime

import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForMaskedLM
from Bio.PDB import PDBParser, PDBIO, Select
from openpyxl import Workbook
import pandas as pd

import xml.etree.ElementTree as ET

START_TIME = datetime.now()

# =====================================================================
# === ì‚¬ìš©ì ì„¤ì • ì˜ì—­: ì—¬ê¸°ë§Œ ìˆ˜ì •í•´ì„œ ì‚¬ìš© ==========================
# =====================================================================

# 1) íƒ€ê¹ƒ ë‹¨ë°±ì§ˆ ì„œì—´ (FASTAì˜ sequence ë¶€ë¶„ë§Œ)
TARGET_SEQUENCE = (
    "AFTVTVPKDLYVVEYGSNMTIECKFPVEKQLDLAALIVYWEMEDKNIIQFVHGEEDLKVQHSSYRQRARLLKDQLSLGNAALQITDVKLQDAGVYRCMISYGGADYKRITVKVNAPYNKINQRILVVDPVTSEHELTCQAEGYPKAEVIWTSSDHQVLSGKTTTTNSKREEKLFNVTSTLRINTTTNEIFYCTFRRLDPEENHTAELVIPELPLAHPPNERT" # PD-L1 ë‹¨ë°±ì§ˆ ì„œì—´
)

# 2) ìƒì„±í•  í©íƒ€ì´ë“œ ì„¤ì •
NUM_PEPTIDES   = 10   # ìƒì„±í•  í©íƒ€ì´ë“œ í›„ë³´ ê°œìˆ˜
PEPTIDE_LENGTH = 4    # ê° í©íƒ€ì´ë“œ ê¸¸ì´ (ì•„ë¯¸ë…¸ì‚° ê°œìˆ˜)

# 3) ColabFold / í‰ê°€ ë‹¨ê³„ ì‚¬ìš© ì—¬ë¶€
RUN_COLABFOLD  = True   # ColabFold êµ¬ì¡° ì˜ˆì¸¡ ì‹¤í–‰ ì—¬ë¶€
RUN_VINA       = True   # AutoDock Vina ë„í‚¹ ì‹¤í–‰ ì—¬ë¶€
RUN_PLIP       = True   # PLIP ìƒí˜¸ì‘ìš© ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€
RUN_PRODIGY    = True   # PRODIGY ê²°í•© ì¹œí™”ë„ í‰ê°€ ì‹¤í–‰ ì—¬ë¶€

# 4) ì‘ì—… ê¸°ë³¸ ë””ë ‰í† ë¦¬
BASE_DIR = Path(os.environ.get("PEPBIND_BASE_DIR", "~/work/pipeline")).expanduser()

# 5) ì™¸ë¶€ ë„êµ¬ ê²½ë¡œ (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)
COLABFOLD_CMD   = os.environ.get("COLABFOLD_CMD", "colabfold_batch").strip()
VINA_CMD        = os.environ.get("VINA_CMD", "vina").strip()
PLIP_CMD        = os.environ.get("PLIP_CMD", "plip").strip()          # ê¸°ë³¸ê°’ë„ plipìœ¼ë¡œ
PRODIGY_SCRIPT  = os.environ.get("PRODIGY_SCRIPT", "prodigy").strip()


# =====================================================================
# === ê³µí†µ ì„¤ì • / ìœ í‹¸ =================================================
# =====================================================================

BASE_DIR.mkdir(parents=True, exist_ok=True)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"[INFO] PyTorch device: {DEVICE}")


def run(cmd, cwd=None):
    """ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ë˜í¼ (ê°„ë‹¨ ë²„ì „)."""
    print(f"[RUN] {cmd}")
    result = subprocess.run(
        cmd,
        cwd=cwd,
        shell=isinstance(cmd, str),
    )
    if result.returncode != 0:
        raise RuntimeError(f"Command failed (code={result.returncode}): {cmd}")
    return result


def timestamp():
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def init_workspace():
    """PDP_YYYYMMDD_HHMMSS í˜•íƒœ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë° í•˜ìœ„ í´ë” ìƒì„±."""
    ws_name = f"PDP_{timestamp()}"
    ws_root = BASE_DIR / ws_name

    folders = {
        "root": ws_root,
        "fasta": ws_root / "fasta",
        "pdb": ws_root / "pdb",
        "colabfold_out": ws_root / "pdb" / "colabfold_output",
        "results": ws_root / "results",
        "vina": ws_root / "results" / "vina",
        "plip": ws_root / "results" / "plip",
        "prodigy": ws_root / "results" / "prodigy",
        "temp": ws_root / "temp",
    }
    for d in folders.values():
        d.mkdir(parents=True, exist_ok=True)

    print("\n" + "=" * 80)
    print("STEP 1: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ / í´ë” êµ¬ì¡° ìƒì„±")
    print("=" * 80)
    for k, v in folders.items():
        print(f"âœ”ï¸ {k:12s}: {v}")
    print("=" * 80)

    return folders


def parse_prodigy_dg_from_stdout(stdout: str):
    """
    PRODIGY stdoutì—ì„œ Î”G(ë˜ëŠ” binding energy)ë¥¼ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜.
    í˜•ì‹ ì˜ˆì‹œ:
      Binding energy: -12.3 kcal/mol
      Predicted Î”G: -10.5 kcal/mol

    ì—¬ëŸ¬ ì¤„ ì¤‘ ì²« ë²ˆì§¸ ë§¤ì¹­ê°’ë§Œ ì‚¬ìš©.
    ì‹¤íŒ¨í•˜ë©´ None ë¦¬í„´.
    """
    if not stdout:
        return None

    # 1) ê°€ì¥ ìì£¼ ë‚˜ì˜¤ëŠ” íŒ¨í„´ë“¤ ìš°ì„  ì‹œë„
    patterns = [
        r"Binding energy\s*[:=]\s*([\-+]?\d+(?:\.\d+)?)",   # Binding energy: -12.3
        r"Predicted\s*Î”?G\s*[:=]\s*([\-+]?\d+(?:\.\d+)?)",  # Predicted Î”G: -10.5
        r"\bÎ”G\s*[:=]\s*([\-+]?\d+(?:\.\d+)?)",             # Î”G: -9.87
    ]

    for pat in patterns:
        m = re.search(pat, stdout, re.IGNORECASE)
        if m:
            try:
                return float(m.group(1))
            except ValueError:
                pass

    # 2) ë°±ì—…: stdout ì „ì²´ì—ì„œ "ì†Œìˆ˜ì ì´ ìˆëŠ” ì²« ë²ˆì§¸ ì‹¤ìˆ˜"
    m = re.search(r"([\-+]?\d+\.\d+)", stdout)
    if m:
        try:
            return float(m.group(1))
        except ValueError:
            return None

    return None


# =====================================================================
# === STEP 2: PepMLM (ESM-2) ê¸°ë°˜ í©íƒ€ì´ë“œ ìƒì„± =======================
# =====================================================================

def load_esm_mlm(model_name: str = "facebook/esm2_t12_35M_UR50D"):
    print("\n" + "=" * 80)
    print("STEP 2: PepMLM (ESM-2) ëª¨ë¸ ë¡œë”©")
    print("=" * 80)
    print(f"ëª¨ë¸ ë¡œë”©: {model_name}")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForMaskedLM.from_pretrained(model_name).to(DEVICE)
    model.eval()
    print("âœ… PepMLM ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    return tokenizer, model


def generate_peptides_with_mlm(
    tokenizer,
    model,
    target_sequence: str,
    num_peptides: int = NUM_PEPTIDES,
    peptide_len: int = PEPTIDE_LENGTH,
    top_k: int = 10,
    temperature: float = 1.0,
):
    """
    PepMLM(ESM-2) ê¸°ë°˜ í©íƒ€ì´ë“œ ìƒì„± (ìƒ˜í”Œë§ ë²„ì „)

    - "[PEP] [MASK] [MASK] ..." í˜•íƒœë¡œ ì…ë ¥
    - ê° MASK ìœ„ì¹˜ì—ì„œ top-k í™•ë¥  ë¶„í¬ì—ì„œ ëœë¤ ìƒ˜í”Œë§
    - special token (PAD, CLS, SEP, MASK, UNK)ëŠ” ì œì™¸
    - ë§ˆì§€ë§‰ peptide_len ê¸€ìë¥¼ í©íƒ€ì´ë“œë¡œ ì‚¬ìš©
    """
    print("\ní©íƒ€ì´ë“œ ì„œì—´ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    mask_token = tokenizer.mask_token
    if mask_token is None:
        raise ValueError("í† í¬ë‚˜ì´ì €ì— [MASK] í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ì œì™¸í•  í† í° ì•„ì´ë””ë“¤
    bad_ids = set()
    for tid in [
        tokenizer.pad_token_id,
        getattr(tokenizer, "cls_token_id", None),
        getattr(tokenizer, "sep_token_id", None),
        tokenizer.mask_token_id,
        getattr(tokenizer, "unk_token_id", None),
    ]:
        if tid is not None:
            bad_ids.add(tid)

    prompt = "[PEP] " + " ".join([mask_token] * peptide_len)
    input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(DEVICE)

    peptides = []
    seen = set()

    with torch.no_grad():
        attempt = 0
        while len(peptides) < num_peptides and attempt < num_peptides * 5:
            attempt += 1
            ids = input_ids.clone()

            for pos in range(ids.size(1)):
                if ids[0, pos].item() == tokenizer.mask_token_id:
                    outputs = model(ids)
                    logits = outputs.logits[0, pos] / temperature
                    probs = F.softmax(logits, dim=-1)

                    for bid in bad_ids:
                        probs[bid] = 0.0

                    probs = probs / probs.sum()

                    k = min(top_k, probs.size(0))
                    top_vals, top_idx = torch.topk(probs, k=k)
                    top_vals = top_vals / top_vals.sum()
                    sampled_local = torch.multinomial(top_vals, num_samples=1)
                    sampled_id = top_idx[sampled_local]
                    ids[0, pos] = sampled_id

            seq = tokenizer.decode(ids[0], skip_special_tokens=True).replace(" ", "")
            pep = seq[-peptide_len:]

            if len(pep) != peptide_len:
                continue
            if pep in seen:
                continue

            seen.add(pep)
            peptides.append(pep)
            print(f"  [{len(peptides)}/{num_peptides}] ìƒì„± ì™„ë£Œ: {pep} (ê¸¸ì´: {len(pep)})")

    print("\n--- ìƒì„±ëœ í©íƒ€ì´ë“œ í›„ë³´ ëª©ë¡ ---")
    for i, p in enumerate(peptides, 1):
        print(f"  - í›„ë³´ {i}: {p}")
    print("=" * 80)
    print(f"âœ… STEP 2: ì´ {len(peptides)}ê°œ í©íƒ€ì´ë“œ í›„ë³´ ìƒì„± ì™„ë£Œ")
    print("=" * 80)
    return peptides


def write_target_fasta(fasta_dir: Path, target_sequence: str) -> Path:
    fasta_path = fasta_dir / "target_protein.fasta"
    with open(fasta_path, "w") as f:
        f.write(">target_protein\n")
        f.write(target_sequence.strip() + "\n")
    return fasta_path


def write_peptide_fasta(fasta_dir: Path, peptides) -> Path:
    pep_fa = fasta_dir / "peptides.fasta"
    with open(pep_fa, "w") as f:
        for i, pep in enumerate(peptides):
            f.write(f">pep_{i}\n{pep}\n")
    return pep_fa


# =====================================================================
# === STEP 3: ColabFold ë°°ì¹˜ (ë©€í‹°ë¨¸) ================================
# =====================================================================

def prepare_colabfold_batch_csv(temp_dir: Path, target_sequence: str, peptides) -> Path:
    """
    ColabFold 1.5.5ìš© multimer CSV ì…ë ¥ ìƒì„±.

    - CSV ì»¬ëŸ¼: id, sequence
    - sequence í˜•ì‹: "íƒ€ê¹ƒì„œì—´:í©íƒ€ì´ë“œì„œì—´"
      ì˜ˆ) AAAAA...AAAA:PPPP
    """
    csv_path = temp_dir / "batch_complexes.csv"
    with open(csv_path, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["id", "sequence"])
        for i, pep in enumerate(peptides):
            complex_id = f"complex_{i}"
            complex_seq = f"{target_sequence}:{pep}"
            writer.writerow([complex_id, complex_seq])
    print(f"âœ… ColabFold ë°°ì¹˜ CSV ìƒì„± (id,sequence í˜•ì‹): {csv_path}")
    return csv_path


def run_colabfold_batch_with_progress(csv_path: Path, out_dir: Path, total_complexes: int):
    """
    colabfold_batch ì‹¤í–‰ + ì§„í–‰ ìƒí™© ì¶œë ¥:
    - rank_001*.pdb ê°œìˆ˜ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì„¸ì–´
    - "ì™„ë£Œëœ êµ¬ì¡° ê°œìˆ˜ / ì „ì²´ ë³µí•©ì²´ ê°œìˆ˜" í˜•íƒœë¡œ ì¶œë ¥
    """
    out_dir.mkdir(parents=True, exist_ok=True)
    log_file = out_dir / "colabfold_batch.log"

    cmd = [
        COLABFOLD_CMD,
        "--num-recycle", "1",
        "--model-type", "alphafold2_multimer_v3",
        "--rank", "ptm",
        "--max-msa", "32:128",
        "--num-models", "1",
        "--stop-at-score", "0.5",
        str(csv_path),
        str(out_dir),
    ]

    print("\n" + "=" * 80)
    print("STEP 3: ColabFold ë°°ì¹˜ ì‹¤í–‰")
    print("=" * 80)
    print("[INFO] ì‹¤í–‰ ëª…ë ¹ì–´:")
    print(" ", " ".join(cmd))
    print(f"[INFO] ë¡œê·¸ íŒŒì¼: {log_file}")

    with open(log_file, "w") as lf:
        proc = subprocess.Popen(cmd, stdout=lf, stderr=subprocess.STDOUT)

    last_done = -1
    while True:
        ret = proc.poll()

        rank1_files = list(out_dir.glob("*rank_001*.*pdb"))
        done = len(rank1_files)
        if done != last_done:
            print(f"\r[ColabFold ì§„í–‰ ìƒí™©] {done}/{total_complexes} êµ¬ì¡° ì™„ë£Œ", end="", flush=True)
            last_done = done

        if ret is not None:
            break
        time.sleep(30)

    print()
    if proc.returncode != 0:
        print(f"[ERROR] ColabFold ì‹¤í–‰ ì‹¤íŒ¨ (returncode={proc.returncode}). ë§ˆì§€ë§‰ 40ì¤„ ë¡œê·¸:")
        try:
            with open(log_file) as f:
                lines = f.readlines()
            for line in lines[-40:]:
                print(line.rstrip())
        except Exception as e:
            print(f"[WARN] ë¡œê·¸ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise RuntimeError(f"ColabFold ì‹¤í–‰ ì‹¤íŒ¨, ë¡œê·¸ í™•ì¸: {log_file}")

    print("[INFO] ColabFold ì‹¤í–‰ ì™„ë£Œ")
    rank1_files = sorted(out_dir.glob("*rank_001*.*pdb"))
    print(f"[INFO] rank_001 PDB ê°œìˆ˜: {len(rank1_files)}")
    return rank1_files


# =====================================================================
# === STEP 4: AutoDock Vina ë„í‚¹ =====================================
# =====================================================================

class ChainSelect(Select):
    def __init__(self, chain_id):
        self.chain_id = chain_id

    def accept_chain(self, chain):
        return chain.get_id() == self.chain_id


def split_complex_to_receptor_ligand(
    complex_pdb: Path,
    out_dir: Path,
    receptor_chain: str = "A",
    ligand_chain: str = "B",
):
    """
    ê°„ë‹¨ ê°€ì •:
    - ColabFold ë©€í‹°ë¨¸ ì¶œë ¥ì—ì„œ ì²´ì¸ A: íƒ€ê¹ƒ ë‹¨ë°±ì§ˆ
    - ì²´ì¸ B: í©íƒ€ì´ë“œ
    """
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("complex", str(complex_pdb))
    model = next(structure.get_models())

    io = PDBIO()
    rec_pdb = out_dir / f"{complex_pdb.stem}_receptor_{receptor_chain}.pdb"
    lig_pdb = out_dir / f"{complex_pdb.stem}_ligand_{ligand_chain}.pdb"

    io.set_structure(model)
    io.save(str(rec_pdb), ChainSelect(receptor_chain))
    io.set_structure(model)
    io.save(str(lig_pdb), ChainSelect(ligand_chain))

    return rec_pdb, lig_pdb


def compute_box_from_ligand(lig_pdb: Path, padding: float = 10.0):
    """
    ë¦¬ê°„ë“œ ì¢Œí‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°•ìŠ¤ ì¤‘ì‹¬/í¬ê¸°ë¥¼ ìë™ ì„¤ì •.
    """
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("ligand", str(lig_pdb))
    model = next(structure.get_models())
    coords = []
    for atom in model.get_atoms():
        coord = atom.get_coord()
        coords.append(coord)
    if not coords:
        raise ValueError(f"ë¦¬ê°„ë“œ PDBì—ì„œ ì›ì ì¢Œí‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {lig_pdb}")

    import numpy as np
    coords = np.array(coords)
    center = coords.mean(axis=0)
    minc = coords.min(axis=0)
    maxc = coords.max(axis=0)
    size = (maxc - minc) + padding

    box = {
        "center_x": float(center[0]),
        "center_y": float(center[1]),
        "center_z": float(center[2]),
        "size_x": float(size[0]),
        "size_y": float(size[1]),
        "size_z": float(size[2]),
    }
    return box


def prepare_pdbqt(rec_pdb: Path, lig_pdb: Path, out_dir: Path):
    """
    PDB â†’ PDBQT ë³€í™˜.
    1) AutoDockTools ìŠ¤í¬ë¦½íŠ¸(prepare_receptor4.py, prepare_ligand4.py)ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒ ì‚¬ìš©
    2) ì—†ìœ¼ë©´ obabel ì‚¬ìš©
    """
    out_dir.mkdir(parents=True, exist_ok=True)
    rec_pdbqt = out_dir / f"{rec_pdb.stem}.pdbqt"
    lig_pdbqt = out_dir / f"{lig_pdb.stem}.pdbqt"

    prep_rec = shutil.which("prepare_receptor4.py")
    prep_lig = shutil.which("prepare_ligand4.py")
    obabel   = shutil.which("obabel")

    if prep_rec and prep_lig:
        run(f"{prep_rec} -r {rec_pdb} -o {rec_pdbqt} -A hydrogens")
        run(f"{prep_lig} -l {lig_pdb} -o {lig_pdbqt} -A hydrogens")
    elif obabel:
        run(f"{obabel} -ipdb {rec_pdb} -xr -opdbqt -O {rec_pdbqt}")
        run(f"{obabel} -ipdb {lig_pdb}      -opdbqt -O {lig_pdbqt}")
    else:
        raise RuntimeError("PDBQT ë³€í™˜ ë„êµ¬(prepare_* ë˜ëŠ” obabel)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return rec_pdbqt, lig_pdbqt


def parse_vina_score_from_stdout(stdout: str):
    """
    AutoDock Vina stdoutì—ì„œ best score(affinity, kcal/mol)ë¥¼ íŒŒì‹±.

    ìš°ì„ ìˆœìœ„:
    1) mode í…Œì´ë¸” (mode | affinity | ...)ì—ì„œ affinity ì—´ íŒŒì‹±
    2) fallback: 'REMARK VINA RESULT' í˜•ì‹ì´ ìˆìœ¼ë©´ ê·¸ ì¤„ì—ì„œ float ì¶”ì¶œ
    """
    energies = []

    # 1) mode í…Œì´ë¸” íŒŒì‹±
    for line in stdout.splitlines():
        s = line.strip()
        if not s:
            continue
        # í—¤ë”/êµ¬ë¶„ì„ ì€ ê±´ë„ˆë›°ê¸°
        if s.startswith("mode") or set(s) <= {"-", "+"}:
            continue

        parts = s.split()
        # "1  -7.5  ..." ì´ëŸ° í˜•ì‹ì¼ ë•Œ
        if parts and parts[0].isdigit() and len(parts) >= 2:
            try:
                val = float(parts[1])
            except ValueError:
                continue
            energies.append(val)

    if energies:
        # ê°€ì¥ ë‚®ì€ ì—ë„ˆì§€(ê°€ì¥ ì¢‹ì€ í¬ì¦ˆ)ë¥¼ ë°˜í™˜
        return min(energies)

    # 2) fallback: ì˜ˆì „ ìŠ¤íƒ€ì¼ 'REMARK VINA RESULT:' ì¤„
    for line in stdout.splitlines():
        if "REMARK VINA RESULT" in line:
            for token in line.split():
                try:
                    return float(token)
                except ValueError:
                    continue

    # ì•„ë¬´ ê²ƒë„ ëª» ì°¾ìœ¼ë©´ None
    return None


def run_vina_on_rank1(rank1_pdbs, vina_dir: Path):
    """
    AutoDock Vina ë„í‚¹ ì‹¤í–‰ + ìš”ì•½/ìƒíƒœ ë¡œê·¸ ê¸°ë¡.

    - vina_summary.csv ì»¬ëŸ¼:
        complex, vina_score, vina_status, receptor_pdbqt, ligand_pdbqt, log_file
    - vina_status ì˜ˆì‹œ:
        'ì •ìƒ', 'ì •ìƒ(ì ìˆ˜=0.0)',
        'ì‹¤íŒ¨: Vina ì‹¤í–‰ ì—ëŸ¬(code=...)',
        'ì‹¤íŒ¨: Vina ì‹¤í–‰ ì—ëŸ¬(code=...)(PDBQT parsing error: ...)',
        'íŒŒì‹±ì‹¤íŒ¨: stdoutì—ì„œ ì ìˆ˜ íŒ¨í„´ ì—†ìŒ'
    """
    print("\n" + "=" * 80)
    print("STEP 4: AutoDock Vina ë„í‚¹")
    print("=" * 80)

    if not rank1_pdbs:
        print("[WARN] Vina ì‹¤í–‰í•  rank_001 PDBê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not shutil.which(VINA_CMD):
        print(f"[WARN] VINA_CMD='{VINA_CMD}' ì‹¤í–‰ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (PATH í™•ì¸ í•„ìš”)")
        return

    vina_dir.mkdir(parents=True, exist_ok=True)
    summary_rows = [["complex", "vina_score", "vina_status", "receptor_pdbqt", "ligand_pdbqt", "log_file"]]
    debug_lines = []

    for complex_pdb in rank1_pdbs:
        base = complex_pdb.stem
        complex_out_dir = vina_dir / base
        complex_out_dir.mkdir(parents=True, exist_ok=True)

        print(f"\n[INFO] Vina ì¤€ë¹„: {complex_pdb.name}")
        rec_pdb, lig_pdb = split_complex_to_receptor_ligand(
            complex_pdb,
            complex_out_dir,
            receptor_chain="A",
            ligand_chain="B",
        )

        rec_pdbqt, lig_pdbqt = prepare_pdbqt(rec_pdb, lig_pdb, complex_out_dir)
        box = compute_box_from_ligand(lig_pdb)

        out_pdbqt = complex_out_dir / f"{base}_vina_out.pdbqt"
        log_file  = complex_out_dir / f"{base}_vina_stdout.txt"

        vina_cmd = (
            f"{VINA_CMD} "
            f"--receptor {rec_pdbqt} "
            f"--ligand {lig_pdbqt} "
            f"--center_x {box['center_x']:.3f} --center_y {box['center_y']:.3f} --center_z {box['center_z']:.3f} "
            f"--size_x {box['size_x']:.3f} --size_y {box['size_y']:.3f} --size_z {box['size_z']:.3f} "
            f"--out {out_pdbqt}"
        )

        print(f"[RUN] {vina_cmd}")
        result = subprocess.run(
            vina_cmd,
            shell=True,
            capture_output=True,
            text=True,
        )

        with open(log_file, "w", encoding="utf-8") as lf:
            lf.write("=== STDOUT ===\n")
            lf.write(result.stdout or "")
            lf.write("\n\n=== STDERR ===\n")
            lf.write(result.stderr or "")

        best_score = None
        status = ""

        if result.returncode != 0:
            # ì‹¤í–‰ ìì²´ ì‹¤íŒ¨
            status = f"ì‹¤íŒ¨: Vina ì‹¤í–‰ ì—ëŸ¬(code={result.returncode})"
            if "PDBQT parsing error" in (result.stdout or "") or "PDBQT parsing error" in (result.stderr or ""):
                status += " (PDBQT parsing error: flex residue/ligand íƒœê·¸ ë¬¸ì œ)"
            print(f"[ERROR] {status}. ë¡œê·¸ íŒŒì¼: {log_file}")
            print(result.stdout or "")
            print(result.stderr or "")
            debug_lines.append(f"{base}\t{status}\tlog={log_file.name}")
        else:
            # ì‹¤í–‰ì€ ì„±ê³µ â†’ score íŒŒì‹±
            best_score = parse_vina_score_from_stdout(result.stdout or "")
            if best_score is None:
                status = "íŒŒì‹±ì‹¤íŒ¨: stdoutì—ì„œ ì ìˆ˜ íŒ¨í„´ ì—†ìŒ"
                print(f"[WARN] {complex_pdb.name} Vina ì ìˆ˜ íŒŒì‹± ì‹¤íŒ¨. ë¡œê·¸ íŒŒì¼ í™•ì¸: {log_file}")
                debug_lines.append(f"{base}\t{status}\tlog={log_file.name}")
            else:
                if best_score == 0.0:
                    status = "ì •ìƒ(ì ìˆ˜=0.0)"
                else:
                    status = "ì •ìƒ"
                print(f"[INFO] {complex_pdb.name} Vina best score: {best_score}")
                debug_lines.append(f"{base}\t{status}\t{best_score}")

        summary_rows.append([base, best_score, status, rec_pdbqt.name, lig_pdbqt.name, log_file.name])

    summary_csv = vina_dir / "vina_summary.csv"
    with open(summary_csv, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerows(summary_rows)
    print(f"\nâœ… Vina ìš”ì•½ ì €ì¥: {summary_csv}")

    if debug_lines:
        debug_file = vina_dir / "vina_debug.txt"
        debug_file.write_text("\n".join(debug_lines), encoding="utf-8")
        print(f"[INFO] Vina ë””ë²„ê·¸ ë¡œê·¸: {debug_file}")

    print("=" * 80)


# =====================================================================
# === STEP 5: PLIP ìƒí˜¸ì‘ìš© ë¶„ì„ =====================================
# =====================================================================

def run_plip_on_rank1(rank1_pdbs, plip_dir: Path):
    """
    PLIP ìƒí˜¸ì‘ìš© ë¶„ì„.
    - ê° complexë³„ stdout/stderr ë¥¼ ë¡œê·¸ íŒŒì¼ë¡œ ì €ì¥.
    """
    print("\n" + "=" * 80)
    print("STEP 5: PLIP ìƒí˜¸ì‘ìš© ë¶„ì„")
    print("=" * 80)
    if not rank1_pdbs:
        print("[WARN] PLIP ì‹¤í–‰í•  rank_001 PDBê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not PLIP_CMD:
        print("[WARN] PLIP_CMD ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return

    plip_dir.mkdir(parents=True, exist_ok=True)
    debug_lines = []

    for pdb in rank1_pdbs:
        base = pdb.stem
        out_subdir = plip_dir / base
        out_subdir.mkdir(exist_ok=True)
        cmd = f"{PLIP_CMD} -f {pdb} -o {out_subdir}"
        print(f"[RUN] {cmd}")
        log_file = out_subdir / f"{base}_plip.log"

        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)

        with open(log_file, "w", encoding="utf-8") as lf:
            lf.write("=== STDOUT ===\n")
            lf.write(result.stdout or "")
            lf.write("\n\n=== STDERR ===\n")
            lf.write(result.stderr or "")

        if result.returncode != 0:
            print(f"[ERROR] PLIP ì‹¤íŒ¨: {pdb.name} (code={result.returncode}). ë¡œê·¸: {log_file}")
            print((result.stderr or "")[:300])
            debug_lines.append(f"{base}\tERROR_returncode_{result.returncode}\tlog={log_file.name}")
        else:
            print(f"âœ”ï¸ PLIP ì™„ë£Œ: {pdb.name} â†’ {out_subdir}")
            debug_lines.append(f"{base}\tOK\tlog={log_file.name}")

    if debug_lines:
        debug_file = plip_dir / "plip_run_debug.txt"
        debug_file.write_text("\n".join(debug_lines), encoding="utf-8")
        print(f"[INFO] PLIP ì‹¤í–‰ ë””ë²„ê·¸ ë¡œê·¸: {debug_file}")
    print("=" * 80)


# =====================================================================
# === STEP 6: PRODIGY ê²°í•© ì¹œí™”ë„ í‰ê°€ ===============================
# =====================================================================

def run_prodigy_on_rank1(rank1_pdbs, out_dir: Path) -> pd.DataFrame:
    """
    PRODIGY ê²°í•© ì¹œí™”ë„ í‰ê°€.

    - prodigy_summary.csv ì»¬ëŸ¼:
        complex, PRODIGY_dG, prodigy_status
    - prodigy_status ì˜ˆì‹œ:
        'ì •ìƒ',
        'ì‹¤íŒ¨: PRODIGY ì‹¤í–‰ ì—ëŸ¬(code=...)',
        'íŒŒì‹±ì‹¤íŒ¨: stdoutì—ì„œ Î”G íŒ¨í„´ ì—†ìŒ'
    """
    print("\n" + "="*80)
    print("STEP 6: PRODIGY ê²°í•© ì¹œí™”ë„ í‰ê°€")
    print("="*80)

    if not PRODIGY_SCRIPT:
        print("[WARN] PRODIGY_SCRIPT í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("       ì˜ˆ: export PRODIGY_SCRIPT='prodigy'")
        return pd.DataFrame()

    out_dir.mkdir(parents=True, exist_ok=True)

    records = []
    debug_lines = []

    for pdb_path in rank1_pdbs:
        complex_name = Path(pdb_path).stem
        out_txt = out_dir / f"{complex_name}_prodigy.txt"
        err_txt = out_dir / f"{complex_name}_prodigy.stderr.txt"

        cmd = [
            *PRODIGY_SCRIPT.split(),
            str(pdb_path),
            "--selection", "A", "B",
        ]
        print(f"[RUN] {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)

        # stdout / stderr ì €ì¥
        out_txt.write_text(result.stdout or "", encoding="utf-8")
        err_txt.write_text(result.stderr or "", encoding="utf-8")

        dg = None
        status = ""

        if result.returncode != 0:
            status = f"ì‹¤íŒ¨: PRODIGY ì‹¤í–‰ ì—ëŸ¬(code={result.returncode})"
            print(f"[ERROR] {status}: {complex_name}. ë¡œê·¸: {out_txt.name}, {err_txt.name}")
            print((result.stderr or "")[:300])
        else:
            # stdoutì—ì„œ Î”G ê°’ íŒŒì‹±
            dg = parse_prodigy_dg_from_stdout(result.stdout or "")
            if dg is None:
                status = "íŒŒì‹±ì‹¤íŒ¨: stdoutì—ì„œ Î”G íŒ¨í„´ ì—†ìŒ"
                print(f"[WARN] PRODIGY Î”G íŒŒì‹± ì‹¤íŒ¨: {complex_name}. (ë¡œê·¸: {out_txt.name})")
            else:
                status = "ì •ìƒ"

        records.append({
            "complex": complex_name,
            "PRODIGY_dG": dg,
            "prodigy_status": status,
        })
        debug_lines.append(f"{complex_name}\t{status}\t{dg}")

    if debug_lines:
        debug_file = out_dir / "prodigy_debug.txt"
        debug_file.write_text("\n".join(debug_lines), encoding="utf-8")
        print(f"[INFO] PRODIGY ë””ë²„ê·¸ ë¡œê·¸: {debug_file}")

    df = pd.DataFrame(records)
    df.to_csv(out_dir / "prodigy_summary.csv", index=False)
    print(f"âœ… PRODIGY ìš”ì•½ ì €ì¥: {out_dir / 'prodigy_summary.csv'}")
    return df


# =====================================================================
# === STEP 7: ìµœì¢… í‰ê°€(ê°€ì¤‘ì¹˜ Aì•ˆ) + PDB zip + ì—‘ì…€ =================
# =====================================================================

def zip_rank1_pdbs(rank1_pdbs, results_dir: Path):
    """
    ColabFoldì—ì„œ ìƒì„±ëœ rank_001 PDBë“¤ì„ í•˜ë‚˜ì˜ zip íŒŒì¼ë¡œ ì••ì¶•.
    (íƒ€ê¹ƒ ë‹¨ë°±ì§ˆ + ìƒì„± í©íƒ€ì´ë“œ ë³µí•©ì²´ êµ¬ì¡°)
    """
    if not rank1_pdbs:
        print("[INFO] zipìœ¼ë¡œ ë¬¶ì„ rank_001 PDBê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    zip_path = results_dir / f"peptide_structures_{timestamp()}.zip"
    with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for pdb_path in rank1_pdbs:
            zf.write(pdb_path, arcname=pdb_path.name)

    print(f"âœ… rank_001 PDB ì••ì¶• ì €ì¥: {zip_path}")
    return zip_path


def load_vina_scores(vina_dir: Path):
    """
    vina_summary.csv ì—ì„œ complexë³„ Vina scoreì™€ ìƒíƒœë¥¼ ë¡œë”©.

    ë°˜í™˜:
      scores   : dict[complex_id] = float ë˜ëŠ” None
      statuses : dict[complex_id] = ìƒíƒœ ë¬¸ìì—´
    """
    scores = {}
    statuses = {}

    summary_csv = vina_dir / "vina_summary.csv"
    if not summary_csv.exists():
        print("[WARN] Vina summary CSVê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤:", summary_csv)
        return scores, statuses

    try:
        df = pd.read_csv(summary_csv)
    except Exception as e:
        print(f"[WARN] Vina summary CSV ë¡œë”© ì‹¤íŒ¨: {e}")
        return scores, statuses

    if "complex" not in df.columns:
        print("[WARN] Vina summary CSVì— 'complex' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return scores, statuses

    has_status = "vina_status" in df.columns

    for _, row in df.iterrows():
        base = row.get("complex")
        if isinstance(base, float) and pd.isna(base):
            continue
        base = str(base).strip()
        if not base:
            continue

        val = row.get("vina_score")
        try:
            scores[base] = float(val)
        except (TypeError, ValueError):
            scores[base] = None

        if has_status:
            s = row.get("vina_status")
            statuses[base] = "" if pd.isna(s) else str(s)
        else:
            # êµ¬ë²„ì „ summaryì—ëŠ” ìƒíƒœê°€ ì—†ìœ¼ë¯€ë¡œ ì ìˆ˜ ìœ ë¬´ë¡œë§Œ ëŒ€ëµ ì¶”ì •
            statuses[base] = "ì •ìƒ" if scores[base] is not None else "ë¯¸ê¸°ë¡"

    print(f"[INFO] Vina ì ìˆ˜ë¥¼ ì½ì–´ì˜¨ êµ¬ì¡° ìˆ˜: {len(scores)}")
    return scores, statuses


def load_prodigy_scores(prodigy_dir: Path):
    """
    PRODIGY ê²°ê³¼ ë¡œë”©.

    ìš°ì„ ìˆœìœ„:
      1) prodigy_summary.csv (ìˆë‹¤ë©´)
      2) ì—†ìœ¼ë©´ *_prodigy.txt ë°±ì—… íŒŒì‹±

    ë°˜í™˜:
      scores   : dict[complex_id] = float ë˜ëŠ” None
      statuses : dict[complex_id] = ìƒíƒœ ë¬¸ìì—´
    """
    scores = {}
    statuses = {}

    if not prodigy_dir.exists():
        return scores, statuses

    summary_csv = prodigy_dir / "prodigy_summary.csv"
    if summary_csv.exists():
        try:
            df = pd.read_csv(summary_csv)
            if "complex" in df.columns:
                # ê°’ ì»¬ëŸ¼ ì°¾ê¸° (prodigy_dg, PRODGIGY_dG ë“±)
                val_col = None
                for c in df.columns:
                    cl = c.lower()
                    if cl.startswith("prodigy") and "status" not in cl:
                        val_col = c
                        break
                has_status = "prodigy_status" in df.columns

                for _, row in df.iterrows():
                    comp = row.get("complex")
                    if isinstance(comp, float) and pd.isna(comp):
                        continue
                    comp = str(comp).strip()
                    if not comp:
                        continue

                    val = row.get(val_col) if val_col is not None else None
                    try:
                        scores[comp] = float(val)
                    except (TypeError, ValueError):
                        scores[comp] = None

                    if has_status:
                        s = row.get("prodigy_status")
                        statuses[comp] = "" if pd.isna(s) else str(s)
                    else:
                        statuses[comp] = "ì •ìƒ" if scores[comp] is not None else "ë¯¸ê¸°ë¡"

            print(f"[INFO] PRODIGY Î”Gë¥¼ ìš”ì•½ íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜´: {len(scores)}ê°œ êµ¬ì¡°")
        except Exception as e:
            print(f"[WARN] prodigy_summary.csv ë¡œë”© ì‹¤íŒ¨: {e}")

    # summaryì—ì„œ ë­”ê°€ ì½ì–´ì™”ë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if scores or statuses:
        return scores, statuses

    # ë°±ì—…: *_prodigy.txt ì§ì ‘ íŒŒì‹±
    for txt in prodigy_dir.glob("*_prodigy.txt"):
        base = txt.stem.replace("_prodigy", "")
        try:
            text = txt.read_text()
        except Exception:
            continue

        vals = []
        for m in re.finditer(r"[-+]?\d+\.\d+", text):
            v = float(m.group(0))
            # PRODIGY Î”G ëŒ€ëµì ì¸ ë²”ìœ„
            if -50.0 <= v <= 0.0:
                vals.append(v)

        if vals:
            scores[base] = min(vals)
            statuses[base] = "í…ìŠ¤íŠ¸ íŒŒì‹±(ë°±ì—…)"
        else:
            scores[base] = None
            statuses[base] = "íŒŒì‹±ì‹¤íŒ¨: *_prodigy.txtì—ì„œ Î”G í›„ë³´ê°’ ì—†ìŒ"

    print(f"[INFO] PRODIGY Î”Gë¥¼ í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ íŒŒì‹±: {len(scores)}ê°œ êµ¬ì¡°")
    return scores, statuses


def load_iptm_scores(colabfold_out_dir: Path, rank1_pdbs):
    """
    ColabFold ì¶œë ¥ í´ë”ì—ì„œ ipTM ê°’ì„ ìµœëŒ€í•œ ìœ ì—°í•˜ê²Œ ì°¾ëŠ”ë‹¤.

    - ê° rank_001 PDBì˜ stem(base)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ
      1) base*scores*.json
      2) base_prefix*scores*.json  (baseì—ì„œ '_unrelaxed' ì•ë¶€ë¶„)
      3) base*_ranking_debug.json, base_prefix*_ranking_debug.json, ranking_debug.json
    ì—ì„œ 'iptm' ë˜ëŠ” 'iptm+ptm' í‚¤ë¥¼ ì°¾ì•„ë³¸ë‹¤.
    """
    iptms = {}
    if not colabfold_out_dir.exists():
        return iptms

    for pdb in rank1_pdbs:
        base = pdb.stem
        prefix = base.split("_unrelaxed")[0]

        found_val = None

        # 1) scores*.json í›„ë³´ë“¤
        candidates = list(colabfold_out_dir.glob(f"{base}*scores*.json"))
        if not candidates:
            candidates = list(colabfold_out_dir.glob(f"{prefix}*scores*.json"))

        for js in candidates:
            try:
                with open(js) as f:
                    data = json.load(f)
            except Exception:
                continue

            if isinstance(data, dict):
                v = data.get("iptm")
                if isinstance(v, (int, float)):
                    found_val = float(v)
                    break
                v = data.get("iptm+ptm")
                if isinstance(v, (int, float)):
                    found_val = float(v)
                    break

        # 2) ranking_debug í›„ë³´ë“¤
        if found_val is None:
            rd_candidates = [
                colabfold_out_dir / f"{base}_ranking_debug.json",
                colabfold_out_dir / f"{prefix}_ranking_debug.json",
                colabfold_out_dir / "ranking_debug.json",
            ]
            for rd in rd_candidates:
                if not rd.exists():
                    continue
                try:
                    with open(rd) as f:
                        data = json.load(f)
                except Exception:
                    continue

                if isinstance(data, dict):
                    v = data.get("iptm") or data.get("iptm+ptm")
                    if isinstance(v, (int, float)):
                        found_val = float(v)
                        break

        if found_val is not None:
            iptms[base] = found_val

    print(f"[INFO] ipTM ê°’ì„ ì½ì–´ì˜¨ êµ¬ì¡° ìˆ˜: {len(iptms)} / {len(rank1_pdbs)}")
    return iptms


def load_plip_scores(plip_dir: Path):
    """
    PLIP ê²°ê³¼ í´ë”ë“¤ì—ì„œ ìƒí˜¸ì‘ìš© ìŠ¤ì½”ì–´ + ìƒíƒœë¥¼ ì¶”ì¶œ.

    - ê° complexë³„ ì„œë¸Œí´ë” ì´ë¦„ì´ complex_0_unrelaxed_... í˜•íƒœë¼ê³  ê°€ì •.
    - ìš°ì„  report.xml, ì—†ìœ¼ë©´ report.txtë¥¼ ì‚¬ìš©.
    - ì•„ë¬´ ê²ƒë„ ì—†ìœ¼ë©´ plip_statusì— ì´ìœ ë¥¼ ê¸°ë¡í•˜ê³  ìƒí˜¸ì‘ìš© ìˆ˜ëŠ” Noneìœ¼ë¡œ ë‘”ë‹¤.

    ë°˜í™˜:
      metrics  : dict[base] = {
                    "total": total or None,
                    "hbond": ...,
                    "hydrophobic": ...,
                    "saltbridge": ...
                }
      statuses : dict[base] = ìƒíƒœ ë¬¸ìì—´
    """
    metrics = {}
    statuses = {}

    if not plip_dir.exists():
        return metrics, statuses

    debug_lines = []

    for subdir in plip_dir.iterdir():
        if not subdir.is_dir():
            continue

        base = subdir.name
        xml_path = subdir / "report.xml"
        txt_report = subdir / "report.txt"

        hbond = 0
        hydrophobic = 0
        saltbridge = 0
        total = None

        source = None
        status = ""

        # 1) report.xml ìš°ì„ 
        if xml_path.exists():
            try:
                tree = ET.parse(xml_path)
                root = tree.getroot()
                hbond = sum(1 for _ in root.iter("hydrogen_bond"))
                hydrophobic = sum(1 for _ in root.iter("hydrophobic_interaction"))
                saltbridge = sum(1 for _ in root.iter("salt_bridge"))
                total = hbond + hydrophobic + saltbridge
                source = "xml"
                status = "ì •ìƒ(xml)"
            except Exception as e:
                status = f"ì‹¤íŒ¨: report.xml íŒŒì‹± ì—ëŸ¬({e})"
                debug_lines.append(f"{base}\treport_xml_parse_error\t{e}")

        # 2) report.txt ë°±ì—…
        if source is None and txt_report.exists():
            try:
                text = txt_report.read_text()
                for line in text.splitlines():
                    lower = line.lower()
                    nums = re.findall(r"\b\d+\b", line)
                    if not nums:
                        continue
                    last_num = int(nums[-1])
                    if "hydrogen bond" in lower:
                        hbond = last_num
                    elif "hydrophobic" in lower:
                        hydrophobic = last_num
                    elif "salt bridge" in lower:
                        saltbridge = last_num
                total = hbond + hydrophobic + saltbridge
                source = "report.txt"
                status = "ì •ìƒ(report.txt)"
            except Exception as e:
                status = f"ì‹¤íŒ¨: report.txt íŒŒì‹± ì—ëŸ¬({e})"
                debug_lines.append(f"{base}\treport_txt_parse_error\t{e}")

        # 3) ë‘˜ ë‹¤ ì—†ìœ¼ë©´ â†’ ì‹¤íŒ¨ ì²˜ë¦¬
        if source is None and not status:
            status = "ì‹¤íŒ¨: report.xml/report.txt ì—†ìŒ (PLIP ì¶œë ¥ì— ìƒí˜¸ì‘ìš© ìš”ì•½ íŒŒì¼ì´ ì—†ìŒ)"

        # totalì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨ ìƒíƒœë©´ ì„¸ë¶€ê°’ì„ Noneìœ¼ë¡œ
        if total is None or status.startswith("ì‹¤íŒ¨"):
            metrics[base] = {
                "total": None,
                "hbond": None,
                "hydrophobic": None,
                "saltbridge": None,
            }
        else:
            metrics[base] = {
                "total": total,
                "hbond": hbond,
                "hydrophobic": hydrophobic,
                "saltbridge": saltbridge,
            }

        statuses[base] = status
        debug_lines.append(
            f"{base}\t{status}\t"
            f"total={metrics[base]['total']}\t"
            f"hbond={metrics[base]['hbond']}\t"
            f"hydrophobic={metrics[base]['hydrophobic']}\t"
            f"saltbridge={metrics[base]['saltbridge']}"
        )

    # ë””ë²„ê·¸ ë¡œê·¸
    if debug_lines:
        debug_file = plip_dir / "plip_parse_debug.txt"
        debug_file.write_text("\n".join(debug_lines), encoding="utf-8")
        print(f"[INFO] PLIP íŒŒì‹± ë””ë²„ê·¸ ë¡œê·¸: {debug_file}")

    # ìš”ì•½ CSV (ê° complexë³„ í•œ ì¤„)
    summary_rows = []
    for base, m in metrics.items():
        summary_rows.append({
            "complex": base,
            "plip_total_interactions": m["total"],
            "plip_hbond": m["hbond"],
            "plip_hydrophobic": m["hydrophobic"],
            "plip_saltbridge": m["saltbridge"],
            "plip_status": statuses.get(base, ""),
        })

    if summary_rows:
        df = pd.DataFrame(summary_rows)
        df.to_csv(plip_dir / "plip_summary.csv", index=False)
        print(f"[INFO] PLIP ìš”ì•½ CSV ì €ì¥: {plip_dir / 'plip_summary.csv'}")

    print(f"[INFO] PLIP ìƒí˜¸ì‘ìš©ì„ ì½ì–´ì˜¨ êµ¬ì¡° ìˆ˜: {len(metrics)}")
    return metrics, statuses


def minmax_norm(value_dict, higher_is_better=True):
    """
    dict(base -> value) í˜•íƒœë¥¼ ë°›ì•„ 0~1 ë²”ìœ„ë¡œ min-max ì •ê·œí™”.
    higher_is_better=True  ì´ë©´ ê°’ì´ í´ìˆ˜ë¡ 1ì— ê°€ê¹ê²Œ,
    higher_is_better=False ì´ë©´ ê°’ì´ ì‘ì„ìˆ˜ë¡(ì—ë„ˆì§€ê°€ ë” ë‚®ì„ìˆ˜ë¡) 1ì— ê°€ê¹ê²Œ.
    """
    vals = [v for v in value_dict.values() if v is not None]
    if not vals:
        return {}

    vmin, vmax = min(vals), max(vals)
    if abs(vmax - vmin) < 1e-8:
        return {k: 1.0 for k, v in value_dict.items() if v is not None}

    out = {}
    for k, v in value_dict.items():
        if v is None:
            continue
        if higher_is_better:
            s = (v - vmin) / (vmax - vmin)
        else:
            s = (vmax - v) / (vmax - vmin)
        out[k] = s
    return out


def build_and_save_final_table(folders, peptides, rank1_pdbs):
    """
    ColabFold / Vina / PLIP / PRODIGY / ipTM ê²°ê³¼ë¥¼ ëª¨ì•„ì„œ
    Aì•ˆ ê°€ì¤‘ì¹˜ë¡œ FinalScore_Aë¥¼ ê³„ì‚°í•˜ê³  ì—‘ì…€ë¡œ ì €ì¥.

    Aì•ˆ:
      PRODIGY 0.35  (Î”G, ë” ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
      Vina    0.20  (ì—ë„ˆì§€, ë” ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
      PLIP    0.25  (ì´ ìƒí˜¸ì‘ìš© ìˆ˜, ë§ì„ìˆ˜ë¡ ì¢‹ìŒ)
      ipTM    0.20  (ì¸í„°í˜ì´ìŠ¤ ì‹ ë¢°ë„, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)

    ì¶”ê°€:
      - ê° í‰ê°€ ëª¨ë¸ë³„ status ì»¬ëŸ¼ì„ ì—‘ì…€ì— í•¨ê»˜ ê¸°ë¡
        (vina_status, prodigy_status, plip_status)
    """
    results_dir     = folders["results"]
    colabfold_out   = folders["colabfold_out"]
    vina_dir        = folders["vina"]
    plip_dir        = folders["plip"]
    prodigy_dir     = folders["prodigy"]

    # ê° í‰ê°€ ì§€í‘œ + ìƒíƒœ ë¶ˆëŸ¬ì˜¤ê¸°
    vina_vals, vina_status         = load_vina_scores(vina_dir)
    prodigy_vals, prodigy_status   = load_prodigy_scores(prodigy_dir)
    iptm_vals                      = load_iptm_scores(colabfold_out, rank1_pdbs)
    plip_metrics, plip_status      = load_plip_scores(plip_dir)

    # PLIP total ê°’ë§Œ ë”°ë¡œ dictë¡œ ì¶”ì¶œ
    plip_total_vals = {b: d.get("total") for b, d in plip_metrics.items()}

    # 0~1 ì •ê·œí™”
    iptm_norm    = minmax_norm(iptm_vals, higher_is_better=True)
    vina_norm    = minmax_norm(vina_vals, higher_is_better=False)
    prodigy_norm = minmax_norm(prodigy_vals, higher_is_better=False)
    plip_norm    = minmax_norm(plip_total_vals, higher_is_better=True)

    # candidate_id â†’ peptide ë§¤í•‘ (complex_0, complex_1 ...)
    id_to_pep = {f"complex_{i}": pep for i, pep in enumerate(peptides)}

    rows = []
    for pdb_path in rank1_pdbs:
        base = pdb_path.stem                                       # complex_0_unrelaxed_...
        candidate_id = base.split("_unrelaxed")[0]                  # complex_0
        pep_seq = id_to_pep.get(candidate_id, "")

        vina    = vina_vals.get(base)
        prodigy = prodigy_vals.get(base)
        iptm    = iptm_vals.get(base)

        plip_data   = plip_metrics.get(base, {})
        plip_total  = plip_data.get("total")
        plip_hbond  = plip_data.get("hbond")
        plip_hphob  = plip_data.get("hydrophobic")
        plip_salt   = plip_data.get("saltbridge")

        # ê°€ì¤‘ì¹˜
        w_prodigy = 0.35
        w_vina    = 0.20
        w_plip    = 0.25
        w_iptm    = 0.20

        # ì •ê·œí™”ëœ ì ìˆ˜ ì¡°í•©
        final_score = (
            w_prodigy * prodigy_norm.get(base, 0.0) +
            w_vina    * vina_norm.get(base, 0.0) +
            w_plip    * plip_norm.get(base, 0.0) +
            w_iptm    * iptm_norm.get(base, 0.0)
        )

        rows.append({
            "candidate_id":     candidate_id,
            "peptide_seq":      pep_seq,
            "complex_pdb":      pdb_path.name,
            "final_score":      final_score,
            "prodigy_dG":       prodigy,
            "prodigy_status":   prodigy_status.get(base, "ë¯¸ê¸°ë¡"),
            "vina_score":       vina,
            "vina_status":      vina_status.get(base, "ë¯¸ê¸°ë¡"),
            "plip_total":       plip_total,
            "plip_hbond":       plip_hbond,
            "plip_hphob":       plip_hphob,
            "plip_salt":        plip_salt,
            "plip_status":      plip_status.get(base, "ë¯¸ê¸°ë¡"),
            "iptm":             iptm,
        })

    # FinalScore_A ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    rows.sort(
        key=lambda r: (r["final_score"] if r["final_score"] is not None else -1e9),
        reverse=True,
    )

    # ì—‘ì…€ ì‘ì„±
    wb = Workbook()
    ws = wb.active
    ws.title = "pepbind_ranking_A"

    headers = [
        "rank",
        "candidate_id",
        "peptide_seq",
        "complex_pdb",
        "FinalScore_A",
        "PRODIGY_dG(kcal/mol)",
        "PRODIGY_status",
        "Vina_score(kcal/mol)",
        "Vina_status",
        "PLIP_total_interactions",
        "PLIP_hbond",
        "PLIP_hydrophobic",
        "PLIP_saltbridge",
        "PLIP_status",
        "ipTM",
    ]
    ws.append(headers)

    for idx, r in enumerate(rows, start=1):
        ws.append([
            idx,
            r["candidate_id"],
            r["peptide_seq"],
            r["complex_pdb"],
            round(r["final_score"], 4) if r["final_score"] is not None else None,
            r["prodigy_dG"],
            r["prodigy_status"],
            r["vina_score"],
            r["vina_status"],
            r["plip_total"],
            r["plip_hbond"],
            r["plip_hphob"],
            r["plip_salt"],
            r["plip_status"],
            r["iptm"],
        ])

    out_xlsx = results_dir / f"final_peptide_ranking_A_{timestamp()}.xlsx"
    wb.save(out_xlsx)
    print(f"âœ… ìµœì¢… ê²°ê³¼ ì—‘ì…€ ì €ì¥: {out_xlsx}")
    return out_xlsx


# =====================================================================
# === MAIN ============================================================
# =====================================================================

def main():
    # 1) ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ìƒì„±
    folders = init_workspace()

    # 2) íƒ€ê¹ƒ ì„œì—´ FASTA ì €ì¥
    target_seq = TARGET_SEQUENCE.strip()
    target_fasta = write_target_fasta(folders["fasta"], target_seq)
    print(f"âœ”ï¸ íƒ€ê¹ƒ ë‹¨ë°±ì§ˆ ê¸¸ì´: {len(target_seq)}")
    print(f"âœ”ï¸ íƒ€ê¹ƒ FASTA: {target_fasta}")

    # 3) PepMLM(ESM-2) ê¸°ë°˜ í©íƒ€ì´ë“œ ìƒì„±
    tokenizer, model = load_esm_mlm()
    peptides = generate_peptides_with_mlm(
        tokenizer,
        model,
        target_seq,
        num_peptides=NUM_PEPTIDES,
        peptide_len=PEPTIDE_LENGTH,
    )
    pep_fasta = write_peptide_fasta(folders["fasta"], peptides)
    print(f"âœ”ï¸ PepMLM ê²°ê³¼ ì €ì¥: {pep_fasta}")

    # 4) ColabFold êµ¬ì¡° ì˜ˆì¸¡
    rank1_pdbs = []
    if RUN_COLABFOLD and peptides:
        csv_path = prepare_colabfold_batch_csv(
            folders["temp"],
            target_seq,
            peptides,
        )
        rank1_pdbs = run_colabfold_batch_with_progress(
            csv_path,
            folders["colabfold_out"],
            total_complexes=len(peptides),
        )
    else:
        print("\n[INFO] RUN_COLABFOLD=False ë˜ëŠ” í©íƒ€ì´ë“œ ì—†ìŒ â†’ ColabFold ë‹¨ê³„ ìŠ¤í‚µ")

    # 5) Vina / PLIP / PRODIGY
    if RUN_VINA:
        run_vina_on_rank1(rank1_pdbs, folders["vina"])
    else:
        print("\n[INFO] RUN_VINA=False â†’ Vina ë‹¨ê³„ ìŠ¤í‚µ")

    if RUN_PLIP:
        run_plip_on_rank1(rank1_pdbs, folders["plip"])
    else:
        print("[INFO] RUN_PLIP=False â†’ PLIP ë‹¨ê³„ ìŠ¤í‚µ")

    if RUN_PRODIGY:
        run_prodigy_on_rank1(rank1_pdbs, folders["prodigy"])
    else:
        print("[INFO] RUN_PRODIGY=False â†’ PRODIGY ë‹¨ê³„ ìŠ¤í‚µ")

    # 6) rank_001 PDB zip ì••ì¶• + Aì•ˆ ìµœì¢… ì—‘ì…€
    pdb_zip = None
    final_xlsx = None
    if rank1_pdbs:
        pdb_zip   = zip_rank1_pdbs(rank1_pdbs, folders["results"])
        final_xlsx = build_and_save_final_table(folders, peptides, rank1_pdbs)
    else:
        print("[INFO] rank_001 PDBê°€ ì—†ì–´ zip/ì—‘ì…€ ìƒì„±ì„ ìƒëµí•©ë‹ˆë‹¤.")

    # ì¢…ë£Œ ì‹œê°„ ë° ì†Œìš” ì‹œê°„ ê³„ì‚°
    END_TIME = datetime.now()

    start_str = START_TIME.strftime("%Y.%m.%d %H:%M:%S")
    end_str   = END_TIME.strftime("%Y.%m.%d %H:%M:%S")

    elapsed = END_TIME - START_TIME
    total_seconds = int(elapsed.total_seconds())

    days = total_seconds // (24 * 3600)
    total_seconds %= (24 * 3600)
    hours = total_seconds // 3600
    total_seconds %= 3600
    minutes = total_seconds // 60
    seconds = total_seconds % 60

    # "00ì¼ 00ì‹œê°„ 00ë¶„ 00ì´ˆ" í˜•íƒœì—ì„œ
    # ì¼/ì‹œê°„ì€ 0ì´ë©´ ìƒëµ
    parts = []
    if days > 0:
        parts.append(f"{days:02d}ì¼")
    if days > 0 or hours > 0:
        parts.append(f"{hours:02d}ì‹œê°„")
    parts.append(f"{minutes:02d}ë¶„")
    parts.append(f"{seconds:02d}ì´ˆ")
    elapsed_str = " ".join(parts)

    print("\n" + "=" * 80)
    print("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¢…ë£Œ")
    print("=" * 80)
    print(f"[INFO] ì›Œí¬ìŠ¤í˜ì´ìŠ¤: {folders['root']}")
    if pdb_zip:
        print(f"[INFO] PDB zip: {pdb_zip}")
    if final_xlsx:
        print(f"[INFO] ìµœì¢… ì—‘ì…€: {final_xlsx}")
    print(f"[INFO] ì‹œì‘ ì‹œê°„: {start_str}")
    print(f"[INFO] ì¢…ë£Œ ì‹œê°„: {end_str}")
    print(f"[INFO] ì´ ì†Œìš” ì‹œê°„: {elapsed_str}")
    print("=" * 80)


if __name__ == "__main__":
    main()
