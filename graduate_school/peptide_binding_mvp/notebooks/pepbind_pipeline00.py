# pepbind_pipeline.py (WSL-friendly starter)
# Generated from Colab notebook on 2025-10-14 10:41
# This script bundles code cells (cleaned) and adds a CLI wrapper.
# Review TODOs below and adapt paths/commands for your local setup.

import os, sys, json, argparse, subprocess, shutil, pathlib, time
from pathlib import Path
# Safe display stub (for scripts; notebook-only display calls won't break)
try:
    from IPython.display import display  # optional, for rich output in notebooks
except Exception:
    def display(x):
        print(x)

# ======== CONFIG (edit as needed) ========
BASE_DIR = Path(os.environ.get("PEPBIND_BASE_DIR", "~/work/pipeline")).expanduser()
DATA_DIR = BASE_DIR / "data"
OUTPUT_DIR = BASE_DIR / "outputs"
STRUCT_DIR = OUTPUT_DIR / "structures"
DOCK_DIR = OUTPUT_DIR / "docking"
PLIP_DIR = OUTPUT_DIR / "plip"
PRODIGY_DIR = OUTPUT_DIR / "prodigy"
LOG_DIR = OUTPUT_DIR / "logs"
for d in [DATA_DIR, OUTPUT_DIR, STRUCT_DIR, DOCK_DIR, PLIP_DIR, PRODIGY_DIR, LOG_DIR]:
    d.mkdir(parents=True, exist_ok=True)

# External tools (set absolute paths if needed)
COLABFOLD_CMD = os.environ.get("COLABFOLD_CMD", "colabfold_batch")  # or path to run_colabfold.py
VINA_CMD = os.environ.get("VINA_CMD", "vina")
PLIP_CLI = os.environ.get("PLIP_CLI", "plip")  # or 'python -m plip' depending on install
PRODIGY_SCRIPT = os.environ.get("PRODIGY_SCRIPT", "prodigy")  # placeholder; replace with your PRODIGY CLI

# ======== Utility helpers ========
def run(cmd, cwd=None):
    print(f"[RUN] {cmd}", flush=True)
    result = subprocess.run(cmd, cwd=cwd, shell=isinstance(cmd, str))
    if result.returncode != 0:
        raise RuntimeError(f"Command failed: {cmd}")
    return result

def find_top_structure(colabfold_out: Path) -> Path | None:
    """Best-effort: pick rank_001*.pdb from colabfold output."""
    candidates = sorted(colabfold_out.glob("rank_001*.*pdb"))
    return candidates[0] if candidates else None

def main():
    parser = argparse.ArgumentParser(description="PepBind pipeline (ipTM â†’ Vina â†’ PLIP â†’ PRODIGY)")
    parser.add_argument("--target_fasta", type=str, required=False, help="Path to target protein FASTA")
    parser.add_argument("--peptide_fasta", type=str, required=False, help="Path to peptide FASTA (candidates)")
    parser.add_argument("--colabfold_out", type=str, default=str(STRUCT_DIR), help="ColabFold output dir")
    parser.add_argument("--vina_box", type=str, default="", help="Vina box params string or JSON")
    parser.add_argument("--threads", type=int, default=8)
    parser.add_argument("--skip_colabfold", action="store_true")
    parser.add_argument("--skip_vina", action="store_true")
    parser.add_argument("--skip_plip", action="store_true")
    parser.add_argument("--skip_prodigy", action="store_true")
    args = parser.parse_args()

    if not args.skip_colabfold:
        # TODO: Adjust ColabFold invocation to your inputs
        # Example:
        # run([COLABFOLD_CMD, args.target_fasta, args.peptide_fasta, args.colabfold_out, f"--num-recycle=3", f"--threads={args.threads}"])
        print("[INFO] ColabFold step is enabled but invocation is left as TODO. Set COLABFOLD_CMD and adjust arguments.")

    top_pdb = find_top_structure(Path(args.colabfold_out))
    if top_pdb is None:
        print("[WARN] No rank_001*.pdb found. Ensure ColabFold output dir is correct.")
    else:
        print(f"[OK] Using top structure: {top_pdb}")

    # Vina docking (placeholder)
    if not args.skip_vina and top_pdb is not None:
        # TODO: Convert PDBâ†’PDBQT, prepare receptor/ligand, and run Vina
        print("[INFO] Vina step enabled. Implement preparation and invocation as needed.")

    # PLIP interactions (placeholder)
    if not args.skip_plip and top_pdb is not None:
        # Example: run([f"python -m plip.cmd.plip -f {top_pdb} -o {PLIP_DIR}"])
        print("[INFO] PLIP step enabled. Implement invocation path (PLIP_CLI) as needed.")

    # PRODIGY affinity (placeholder)
    if not args.skip_prodigy and top_pdb is not None:
        print("[INFO] PRODIGY step enabled. Implement PRODIGY call as needed.")

    print("[DONE] Pipeline completed (placeholders for external tools may need edits).")

if __name__ == "__main__":
    main()

# ======== BEGIN: Code extracted from Colab (cleaned) ========


# ##############################################################################
#
# í†µí•© í©íƒ€ì´ë“œ ë°œêµ´ íŒŒì´í”„ë¼ì¸ (Single-Notebook Peptide Discovery Pipeline) - PRODIGY ê°œì„  ë²„ì „
#
# ì´ ì½”ë“œëŠ” Google Colab Pro/Pro+ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
# Colab ë©”ë‰´ì—ì„œ 'ëŸ°íƒ€ì„' -> 'ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½'ì„ ì„ íƒí•˜ì—¬
# í•˜ë“œì›¨ì–´ ê°€ì†ê¸°ë¥¼ 'GPU'ë¡œ, ëŸ°íƒ€ì„ êµ¬ì„±ì„ 'ë†’ì€ RAM'ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.
#
# ##############################################################################


# ==============================================================================
# STEP 0: í™˜ê²½ ì„¤ì • ë° ëª¨ë“  í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ìˆ˜ì • ë²„ì „)
# ==============================================================================
import torch
from datetime import datetime
import pytz
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForMaskedLM
import glob
import json
import pandas as pd
import re
import subprocess
import numpy as np
import requests
import time
from bs4 import BeautifulSoup
import os
import sys
import site
import shutil
import zipfile

# íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹œê°„ ê¸°ë¡
pipeline_start_time = time.time()

print("="*80)
print("STEP 0: í™˜ê²½ ì„¤ì • ë° ëª¨ë“  í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ê°œì„  ë²„ì „)")
print("="*80)

# ì‹œê°„ëŒ€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
print("\n   > ì‹œê°„ëŒ€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ (pytz) ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q pytz")
print("   > pytz ì„¤ì¹˜ ì™„ë£Œ")

# ColabFold (AlphaFold2) ì„¤ì¹˜
print("\n[1/5] ColabFold (AlphaFold2) ì„¤ì¹˜ ì¤‘...")
print("   > ê¸°ì¡´ TensorFlow íŒ¨í‚¤ì§€ë¥¼ ì œê±°í•˜ì—¬ ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤...")
os.system("pip uninstall -y tensorflow tensorboard tb-nightly tensorflow-estimator tensorflow-hub tensorflow-io > /dev/null 2>&1")
os.system("pip install -q --no-warn-conflicts 'colabfold[alphafold] @ git+https://github.com/sokrypton/ColabFold'")
os.system("pip install -q --no-warn-conflicts 'jax[cuda11_pip]' -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html")

# ColabFold ìŠ¤í¬ë¦½íŠ¸ íŒ¨ì¹˜
print("   > ColabFold ìŠ¤í¬ë¦½íŠ¸ íŒ¨ì¹˜ ì ìš© ì¤‘...")
try:
    dist_packages_path = site.getsitepackages()[0]
    batch_py_path = os.path.join(dist_packages_path, 'colabfold', 'batch.py')
    if os.path.exists(batch_py_path):
        os.system(f"sed -i 's/tf.get_logger().setLevel(logging.ERROR)/#tf.get_logger().setLevel(logging.ERROR)/g' {batch_py_path}")
        os.system(f"sed -i \\\"s/tf.config.set_visible_devices(\\\\\\\\[\\\\\\\\], 'GPU')/#tf.config.set_visible_devices(\\\\\\\\[\\\\\\\\], 'GPU')/g\\\" {batch_py_path}")
        print("   > íŒ¨ì¹˜ ì ìš© ì™„ë£Œ.")
    else:
        print(f"   > ê²½ê³ : {batch_py_path}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ íŒ¨ì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
except Exception as e:
    print(f"   > ê²½ê³ : ColabFold íŒ¨ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")

# í©íƒ€ì´ë“œ ìƒì„± ëª¨ë¸ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
print("\n[2/5] í©íƒ€ì´ë“œ ìƒì„± ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Transformers) ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q --upgrade transformers sentencepiece")

# ê²°í•©ë ¥ í‰ê°€ ë„êµ¬ ì„¤ì¹˜ (ê°œì„ ëœ ë²„ì „)
print("\n[3/5] ê²°í•©ë ¥ í‰ê°€ ë„êµ¬ ì„¤ì¹˜ ì¤‘ (ê°œì„ ëœ ë²„ì „)...")

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ë° ì„¤ì¹˜
print("   > ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ì¤‘...")
os.system("apt-get update -qq > /dev/null 2>&1")

# OpenBabel ì„¤ì¹˜ (ê°œì„ ëœ ë°©ë²•)
print("   > OpenBabel ì„¤ì¹˜ ì¤‘...")
os.system("apt-get install -y --quiet openbabel python3-openbabel libopenbabel-dev")
os.system("pip install -q openbabel-wheel")
print("   > OpenBabel ì„¤ì¹˜ ì™„ë£Œ")

# RDKit ì„¤ì¹˜ (í™”í•™ êµ¬ì¡° ì²˜ë¦¬ìš©)
print("   > RDKit ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q rdkit-pypi")
print("   > RDKit ì„¤ì¹˜ ì™„ë£Œ")

# PLIP ì„¤ì¹˜ (ê°œì„ ëœ ë°©ë²•)
print("   > PLIP ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q plip")
# PLIP ëŒ€ì²´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë„ ì„¤ì¹˜
os.system("pip install -q biopython ProLIF MDAnalysis")
print("   > PLIP ë° ëŒ€ì²´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ")

# ODDT ë° ê¸°íƒ€ í™”í•™ ì •ë³´í•™ ë„êµ¬ ì„¤ì¹˜
print("   > í™”í•™ ì •ë³´í•™ ë„êµ¬ (ODDT, scikit-learn) ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q oddt scikit-learn")
print("   > ODDT ì„¤ì¹˜ ì™„ë£Œ")

# Excel íŒŒì¼ ì¶œë ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
print("   > Excel íŒŒì¼ ì§€ì› ë¼ì´ë¸ŒëŸ¬ë¦¬ (openpyxl) ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q openpyxl")
print("   > openpyxl ì„¤ì¹˜ ì™„ë£Œ")

# AutoDock Vina ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜ (ê°œì„ ëœ ë²„ì „)
print("\n[4/5] AutoDock Vina ì„¤ì¹˜ ì¤‘...")

def setup_vina_robust():
    """ê°•í™”ëœ Vina ì„¤ì¹˜ í•¨ìˆ˜"""
    vina_dir = "vina_1.2.3_linux_x86_64"

    if not os.path.exists(vina_dir):
        print("   > Vina ë‹¤ìš´ë¡œë“œ ì¤‘...")
        # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ì‹œë„
        download_commands = [
            "wget -q https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip",
            "curl -L -o vina_1.2.3_linux_x86_64.zip https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip"
        ]

        for cmd in download_commands:
            if os.system(cmd) == 0:
                break
        else:
            print("   > Vina ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            return False

        # ì••ì¶• í•´ì œ
        os.system("unzip -q -o vina_1.2.3_linux_x86_64.zip")

        # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
        vina_executables = [
            f"{vina_dir}/vina",
            f"{vina_dir}/bin/vina",
        ]

        for executable in vina_executables:
            if os.path.exists(executable):
                os.chmod(executable, 0o755)
                print(f"   > ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬: {executable}")

    # Vina ì‹¤í–‰íŒŒì¼ ì°¾ê¸°
    possible_paths = [
        f"./{vina_dir}/vina",
        f"./{vina_dir}/bin/vina",
        "vina",
        "/usr/local/bin/vina"
    ]

    for path in possible_paths:
        if os.path.exists(path) and os.access(path, os.X_OK):
            print(f"   > Vina ì‹¤í–‰íŒŒì¼ ë°œê²¬: {path}")
            return os.path.abspath(path)

    print("   > Vina ì‹¤í–‰íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    return None

VINA_EXECUTABLE = setup_vina_robust()

# ì¶”ê°€ ë„êµ¬ ì„¤ì¹˜
print("\n[5/5] ì¶”ê°€ ë¶„ì ë„í‚¹ ë„êµ¬ ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q pymol-open-source > /dev/null 2>&1")
os.system("pip install -q meeko > /dev/null 2>&1")
print("   > ì¶”ê°€ ë„êµ¬ ì„¤ì¹˜ ì™„ë£Œ")

print("   > ì›¹ API í˜¸ì¶œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q requests beautifulsoup4")
print("   > requests ì„¤ì¹˜ ì™„ë£Œ")

print("\nëª¨ë“  ì„¤ì¹˜ ì™„ë£Œ!")
print("="*80)
print("âœ… STEP 0: í™˜ê²½ ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
print("="*80)



# ==============================================================================
# STEP 1: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ìœ„í•œ ë³€ìˆ˜ ì„¤ì • ë° í´ë” êµ¬ì¡° ìƒì„±
# ==============================================================================

print("\n" + "="*80)
print("STEP 1: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ìœ„í•œ ë³€ìˆ˜ ì„¤ì • ë° í´ë” êµ¬ì¡° ìƒì„±")
print("="*80)

# --- ì‚¬ìš©ì ì„¤ì • ì˜ì—­ ---

# 1. ìƒì„±í•  í©íƒ€ì´ë“œ í›„ë³´ì˜ ê°œìˆ˜
N_PEPTIDES = 10

# 2. íƒ€ê²Ÿ ë‹¨ë°±ì§ˆì˜ ì•„ë¯¸ë…¸ì‚° ì„œì—´ (FASTA í˜•ì‹, í•œ ì¤„ë¡œ ì…ë ¥)
TARGET_PROTEIN_SEQUENCE = "AFTVTVPKDLYVVEYGSNMTIECKFPVEKQLDLAALIVYWEMEDKNIIQFVHGEEDLKVQHSSYRQRARLLKDQLSLGNAALQITDVKLQDAGVYRCMISYGGADYKRITVKVNAPYNKINQRILVVDPVTSEHELTCQAEGYPKAEVIWTSSDHQVLSGKTTTTNSKREEKLFNVTSTLRINTTTNEIFYCTFRRLDPEENHTAELVIPELPLAHPPNERT" # PD-L1 ë‹¨ë°±ì§ˆ ì„œì—´

# 3. ìƒì„±í•  í©íƒ€ì´ë“œì˜ ê¸¸ì´
PEPTIDE_LENGTH = 4

# 4. ê²°ê³¼ í´ë”ì˜ ê¸°ë³¸ ì´ë¦„ ì ‘ë‘ì‚¬
BASE_FOLDER_PREFIX = "PDP"

# í•œêµ­ ì‹œê°„(KST)ì„ ê¸°ì¤€ìœ¼ë¡œ ë™ì  í´ë” ë° íŒŒì¼ ì´ë¦„ ìƒì„±
kst = pytz.timezone('Asia/Seoul')
now_kst = datetime.now(kst)
timestamp = now_kst.strftime("%Y%m%d_%H%M%S")

# ìµœì¢… ì‘ì—… í´ë”ëª…
JOB_NAME = f"{BASE_FOLDER_PREFIX}_{timestamp}"

# í•˜ìœ„ í´ë” êµ¬ì¡° ìƒì„±
FOLDERS = {
    'main': JOB_NAME,
    'fasta': os.path.join(JOB_NAME, 'fasta'),
    'pdb': os.path.join(JOB_NAME, 'pdb'),
    'results': os.path.join(JOB_NAME, 'results'),
    'colabfold_output': os.path.join(JOB_NAME, 'pdb', 'colabfold_output'),
    'temp': os.path.join(JOB_NAME, 'temp')
}

# ëª¨ë“  í´ë” ìƒì„±
for folder_name, folder_path in FOLDERS.items():
    os.makedirs(folder_path, exist_ok=True)
    print(f"âœ”ï¸ í´ë” ìƒì„±: {folder_path}")

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
PROTEIN_FASTA_PATH = os.path.join(FOLDERS['fasta'], "target_protein.fasta")
OUTPUT_FINAL_XLSX_PATH = os.path.join(FOLDERS['results'], f"final_peptide_ranking_{timestamp}.xlsx")
PDB_ZIP_PATH = os.path.join(FOLDERS['results'], f"peptide_structures_{timestamp}.zip")

# íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ FASTA íŒŒì¼ ìƒì„±
with open(PROTEIN_FASTA_PATH, "w") as f:
    f.write(f">target_protein\n{TARGET_PROTEIN_SEQUENCE}\n")

print(f"\nâœ”ï¸ ì‘ì—… í´ë”: {JOB_NAME}")
print(f"âœ”ï¸ ìƒì„±í•  í©íƒ€ì´ë“œ ê°œìˆ˜: {N_PEPTIDES}")
print(f"âœ”ï¸ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ ì„œì—´ ê¸¸ì´: {len(TARGET_PROTEIN_SEQUENCE)}")
print(f"âœ”ï¸ ìƒì„±í•  í©íƒ€ì´ë“œ ê¸¸ì´: {PEPTIDE_LENGTH}")
print(f"âœ”ï¸ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ FASTA íŒŒì¼: {PROTEIN_FASTA_PATH}")
print(f"âœ”ï¸ ìµœì¢… ê²°ê³¼ íŒŒì¼: {OUTPUT_FINAL_XLSX_PATH}")
print(f"âœ”ï¸ PDB ì••ì¶• íŒŒì¼: {PDB_ZIP_PATH}")
print("="*80)
print("âœ… STEP 1: ì„¤ì • ë° í´ë” êµ¬ì¡° ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
print("="*80)



# ==============================================================================
# STEP 2: PepMLM (ESM-2)ì„ ì´ìš©í•œ íƒ€ê²Ÿ íŠ¹ì´ì  í©íƒ€ì´ë“œ í›„ë³´ ìƒì„±
# ==============================================================================

print("\n" + "="*80)
print("STEP 2: PepMLM (ESM-2)ì„ ì´ìš©í•œ íƒ€ê²Ÿ íŠ¹ì´ì  í©íƒ€ì´ë“œ í›„ë³´ ìƒì„±")
print("="*80)

# ESM-2 ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model_name = "facebook/esm2_t12_35M_UR50D"
print(f"'{model_name}' ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤...")
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForMaskedLM.from_pretrained(model_name).to("cuda" if torch.cuda.is_available() else "cpu")
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# ìƒì„± íŒŒë¼ë¯¸í„°
temperature = 1.0
top_k = 50

# ëª¨ë¸ ì…ë ¥ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
formatted_target = " ".join(list(TARGET_PROTEIN_SEQUENCE))
mask_tokens = " ".join([tokenizer.mask_token] * PEPTIDE_LENGTH)
prompt = f"{tokenizer.cls_token} {formatted_target} {tokenizer.eos_token} {mask_tokens}"
input_ids = tokenizer(prompt, return_tensors="pt").input_ids

mask_token_indices = (input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]

peptides = []
peptide_fasta_paths = []

print("\ní©íƒ€ì´ë“œ ì„œì—´ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
with torch.no_grad():
    for i in range(N_PEPTIDES):
        current_ids = input_ids.clone().to(model.device)
        shuffled_mask_indices = mask_token_indices[torch.randperm(len(mask_token_indices))]

        for mask_idx in shuffled_mask_indices:
            outputs = model(input_ids=current_ids)
            logits = outputs.logits
            mask_logits = logits[0, mask_idx, :]
            filtered_logits = mask_logits / temperature
            effective_top_k = min(top_k, tokenizer.vocab_size)
            top_k_values, top_k_indices = torch.topk(filtered_logits, effective_top_k)
            filter_tensor = torch.full_like(filtered_logits, -float('Inf'))
            filter_tensor.scatter_(0, top_k_indices, top_k_values)
            probs = F.softmax(filter_tensor, dim=-1)
            predicted_token_id = torch.multinomial(probs, num_samples=1)
            current_ids[0, mask_idx] = predicted_token_id.item()

        generated_token_ids = current_ids[0, mask_token_indices]
        sequence_part = tokenizer.decode(generated_token_ids, skip_special_tokens=True)
        sequence = "".join(sequence_part.split())
        peptides.append(sequence)

        # FASTA íŒŒì¼ì„ fasta í´ë”ì— ì €ì¥
        fasta_path = os.path.join(FOLDERS['fasta'], f"peptide_{i}.fasta")
        with open(fasta_path, "w") as f:
            f.write(f">peptide_{i}\n{sequence}\n")
        peptide_fasta_paths.append(fasta_path)
        print(f"  [{i+1}/{N_PEPTIDES}] ìƒì„± ì™„ë£Œ: {sequence} (ê¸¸ì´: {len(sequence)})")

print("\n--- ìƒì„±ëœ í©íƒ€ì´ë“œ í›„ë³´ ëª©ë¡ ---")
for i, seq in enumerate(peptides):
    print(f"  - í›„ë³´ {i+1}: {seq}")
print("="*80)
print(f"âœ… STEP 2: ì´ {N_PEPTIDES}ê°œì˜ í©íƒ€ì´ë“œ í›„ë³´ ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
print("="*80)



# ==============================================================================
# STEP 3: ë‹¨ë°±ì§ˆ-í©íƒ€ì´ë“œ ë³µí•©ì²´ 3D êµ¬ì¡° ì˜ˆì¸¡ (ColabFold)
# ==============================================================================

print("\n" + "="*80)
print("STEP 3: ë‹¨ë°±ì§ˆ-í©íƒ€ì´ë“œ ë³µí•©ì²´ 3D êµ¬ì¡° ì˜ˆì¸¡ (ColabFold)")
print("="*80)

predicted_pdb_files = []

# ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³µí•©ì²´ CSV íŒŒì¼ ìƒì„±
print("\në°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³µí•©ì²´ CSV íŒŒì¼ ìƒì„± ì¤‘...")
batch_csv_path = os.path.join(FOLDERS['temp'], "batch_complexes.csv")
with open(batch_csv_path, "w") as f:
    f.write("id,sequence\n")
    for i in range(N_PEPTIDES):
        peptide_seq = peptides[i]
        complex_sequence = f"{TARGET_PROTEIN_SEQUENCE}:{peptide_seq}"
        f.write(f"complex_{i},{complex_sequence}\n")

print(f"âœ… ë°°ì¹˜ íŒŒì¼ ìƒì„± ì™„ë£Œ: {batch_csv_path}")

# ColabFold ë°°ì¹˜ ì‹¤í–‰ (ì¶œë ¥ì„ pdb/colabfold_output í´ë”ë¡œ)
output_dir = FOLDERS['colabfold_output']
log_file = os.path.join(output_dir, "colabfold_batch.log")

print(f"\nColabFold ë°°ì¹˜ ì‹¤í–‰ ì‹œì‘... (ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir})")
print("â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 10-30ë¶„ (ë³µí•©ì²´ ê°œìˆ˜ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤)")

# Colab í™˜ê²½ì— ìµœì í™”ëœ ì˜µì…˜ ì‚¬ìš©
colabfold_cmd = (f"colabfold_batch "
                f"--num-recycle 1 "
                f"--model-type alphafold2_multimer_v3 "
                f"--rank ptm "
                f"--max-msa 32:128 "
                f"--num-models 1 "
                f"--stop-at-score 0.5 "
                f"{batch_csv_path} {output_dir} > {log_file} 2>&1")

print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {colabfold_cmd}")
result = os.system(colabfold_cmd)

# ê²°ê³¼ í™•ì¸
print(f"\nColabFold ì‹¤í–‰ ì™„ë£Œ (ì¢…ë£Œ ì½”ë“œ: {result})")

# ìƒì„±ëœ PDB íŒŒì¼ ì°¾ê¸°
for i in range(N_PEPTIDES):
    pdb_pattern = os.path.join(output_dir, f"complex_{i}_unrelaxed_rank_001*.pdb")
    pdb_files = sorted(glob.glob(pdb_pattern))

    if pdb_files:
        predicted_pdb_files.append(pdb_files[0])
        print(f"  âœ… ë³µí•©ì²´ {i}: {os.path.basename(pdb_files[0])}")
    else:
        print(f"  âŒ ë³µí•©ì²´ {i}: PDB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

# ì‹¤íŒ¨ ì‹œ ë¡œê·¸ íŒŒì¼ ë‚´ìš© ì¶œë ¥
if len(predicted_pdb_files) < N_PEPTIDES and os.path.exists(log_file):
    print("\n" + "="*50)
    print("âš ï¸ ì¼ë¶€ ì˜ˆì¸¡ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. COLABFOLD ì‹¤í–‰ ë¡œê·¸:")
    print("="*50)
    with open(log_file, 'r') as f:
        print(f.read()[-2000:])
    print("="*50)

print("="*80)
print(f"âœ… STEP 3: ì´ {len(predicted_pdb_files)}ê°œì˜ 3D êµ¬ì¡° ì˜ˆì¸¡ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
print("="*80)


# ==============================================================================
# STEP 3.5: êµ¬ì¡° ì˜ˆì¸¡ ì‹ ë¢°ë„ ì ìˆ˜(pTM) í™•ì¸ ë° ì €ì¥
# ==============================================================================

print("\n" + "="*80)
print("STEP 3.5: êµ¬ì¡° ì˜ˆì¸¡ ì‹ ë¢°ë„ ì ìˆ˜(pTM) í™•ì¸")
print("="*80)

scores_info = []
ptm_scores_map = {}

# ë‹¤ì–‘í•œ ì ìˆ˜ íŒŒì¼ íŒ¨í„´ ì‹œë„
score_file_patterns = [
    os.path.join(output_dir, "*_scores.json"),
    os.path.join(output_dir, "complex_*_scores.json"),
    os.path.join(output_dir, "*_rank_001_*.json"),
    os.path.join(output_dir, "*_score*.json")
]

all_score_files = []
for pattern in score_file_patterns:
    files = sorted(glob.glob(pattern))
    all_score_files.extend(files)

# ì¤‘ë³µ ì œê±°
all_score_files = list(set(all_score_files))

print(f"ì°¾ì€ ì ìˆ˜ íŒŒì¼ë“¤: {len(all_score_files)}ê°œ")

if not all_score_files:
    print("âš ï¸ ColabFold ì ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pTM ì ìˆ˜ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
else:
    print(f"ì´ {len(all_score_files)}ê°œì˜ ì ìˆ˜ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤...")

    for score_file in all_score_files:
        try:
            basename = os.path.basename(score_file)
            match = re.search(r'complex_(\d+)', basename)
            if not match:
                continue

            peptide_index = int(match.group(1))
            with open(score_file, 'r') as f:
                data = json.load(f)

            ptm_score = data.get('ptm', data.get('iptm', 0.0))
            if isinstance(ptm_score, list):
                ptm_score = ptm_score[0] if ptm_score else 0.0

            if peptide_index < len(peptides):
                peptide_seq = peptides[peptide_index]
                ptm_scores_map[peptide_seq] = round(float(ptm_score), 3)
                print(f"  ë³µí•©ì²´ {peptide_index} ({peptide_seq}): pTM = {ptm_scores_map[peptide_seq]}")

        except Exception as e:
            print(f"ì˜¤ë¥˜: {score_file} ì²˜ë¦¬ ì¤‘ ë¬¸ì œ ë°œìƒ - {e}")
            continue

print("\n" + "="*80)
print("âœ… STEP 3.5: pTM ì ìˆ˜ í™•ì¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
print("="*80)



# ==============================================================================
# STEP 4: ê°œì„ ëœ ê²°í•©ë ¥ í‰ê°€ ë° ìµœì¢… ë­í‚¹ ê³„ì‚° (PRODIGY ê°œì„  ë²„ì „)
# ==============================================================================

print("\n" + "="*80)
print("STEP 4: ê°œì„ ëœ ê²°í•©ë ¥ í‰ê°€ ë° ìµœì¢… ë­í‚¹ ê³„ì‚° (PRODIGY ê°œì„ )")
print("="*80)

# ============= PRODIGY ëŒ€ì²´ í•¨ìˆ˜ ì¶”ê°€ =============

def estimate_binding_affinity_alternative(pdb_file):
    """PRODIGY ì›¹ì„œë²„ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ê²°í•© ì¹œí™”ë„ ì¶”ì • í•¨ìˆ˜"""
    try:
        chain_a_atoms, chain_b_atoms = [], []

        with open(pdb_file, 'r') as f:
            for line in f:
                if line.startswith(('ATOM', 'HETATM')):
                    chain = line[21]
                    atom_type = line[12:16].strip()
                    residue = line[17:20].strip()
                    element = line[76:78].strip() or atom_type[0]
                    coords = (
                        float(line[30:38]),
                        float(line[38:46]),
                        float(line[46:54]),
                        atom_type,
                        element,
                        residue
                    )

                    if chain == 'A':
                        chain_a_atoms.append(coords)
                    elif chain == 'B':
                        chain_b_atoms.append(coords)

        if not chain_a_atoms or not chain_b_atoms:
            return -5.0  # ê¸°ë³¸ê°’

        # ì ‘ì´‰ë©´ ë¶„ì„ ê¸°ë°˜ ì¹œí™”ë„ ì¶”ì •
        contact_pairs = 0
        hydrophobic_contacts = 0
        polar_contacts = 0
        aromatic_contacts = 0

        hydrophobic_residues = {'ALA', 'VAL', 'LEU', 'ILE', 'MET', 'PHE', 'TRP', 'PRO'}
        polar_residues = {'SER', 'THR', 'ASN', 'GLN', 'TYR', 'CYS'}
        aromatic_residues = {'PHE', 'TRP', 'TYR', 'HIS'}

        for bx, by, bz, b_atom, b_element, b_res in chain_b_atoms:
            for ax, ay, az, a_atom, a_element, a_res in chain_a_atoms:
                distance = np.sqrt((bx-ax)**2 + (by-ay)**2 + (bz-az)**2)

                if distance <= 4.5:  # ì ‘ì´‰ ê±°ë¦¬
                    contact_pairs += 1

                    # ìƒí˜¸ì‘ìš© íƒ€ì…ë³„ ê°€ì¤‘ì¹˜ ì ìš©
                    if a_res in hydrophobic_residues and b_res in hydrophobic_residues:
                        hydrophobic_contacts += 1
                    elif a_res in polar_residues or b_res in polar_residues:
                        polar_contacts += 1
                    elif a_res in aromatic_residues and b_res in aromatic_residues:
                        aromatic_contacts += 1

        # ê²½í—˜ì  ê³µì‹ì„ ì‚¬ìš©í•œ ì¹œí™”ë„ ì¶”ì • (ë” ìŒìˆ˜ê°€ ê°•í•œ ê²°í•©)
        if contact_pairs == 0:
            return -2.0

        base_affinity = -3.0  # ê¸°ë³¸ ì¹œí™”ë„
        hydrophobic_contribution = hydrophobic_contacts * -0.3
        polar_contribution = polar_contacts * -0.4
        aromatic_contribution = aromatic_contacts * -0.5
        contact_penalty = max(0, (contact_pairs - 50) * 0.1)  # ë„ˆë¬´ ë§ì€ ì ‘ì´‰ì€ ë¶ˆë¦¬

        estimated_affinity = base_affinity + hydrophobic_contribution + polar_contribution + aromatic_contribution - contact_penalty

        # -15 ~ -1 ë²”ìœ„ë¡œ ì œí•œ
        return max(-15.0, min(-1.0, estimated_affinity))

    except Exception as e:
        print(f"       ëŒ€ì²´ ì¹œí™”ë„ ì¶”ì • ì˜¤ë¥˜: {e}")
        return -5.0


def predict_binding_affinity_with_prodigy(pdb_file_path, chain_a='A', chain_b='B', max_retries=2):
    """ê°œì„ ëœ PRODIGY ì›¹ ì„œë²„ í˜¸ì¶œ í•¨ìˆ˜ (ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ í•¨ìˆ˜ ì‚¬ìš©)"""
    url = "https://bianca.science.uu.nl/prodigy/"

    print(f"       PRODIGY ì›¹ì„œë²„ ì‹œë„ ì¤‘...")

    for attempt in range(max_retries):
        try:
            with open(pdb_file_path, 'rb') as f:
                files = {'file': (os.path.basename(pdb_file_path), f, 'application/octet-stream')}
                data = {
                    'chain1': chain_a,
                    'chain2': chain_b,
                    'temperature': 25.0,
                    'contact_list': 'true'
                }

                # ë” ì§§ì€ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë¹ ë¥¸ ì‹¤íŒ¨ ì²˜ë¦¬
                response = requests.post(url, files=files, data=data, timeout=30)

            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')

                # ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ ê²°ê³¼ íŒŒì‹± ì‹œë„
                patterns_to_try = [
                    r'Predicted binding affinity.*?(-?\d+\.?\d*)',
                    r'Î”G.*?(-?\d+\.?\d*)',
                    r'(-?\d+\.?\d+)\s*kcal/mol'
                ]

                for pattern in patterns_to_try:
                    matches = re.findall(pattern, response.text, re.IGNORECASE)
                    if matches:
                        try:
                            affinity_value = float(matches[0])
                            print(f"       PRODIGY ì„±ê³µ: {affinity_value:.3f} kcal/mol")
                            return affinity_value
                        except ValueError:
                            continue

                # HTML íŒŒì‹± ì‹œë„
                affinity_header = soup.find(string=re.compile(r'Predicted binding affinity', re.IGNORECASE))
                if affinity_header:
                    affinity_value_tag = affinity_header.find_next_sibling('p')
                    if affinity_value_tag:
                        try:
                            affinity_value = float(affinity_value_tag.text.strip())
                            print(f"       PRODIGY ì„±ê³µ (HTML): {affinity_value:.3f} kcal/mol")
                            return affinity_value
                        except ValueError:
                            pass

                print(f"       PRODIGY ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries})")

            else:
                print(f"       PRODIGY ì„œë²„ ì—ëŸ¬: ìƒíƒœ ì½”ë“œ {response.status_code} (ì‹œë„ {attempt + 1}/{max_retries})")

        except requests.exceptions.Timeout:
            print(f"       PRODIGY íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/{max_retries})")
        except requests.exceptions.RequestException as e:
            print(f"       PRODIGY ìš”ì²­ ì—ëŸ¬ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")

        if attempt < max_retries - 1:
            print(f"       {3}ì´ˆ í›„ ì¬ì‹œë„...")
            time.sleep(3)

    # ì›¹ì„œë²„ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ í•¨ìˆ˜ ì‚¬ìš©
    print(f"       PRODIGY ì›¹ì„œë²„ ì‹¤íŒ¨. ëŒ€ì²´ ì¶”ì • í•¨ìˆ˜ ì‚¬ìš©.")
    alternative_score = estimate_binding_affinity_alternative(pdb_file_path)
    print(f"       ëŒ€ì²´ ì¶”ì • ê²°ê³¼: {alternative_score:.3f} kcal/mol")
    return alternative_score


def calculate_interactions_advanced(pdb_file):
    """ê°œì„ ëœ ë¶„ìê°„ ìƒí˜¸ì‘ìš© ê³„ì‚°"""
    try:
        chain_a_atoms, chain_b_atoms = [], []

        with open(pdb_file, 'r') as f:
            for line in f:
                if line.startswith(('ATOM', 'HETATM')):
                    chain = line[21]
                    atom_type = line[12:16].strip()
                    element = line[76:78].strip() or atom_type[0]
                    coords = (
                        float(line[30:38]),
                        float(line[38:46]),
                        float(line[46:54]),
                        atom_type,
                        element
                    )

                    if chain == 'A':
                        chain_a_atoms.append(coords)
                    elif chain == 'B':
                        chain_b_atoms.append(coords)

        if not chain_a_atoms or not chain_b_atoms:
            return {'h_bonds': 0, 'hydrophobic': 0, 'electrostatic': 0, 'total': 0}

        h_bonds = 0
        hydrophobic = 0
        electrostatic = 0

        for bx, by, bz, b_atom, b_element in chain_b_atoms:
            for ax, ay, az, a_atom, a_element in chain_a_atoms:
                distance = np.sqrt((bx-ax)**2 + (by-ay)**2 + (bz-az)**2)

                # ìˆ˜ì†Œê²°í•© (N, O ì›ìê°„ 3.5Ã… ì´ë‚´)
                if distance <= 3.5:
                    if ((a_element in ['N', 'O'] and b_element in ['N', 'O']) or
                        ('N' in a_atom and 'O' in b_atom) or
                        ('O' in a_atom and 'N' in b_atom)):
                        h_bonds += 1

                # ì†Œìˆ˜ì„± ìƒí˜¸ì‘ìš© (íƒ„ì†Œ ì›ìê°„ 4.5Ã… ì´ë‚´)
                if distance <= 4.5:
                    if a_element == 'C' and b_element == 'C':
                        hydrophobic += 1

                # ì •ì „ê¸°ì  ìƒí˜¸ì‘ìš© (í•˜ì „ ì›ìê°„ 5.0Ã… ì´ë‚´)
                if distance <= 5.0:
                    charged_atoms_pos = ['LYS', 'ARG', 'HIS']  # ì–‘ì „í•˜
                    charged_atoms_neg = ['ASP', 'GLU']         # ìŒì „í•˜

                    a_residue = a_atom[:3] if len(a_atom) >= 3 else ''
                    b_residue = b_atom[:3] if len(b_atom) >= 3 else ''

                    if ((a_residue in charged_atoms_pos and b_residue in charged_atoms_neg) or
                        (a_residue in charged_atoms_neg and b_residue in charged_atoms_pos)):
                        electrostatic += 1

        total_interactions = h_bonds + hydrophobic + electrostatic
        return {
            'h_bonds': h_bonds,
            'hydrophobic': hydrophobic,
            'electrostatic': electrostatic,
            'total': total_interactions
        }

    except Exception as e:
        print(f"       ìƒí˜¸ì‘ìš© ê³„ì‚° ì˜¤ë¥˜: {e}")
        return {'h_bonds': 0, 'hydrophobic': 0, 'electrostatic': 0, 'total': 0}

def split_pdb_and_get_center(pdb_file, base_name):
    """PDB íŒŒì¼ì„ Receptor(Chain A)ì™€ Ligand(Chain B)ë¡œ ë¶„ë¦¬í•˜ê³ , Ligandì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    receptor_path = os.path.join(FOLDERS['temp'], f"{base_name}_receptor.pdb")
    ligand_path = os.path.join(FOLDERS['temp'], f"{base_name}_ligand.pdb")

    chain_b_coords = []
    with open(pdb_file, 'r') as f_in, open(receptor_path, 'w') as f_receptor, open(ligand_path, 'w') as f_ligand:
        for line in f_in:
            if line.startswith(('ATOM', 'HETATM')):
                chain_id = line[21]
                if chain_id == 'A':
                    f_receptor.write(line)
                elif chain_id == 'B':
                    f_ligand.write(line)
                    x = float(line[30:38])
                    y = float(line[38:46])
                    z = float(line[46:54])
                    chain_b_coords.append([x, y, z])

    center = [0.0, 0.0, 0.0]
    if chain_b_coords:
        center = np.mean(chain_b_coords, axis=0).tolist()

    return receptor_path, ligand_path, center

def run_vina_docking(receptor_pdb, ligand_pdb, center, vina_executable):
    """AutoDock Vinaë¥¼ ì‚¬ìš©í•˜ì—¬ ë„í‚¹ì„ ìˆ˜í–‰í•˜ê³  ê²°í•© ì—ë„ˆì§€ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # Meekoë¥¼ ì‚¬ìš©í•˜ì—¬ PDBQT íŒŒì¼ ì¤€ë¹„
        receptor_pdbqt = receptor_pdb.replace('.pdb', '.pdbqt')
        ligand_pdbqt = ligand_pdb.replace('.pdb', '.pdbqt')

        # -W: ìˆ˜ì†Œ ì›ì ìœ ì§€, --rigid: ë¦¬ê°„ë“œë¥¼ rigidë¡œ ì²˜ë¦¬ (í©íƒ€ì´ë“œì— ì í•©)
        os.system(f"mk_prepare_receptor -i {receptor_pdb} -o {receptor_pdbqt} > /dev/null 2>&1")
        os.system(f"mk_prepare_ligand -i {ligand_pdb} -o {ligand_pdbqt} --rigid > /dev/null 2>&1")

        if not os.path.exists(receptor_pdbqt) or not os.path.exists(ligand_pdbqt):
            print("       PDBQT íŒŒì¼ ìƒì„± ì‹¤íŒ¨. OpenBabelë¡œ ëŒ€ì²´ ì‹œë„.")
            os.system(f"obabel {receptor_pdb} -O {receptor_pdbqt} -xr > /dev/null 2>&1")
            os.system(f"obabel {ligand_pdb} -O {ligand_pdbqt} > /dev/null 2>&1")
            if not os.path.exists(receptor_pdbqt) or not os.path.exists(ligand_pdbqt):
                 print("       ëŒ€ì²´ ë°©ë²•ë„ ì‹¤íŒ¨. Vina ë„í‚¹ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                 return 0.0

        # Vina ì‹¤í–‰
        output_pdbqt = ligand_pdb.replace('.pdb', '_vina_out.pdbqt')
        log_file = ligand_pdb.replace('.pdb', '_vina.log')

        cmd = [
            vina_executable,
            '--receptor', receptor_pdbqt,
            '--ligand', ligand_pdbqt,
            '--center_x', str(center[0]),
            '--center_y', str(center[1]),
            '--center_z', str(center[2]),
            '--size_x', '30', # í©íƒ€ì´ë“œ í¬ê¸°ì— ë§ê²Œ ë°•ìŠ¤ í¬ê¸° ì¡°ì •
            '--size_y', '30',
            '--size_z', '30',
            '--exhaustiveness', '16', # ì •í™•ë„ í–¥ìƒ
            '--out', output_pdbqt,
            '--log', log_file
        ]

        subprocess.run(cmd, check=True, capture_output=True, text=True)

        # ê²°ê³¼ íŒŒì‹±
        with open(log_file, 'r') as f:
            for line in f:
                if line.strip().startswith('1'):
                    parts = line.split()
                    return float(parts[1])
        return 0.0
    except Exception as e:
        print(f"       Vina ë„í‚¹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 0.0


# ë©”ì¸ í‰ê°€ ë£¨í”„
results = []

if not predicted_pdb_files:
    print("í‰ê°€í•  PDB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    print(f"ì´ {len(predicted_pdb_files)}ê°œì˜ êµ¬ì¡°ì— ëŒ€í•´ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    for idx, pred_pdb in enumerate(predicted_pdb_files):
        print(f"\n  í‰ê°€ ì¤‘ ({idx+1}/{len(predicted_pdb_files)}): {os.path.basename(pred_pdb)}")

        base_name = f"eval_{idx}"

        if not os.path.exists(pred_pdb) or os.path.getsize(pred_pdb) == 0:
            print("    -> PDB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            continue

        # í©íƒ€ì´ë“œ ì„œì—´ í™•ì¸
        try:
            peptide_index = int(re.search(r'complex_(\d+)', os.path.basename(pred_pdb)).group(1))
            peptide_seq = peptides[peptide_index]
        except (AttributeError, IndexError, ValueError):
            peptide_seq = f"Unknown_{idx}"

        print("    -> PRODIGY ê²°í•© ì¹œí™”ë„ ì˜ˆì¸¡ ì¤‘...")
        prodigy_score = predict_binding_affinity_with_prodigy(pred_pdb, chain_a='A', chain_b='B')

        # PDB íŒŒì¼ ë¶„ë¦¬
        receptor_pdb, ligand_pdb, center = split_pdb_and_get_center(pred_pdb, base_name)
        print(f"    -> PDB ë¶„ë¦¬ ì™„ë£Œ: Receptor={os.path.basename(receptor_pdb)}, Ligand={os.path.basename(ligand_pdb)}")

        # Vina ë„í‚¹ ì ìˆ˜ ê³„ì‚°
        vina_score = 0.0
        if VINA_EXECUTABLE and os.path.exists(VINA_EXECUTABLE) and center:
            print("    -> Vina ë„í‚¹ ì‹¤í–‰ ì¤‘...")
            vina_score = run_vina_docking(receptor_pdb, ligand_pdb, center, VINA_EXECUTABLE)
            print(f"       Vina ì ìˆ˜: {vina_score:.3f} kcal/mol")
        else:
            print("    -> Vinaë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê°„ë‹¨í•œ ì¶”ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
            # ê°„ë‹¨í•œ ê±°ë¦¬ ê¸°ë°˜ ì¶”ì • ë¡œì§
            try:
                with open(receptor_pdb, 'r') as f:
                    receptor_lines = [line for line in f if line.startswith(('ATOM', 'HETATM'))]
                with open(ligand_pdb, 'r') as f:
                    ligand_lines = [line for line in f if line.startswith(('ATOM', 'HETATM'))]

                if receptor_lines and ligand_lines:
                    min_dist = float('inf')
                    # ê³„ì‚°ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ì¼ë¶€ ì›ìë§Œ ìƒ˜í”Œë§
                    for r_line in receptor_lines[::10]: # 10ê°œ ì¤‘ 1ê°œ
                        rx = float(r_line[30:38])
                        ry = float(r_line[38:46])
                        rz = float(r_line[46:54])
                        for l_line in ligand_lines:
                            lx = float(l_line[30:38])
                            ly = float(l_line[38:46])
                            lz = float(l_line[46:54])
                            dist = np.sqrt((rx-lx)**2 + (ry-ly)**2 + (rz-lz)**2)
                            min_dist = min(min_dist, dist)

                    if min_dist < float('inf'):
                        # ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ì ìˆ˜ê°€ ë‚®ì•„ì§(ì•ˆì •)
                        vina_score = max(-1.0 * (15.0 / max(min_dist, 0.1)), -15.0)

            except Exception as e:
                print(f"       ê°„ë‹¨í•œ ì¶”ì • ì‹¤íŒ¨: {e}")
                vina_score = -5.0

        # ìƒí˜¸ì‘ìš© ë¶„ì„
        print("    -> ë¶„ìê°„ ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...")
        interactions = calculate_interactions_advanced(pred_pdb)
        print(f"       ìƒí˜¸ì‘ìš©: H-bonds={interactions['h_bonds']}, "
              f"Hydrophobic={interactions['hydrophobic']}, "
              f"Electrostatic={interactions['electrostatic']}")

        print("    -> ìµœì¢… ì ìˆ˜ ê³„ì‚° ì¤‘...")

        # ê°œì„ ëœ ê°€ì¤‘ì¹˜ ì ìš©
        final_score = (
            abs(vina_score) * 0.25 +           # Vina ì ìˆ˜ (ê°€ì¤‘ì¹˜ ê°ì†Œ)
            abs(prodigy_score) * 0.5 +         # PRODIGY (ë†’ì€ ê°€ì¤‘ì¹˜, ì ˆëŒ€ê°’ ì‚¬ìš©)
            interactions['total'] * 0.15 +     # ìƒí˜¸ì‘ìš© ìˆ˜
            ptm_scores_map.get(peptide_seq, 0.0) * 10 * 0.1  # pTM ì ìˆ˜(0-1 ìŠ¤ì¼€ì¼)ë¥¼ 10ì  ë§Œì ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜ì˜
        )

        # ê²°ê³¼ ì €ì¥ (PRODIGY ì ìˆ˜ ì¶”ê°€)
        results.append({
            "Peptide Sequence": peptide_seq,
            "pTM Score": ptm_scores_map.get(peptide_seq, 0.0),
            "Vina Score (kcal/mol)": round(vina_score, 3),
            "PRODIGY Score (kcal/mol)": round(prodigy_score, 3),
            "H-bonds": interactions['h_bonds'],
            "Hydrophobic": interactions['hydrophobic'],
            "Electrostatic": interactions['electrostatic'],
            "Total Interactions": interactions['total'],
            "Final Score": round(final_score, 3),
            "Source PDB": os.path.basename(pred_pdb)
        })

        print(f"    -> í‰ê°€ ì™„ë£Œ: Final Score = {final_score:.3f}")

print("="*80)
print("âœ… STEP 4: ëª¨ë“  êµ¬ì¡°ì— ëŒ€í•œ í‰ê°€ ë° ì ìˆ˜ ê³„ì‚°ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
print("="*80)



# ==============================================================================
# STEP 5: PDB íŒŒì¼ ì••ì¶• ë° ìµœì¢… ê²°ê³¼ ì €ì¥
# ==============================================================================

print("\n" + "="*80)
print("STEP 5: PDB íŒŒì¼ ì••ì¶• ë° ìµœì¢… ê²°ê³¼ ì €ì¥")
print("="*80)

# PDB íŒŒì¼ë“¤ì„ ZIPìœ¼ë¡œ ì••ì¶•
print("\nğŸ“¦ PDB íŒŒì¼ë“¤ì„ ì••ì¶•í•˜ëŠ” ì¤‘...")
try:
    with zipfile.ZipFile(PDB_ZIP_PATH, 'w', zipfile.ZIP_DEFLATED) as zipf:
        # ColabFold ì¶œë ¥ í´ë”ì˜ ëª¨ë“  PDB íŒŒì¼ ì¶”ê°€
        pdb_files_added = 0
        for root, dirs, files in os.walk(FOLDERS['colabfold_output']):
            for file in files:
                if file.endswith('.pdb'):
                    file_path = os.path.join(root, file)
                    # ZIP ë‚´ì—ì„œì˜ ê²½ë¡œëª…ì„ ìƒëŒ€ê²½ë¡œë¡œ ì„¤ì •
                    arc_name = os.path.relpath(file_path, FOLDERS['colabfold_output'])
                    zipf.write(file_path, arc_name)
                    pdb_files_added += 1
                    print(f"  âœ… ì¶”ê°€ë¨: {file}")

        # # JSON ì ìˆ˜ íŒŒì¼ë“¤ë„ í•¨ê»˜ ì••ì¶•
        # for root, dirs, files in os.walk(FOLDERS['colabfold_output']):
        #     for file in files:
        #         if file.endswith('.json'):
        #             file_path = os.path.join(root, file)
        #             arc_name = os.path.relpath(file_path, FOLDERS['colabfold_output'])
        #             zipf.write(file_path, arc_name)
        #             print(f"  âœ… ì ìˆ˜ íŒŒì¼ ì¶”ê°€: {file}")

    print(f"ğŸ“¦ ì••ì¶• ì™„ë£Œ: {pdb_files_added}ê°œì˜ PDB íŒŒì¼ì´ {PDB_ZIP_PATH}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"âŒ ì••ì¶• ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ìµœì¢… ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
if results:
    df = pd.DataFrame(results)

    # ìµœì¢… ê²°ê³¼ì— í‘œì‹œí•  ì»¬ëŸ¼ ìˆœì„œ (PRODIGY ì¶”ê°€)
    column_order = [
        "Peptide Sequence", "Final Score", "pTM Score",
        "PRODIGY Score (kcal/mol)",
        "Vina Score (kcal/mol)",
        "Total Interactions",
        "H-bonds", "Hydrophobic", "Electrostatic",
        "Source PDB"
    ]

    # DataFrame ì •ë ¬ ë° ì¬ë°°ì¹˜
    df_sorted = df.sort_values("Final Score", ascending=False).reset_index(drop=True)
    df_final = df_sorted[[col for col in column_order if col in df_sorted.columns]]

    # Excel íŒŒì¼ë¡œ ì €ì¥ (results í´ë”ì—)
    df_final.to_excel(OUTPUT_FINAL_XLSX_PATH, index=False)

    print("\nğŸ† ìµœì¢… í©íƒ€ì´ë“œ í›„ë³´ ë­í‚¹:")
    display(df_final)

    print(f"\nğŸ’¾ ì „ì²´ ê²°ê³¼ê°€ Excel íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {OUTPUT_FINAL_XLSX_PATH}")
    print("   (Colab ì™¼ìª½ì˜ íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")

    # ìš”ì•½ ì •ë³´ ì¶œë ¥
    print("\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
    print(f"   â€¢ ì´ í‰ê°€ëœ í©íƒ€ì´ë“œ: {len(results)}ê°œ")
    print(f"   â€¢ ìµœê³  ì ìˆ˜ í©íƒ€ì´ë“œ: {df_final.iloc[0]['Peptide Sequence']} (ì ìˆ˜: {df_final.iloc[0]['Final Score']:.3f})")
    print(f"   â€¢ í‰ê·  pTM ì ìˆ˜: {df_final['pTM Score'].mean():.3f}")
    print(f"   â€¢ í‰ê·  PRODIGY ì ìˆ˜: {df_final['PRODIGY Score (kcal/mol)'].mean():.3f}")
    print(f"   â€¢ í‰ê·  ìƒí˜¸ì‘ìš© ìˆ˜: {df_final['Total Interactions'].mean():.1f}")

    # í´ë” êµ¬ì¡° ìš”ì•½
    print("\nğŸ“ ìƒì„±ëœ íŒŒì¼ êµ¬ì¡°:")
    print(f"   â€¢ ë©”ì¸ í´ë”: {JOB_NAME}/")
    print(f"     â”œâ”€â”€ fasta/           : í©íƒ€ì´ë“œ ë° íƒ€ê²Ÿ FASTA íŒŒì¼ë“¤")
    print(f"     â”œâ”€â”€ pdb/             : êµ¬ì¡° ì˜ˆì¸¡ ê²°ê³¼")
    print(f"     â”‚   â””â”€â”€ colabfold_output/ : ColabFold ì›ë³¸ ì¶œë ¥")
    print(f"     â”œâ”€â”€ results/         : ìµœì¢… ê²°ê³¼ íŒŒì¼ë“¤")
    print(f"     â”‚   â”œâ”€â”€ {os.path.basename(OUTPUT_FINAL_XLSX_PATH)}")
    print(f"     â”‚   â””â”€â”€ {os.path.basename(PDB_ZIP_PATH)}")
    print(f"     â””â”€â”€ temp/            : ì„ì‹œ ì²˜ë¦¬ íŒŒì¼ë“¤")

else:
    print("\nâŒ ìµœì¢… ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ì¤‘ê°„ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

print("="*80)
print("ğŸ‰ ëª¨ë“  íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print("="*80)

# ì„¤ì¹˜ëœ ë„êµ¬ë“¤ì˜ ìƒíƒœ ìš”ì•½
print("\nğŸ“‹ ì„¤ì¹˜ëœ ë„êµ¬ ìƒíƒœ:")
print(f"   â€¢ ColabFold: âœ… ì„¤ì¹˜ë¨")
print(f"   â€¢ ESM-2 (Transformers): âœ… ì„¤ì¹˜ë¨")
print(f"   â€¢ PRODIGY: âœ… ì›¹ API + ëŒ€ì²´ í•¨ìˆ˜")
print(f"   â€¢ OpenBabel: âœ… ì„¤ì¹˜ë¨")
print(f"   â€¢ AutoDock Vina: {'âœ… ì„¤ì¹˜ë¨' if VINA_EXECUTABLE else 'âš ï¸ ê°„ë‹¨í•œ ì¶”ì • ì‚¬ìš©'}")
print(f"   â€¢ PLIP ëŒ€ì²´ í•¨ìˆ˜: âœ… êµ¬í˜„ë¨")
print("="*80)

# ì´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚° ë° ì¶œë ¥
pipeline_end_time = time.time()
total_duration = pipeline_end_time - pipeline_start_time

# ì‹œ:ë¶„:ì´ˆë¡œ ë³€í™˜
hours = int(total_duration // 3600)
minutes = int((total_duration % 3600) // 60)
seconds = int(total_duration % 60)

# ì¡°ê±´ì— ë”°ë¼ ì¶œë ¥ í˜•ì‹ ë‹¬ë¦¬í•˜ê¸°
if hours > 0:
    print(f"\nâ±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„ {seconds}ì´ˆ")
else:
    print(f"\nâ±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {minutes}ë¶„ {seconds}ì´ˆ")

print("="*80)
