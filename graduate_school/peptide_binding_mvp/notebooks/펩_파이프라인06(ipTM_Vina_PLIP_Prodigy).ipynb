{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlmbP7btofks",
        "outputId": "c32dd17f-95a2-48a9-beee-0d32920a1498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "STEP 0: 환경 설정 및 라이브러리 설치 (중복 방지)\n",
            "================================================================================\n",
            "✅ 이미 설치된 환경이 감지되었습니다. 설치를 건너뜁니다.\n",
            "\n",
            "# 설치된 도구들의 상태 요약\n",
            "   • AutoDock Vina: ⚠️ 간단한 추정 사용\n",
            "   • PLIP: ⚠️ 대체 계산 사용\n",
            "   • PRODIGY(Web): 🌐 웹 시도/실패 시 대체 점수\n",
            "================================================================================\n",
            "\n",
            "STEP 1: 변수 설정 및 폴더 구조 생성\n",
            "================================================================================\n",
            "✅ 프로젝트 폴더 구조 생성 완료: PDP_20250916_110743\n",
            "📊 설정 요약:\n",
            "   • 작업 폴더: PDP_20250916_110743\n",
            "   • 펩타이드 개수: 10\n",
            "   • 펩타이드 길이: 4\n",
            "   • 타겟 서열 길이: 222\n",
            "================================================================================\n",
            "\n",
            "STEP 2: ESM-2 펩타이드 생성\n",
            "================================================================================\n",
            "ESM-2 모델 로딩: facebook/esm2_t12_35M_UR50D\n",
            "\n",
            "🧬 펩타이드 생성 중...\n",
            "  [ 1/10] VAIH\n",
            "  [ 2/10] EQIL\n",
            "  [ 3/10] KATT\n",
            "  [ 4/10] DGWY\n",
            "  [ 5/10] IHNK\n",
            "  [ 6/10] RCSC\n",
            "  [ 7/10] PTLT\n",
            "  [ 8/10] VSPG\n",
            "  [ 9/10] VATD\n",
            "  [10/10] CNLL\n",
            "\n",
            "✅ 10개 펩타이드 생성 완료\n",
            "================================================================================\n",
            "\n",
            "STEP 3: ColabFold 3D 구조 예측\n",
            "================================================================================\n",
            "ColabFold 실행 중... (예상 시간: 10-30분)\n",
            "  ✅ 복합체 0: complex_0_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 1: complex_1_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 2: complex_2_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 3: complex_3_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 4: complex_4_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 5: complex_5_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 6: complex_6_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 7: complex_7_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 8: complex_8_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 9: complex_9_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "\n",
            "✅ 10개 구조 예측 완료\n",
            "================================================================================\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_000/ranking_debug.json (from: no source → zeros)\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_001/ranking_debug.json (from: no source → zeros)\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_002/ranking_debug.json (from: no source → zeros)\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_003/ranking_debug.json (from: no source → zeros)\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_004/ranking_debug.json (from: no source → zeros)\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_005/ranking_debug.json (from: no source → zeros)\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_006/ranking_debug.json (from: no source → zeros)\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_007/ranking_debug.json (from: no source → zeros)\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_008/ranking_debug.json (from: no source → zeros)\n",
            "🆕 ranking_debug 생성: PDP_20250916_110743/pdb/complex_009/ranking_debug.json (from: no source → zeros)\n",
            "STEP 3.5 완료 → 생성 10개, 재사용 0개 (검색 루트: PDP_20250916_110743/pdb)\n",
            "\n",
            "STEP 3: ColabFold 3D 구조 예측\n",
            "================================================================================\n",
            "ColabFold 실행 중... (예상 시간: 10-30분)\n",
            "  ✅ 복합체 0: complex_0_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 1: complex_1_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 2: complex_2_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 3: complex_3_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 4: complex_4_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 5: complex_5_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 6: complex_6_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 7: complex_7_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 8: complex_8_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  ✅ 복합체 9: complex_9_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "\n",
            "✅ 10개 구조 예측 완료\n",
            "================================================================================\n",
            "STEP 3.5 완료 → 생성 0개, 재사용 10개 (검색 루트: PDP_20250916_110743/pdb)\n",
            "\n",
            "STEP 4: pTM/ipTM 점수 추출\n",
            "================================================================================\n",
            "검색 루트: PDP_20250916_110743/pdb\n",
            "🔎 확인: complex_* 디렉터리 30개, 루트 점수 JSON 10개\n",
            "✅ pTM/ipTM 점수 추출 완료: 10개\n",
            "================================================================================\n",
            "\n",
            "STEP 6: 결합력 평가 및 최종 랭킹\n",
            "================================================================================\n",
            "\n",
            "평가 중 (1/10): complex_0_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 147339 bytes\n",
            "    -> 펩타이드: VAIH\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 30\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -10.396 kcal/mol\n",
            "    -> PRODIGY 결과: -10.396 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 7, Hydrophobic: 8, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 9.698\n",
            "\n",
            "평가 중 (2/10): complex_1_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 147663 bytes\n",
            "    -> 펩타이드: EQIL\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 34\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -20.000 kcal/mol\n",
            "    -> PRODIGY 결과: -20.000 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 27, Hydrophobic: 121, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 54.400\n",
            "\n",
            "평가 중 (3/10): complex_2_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 147177 bytes\n",
            "    -> 펩타이드: KATT\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 28\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -20.000 kcal/mol\n",
            "    -> PRODIGY 결과: -20.000 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 18, Hydrophobic: 151, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 60.700\n",
            "\n",
            "평가 중 (4/10): complex_3_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 147987 bytes\n",
            "    -> 펩타이드: DGWY\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 38\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -11.226 kcal/mol\n",
            "    -> PRODIGY 결과: -11.226 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 3, Hydrophobic: 52, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 22.113\n",
            "\n",
            "평가 중 (5/10): complex_4_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 147744 bytes\n",
            "    -> 펩타이드: IHNK\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 35\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -14.214 kcal/mol\n",
            "    -> PRODIGY 결과: -14.214 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 6, Hydrophobic: 34, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 19.107\n",
            "\n",
            "평가 중 (6/10): complex_5_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 147258 bytes\n",
            "    -> 펩타이드: RCSC\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 29\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -15.160 kcal/mol\n",
            "    -> PRODIGY 결과: -15.160 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 19, Hydrophobic: 79, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 36.980\n",
            "\n",
            "평가 중 (7/10): complex_6_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 147258 bytes\n",
            "    -> 펩타이드: PTLT\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 29\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -11.902 kcal/mol\n",
            "    -> PRODIGY 결과: -11.902 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 1, Hydrophobic: 18, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 11.651\n",
            "\n",
            "평가 중 (8/10): complex_7_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 146853 bytes\n",
            "    -> 펩타이드: VSPG\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 24\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -20.000 kcal/mol\n",
            "    -> PRODIGY 결과: -20.000 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 30, Hydrophobic: 166, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 68.800\n",
            "\n",
            "평가 중 (9/10): complex_8_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 147096 bytes\n",
            "    -> 펩타이드: VATD\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 27\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -9.242 kcal/mol\n",
            "    -> PRODIGY 결과: -9.242 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 10, Hydrophobic: 13, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 11.521\n",
            "\n",
            "평가 중 (10/10): complex_9_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB 파일 크기: 147339 bytes\n",
            "    -> 펩타이드: CNLL\n",
            "    -> Chain A 원자수: 1784\n",
            "    -> Chain B 원자수: 30\n",
            "    -> PRODIGY 분석 시작...\n",
            "       → PRODIGY 대체 점수 사용: -10.374 kcal/mol\n",
            "    -> PRODIGY 결과: -10.374 kcal/mol\n",
            "    -> 상호작용 분석 중...\n",
            "    -> PLIP 미설치/미사용, 대체 계산 사용\n",
            "    -> H-bonds: 4, Hydrophobic: 6, Electrostatic: 0\n",
            "    -> pTM 점수: 0.0\n",
            "    -> 최종 점수: 8.187\n",
            "\n",
            "✅ 10개 구조 평가 완료\n",
            "================================================================================\n",
            "\n",
            "STEP 7: 최종 결과 정리 및 저장\n",
            "================================================================================\n",
            "🏆 최종 펩타이드 랭킹:\n",
            "====================================================================================================\n",
            "순위   펩타이드         종합점수     pTM    PRODIGY  상호작용    \n",
            "====================================================================================================\n",
            "1    VSPG         68.800   0.000  -20.000  196     \n",
            "2    KATT         60.700   0.000  -20.000  169     \n",
            "3    EQIL         54.400   0.000  -20.000  148     \n",
            "4    RCSC         36.980   0.000  -15.160  98      \n",
            "5    DGWY         22.113   0.000  -11.226  55      \n",
            "6    IHNK         19.107   0.000  -14.214  40      \n",
            "7    PTLT         11.651   0.000  -11.902  19      \n",
            "8    VATD         11.521   0.000  -9.242   23      \n",
            "9    VAIH         9.698    0.000  -10.396  15      \n",
            "10   CNLL         8.187    0.000  -10.374  10      \n",
            "\n",
            "💾 전체 결과 저장: PDP_20250916_110743/results/final_ranking_20250916_110743.xlsx\n",
            "\n",
            "⏱️  총 실행 시간: 34분 40초\n",
            "================================================================================\n",
            "🎉 펩타이드 발굴 파이프라인 완료!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ##############################################################################\n",
        "#\n",
        "# 통합 펩타이드 발굴 파이프라인 (PRODIGY 개선 버전)\n",
        "# - 라이브러리 설치 중복 방지\n",
        "# - 파일 구조 개선 (fasta/, pdb/ 폴더 분리)\n",
        "#\n",
        "# ##############################################################################\n",
        "\n",
        "# to do\n",
        "# pdb파일 한번에 다운 받을 수 있게 results 폴더에 압축해서 저장하는 기능 추가\n",
        "\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import site\n",
        "import subprocess\n",
        "import shutil\n",
        "import re, glob, json, pickle\n",
        "\n",
        "# 파이프라인 시작 시간 기록\n",
        "pipeline_start_time = time.time()\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 0: 통합 환경 설정 및 라이브러리 설치 (중복 방지)\n",
        "# ==============================================================================\n",
        "\n",
        "def check_and_install_libraries():\n",
        "    \"\"\"라이브러리 설치 상태를 확인하고 필요한 것만 설치\"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"STEP 0: 환경 설정 및 라이브러리 설치 (중복 방지)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 설치 플래그 파일\n",
        "    install_flag_file = \"peptide_pipeline_installed.flag\"\n",
        "\n",
        "    if os.path.exists(install_flag_file):\n",
        "        print(\"✅ 이미 설치된 환경이 감지되었습니다. 설치를 건너뜁니다.\")\n",
        "        return True\n",
        "\n",
        "    print(\"🔧 첫 실행입니다. 필요한 라이브러리들을 설치합니다...\")\n",
        "\n",
        "    try:\n",
        "        # 1. 기본 라이브러리 설치\n",
        "        print(\"\\n[1/6] 기본 라이브러리 설치...\")\n",
        "        os.system(\"pip install -q pytz requests beautifulsoup4 openpyxl\")\n",
        "\n",
        "        # 2. ColabFold 설치\n",
        "        print(\"\\n[2/6] ColabFold 설치...\")\n",
        "        os.system(\"pip uninstall -y tensorflow tensorboard tb-nightly tensorflow-estimator tensorflow-hub tensorflow-io > /dev/null 2>&1\")\n",
        "        os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "        os.system(\"pip install -q --no-warn-conflicts 'jax[cuda11_pip]' -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\")\n",
        "\n",
        "        # ColabFold 패치\n",
        "        try:\n",
        "            dist_packages_path = site.getsitepackages()[0]\n",
        "            batch_py_path = os.path.join(dist_packages_path, 'colabfold', 'batch.py')\n",
        "            if os.path.exists(batch_py_path):\n",
        "                os.system(f\"sed -i 's/tf.get_logger().setLevel(logging.ERROR)/#tf.get_logger().setLevel(logging.ERROR)/g' {batch_py_path}\")\n",
        "                print(\"   > ColabFold 패치 완료\")\n",
        "        except:\n",
        "            print(\"   > ColabFold 패치 건너뜀\")\n",
        "\n",
        "        # 3. 펩타이드 생성 모델\n",
        "        print(\"\\n[3/6] Transformers 설치...\")\n",
        "        os.system(\"pip install -q --upgrade transformers sentencepiece\")\n",
        "\n",
        "        # 4. 화학 정보학 도구\n",
        "        print(\"\\n[4/6] 화학 정보학 도구 설치...\")\n",
        "        os.system(\"apt-get update -qq > /dev/null 2>&1\")\n",
        "        os.system(\"apt-get install -y --quiet openbabel python3-openbabel libopenbabel-dev > /dev/null 2>&1\")\n",
        "        os.system(\"pip install -q openbabel-wheel rdkit-pypi biopython ProLIF MDAnalysis oddt scikit-learn plip\")\n",
        "\n",
        "        # 5. AutoDock Vina\n",
        "        print(\"\\n[5/6] AutoDock Vina 설치...\")\n",
        "        setup_vina_robust()\n",
        "\n",
        "        # 6. 추가 도구\n",
        "        print(\"\\n[6/6] 추가 도구 설치...\")\n",
        "        os.system(\"pip install -q pymol-open-source meeko > /dev/null 2>&1\")\n",
        "\n",
        "        # 설치 완료 플래그 생성\n",
        "        with open(install_flag_file, 'w') as f:\n",
        "            f.write(f\"Installed at: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        print(\"\\n✅ 모든 라이브러리 설치 완료!\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 설치 중 오류 발생: {e}\")\n",
        "        return False\n",
        "\n",
        "def setup_vina_robust():\n",
        "    \"\"\"AutoDock Vina 설치\"\"\"\n",
        "    vina_dir = \"vina_1.2.3_linux_x86_64\"\n",
        "\n",
        "    if not os.path.exists(vina_dir):\n",
        "        download_commands = [\n",
        "            \"wget -q https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip\",\n",
        "            \"curl -L -o vina_1.2.3_linux_x86_64.zip https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip\"\n",
        "        ]\n",
        "\n",
        "        for cmd in download_commands:\n",
        "            if os.system(cmd) == 0:\n",
        "                break\n",
        "\n",
        "        os.system(\"unzip -q -o vina_1.2.3_linux_x86_64.zip\")\n",
        "\n",
        "        for executable in [f\"{vina_dir}/vina\", f\"{vina_dir}/bin/vina\"]:\n",
        "            if os.path.exists(executable):\n",
        "                os.chmod(executable, 0o755)\n",
        "\n",
        "    # Vina 실행파일 경로 반환\n",
        "    for path in [f\"./{vina_dir}/vina\", f\"./{vina_dir}/bin/vina\", \"vina\"]:\n",
        "        if os.path.exists(path) and os.access(path, os.X_OK):\n",
        "            return os.path.abspath(path)\n",
        "    return None\n",
        "\n",
        "# 라이브러리 설치 실행\n",
        "if not check_and_install_libraries():\n",
        "    print(\"❌ 설치 실패. 파이프라인을 종료합니다.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Vina 실행파일 경로 설정\n",
        "VINA_EXECUTABLE = setup_vina_robust()\n",
        "PLIP_AVAILABLE = (shutil.which(\"plipcmd\") is not None)\n",
        "\n",
        "print(\"\\n# 설치된 도구들의 상태 요약\")\n",
        "print(f\"   • AutoDock Vina: {'✅ 설치됨' if VINA_EXECUTABLE else '⚠️ 간단한 추정 사용'}\")\n",
        "print(f\"   • PLIP: {'✅ 사용 가능' if PLIP_AVAILABLE else '⚠️ 대체 계산 사용'}\")\n",
        "print(f\"   • PRODIGY(Web): 🌐 웹 시도/실패 시 대체 점수\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 1: 파이프라인 실행 변수 설정 및 폴더 구조 생성\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 1: 변수 설정 및 폴더 구조 생성\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# --- 사용자 설정 ---\n",
        "N_PEPTIDES = 10\n",
        "TARGET_PROTEIN_SEQUENCE = \"AFTVTVPKDLYVVEYGSNMTIECKFPVEKQLDLAALIVYWEMEDKNIIQFVHGEEDLKVQHSSYRQRARLLKDQLSLGNAALQITDVKLQDAGVYRCMISYGGADYKRITVKVNAPYNKINQRILVVDPVTSEHELTCQAEGYPKAEVIWTSSDHQVLSGKTTTTNSKREEKLFNVTSTLRINTTTNEIFYCTFRRLDPEENHTAELVIPELPLAHPPNERT\"\n",
        "PEPTIDE_LENGTH = 4\n",
        "BASE_FOLDER_PREFIX = \"PDP\"\n",
        "\n",
        "# 한국 시간 기반 폴더명 생성\n",
        "kst = pytz.timezone('Asia/Seoul')\n",
        "now_kst = datetime.now(kst)\n",
        "timestamp = now_kst.strftime(\"%Y%m%d_%H%M%S\")\n",
        "JOB_NAME = f\"{BASE_FOLDER_PREFIX}_{timestamp}\"\n",
        "\n",
        "# 📁 개선된 폴더 구조 생성\n",
        "def create_project_structure():\n",
        "    \"\"\"프로젝트 폴더 구조 생성\"\"\"\n",
        "    folders = [\n",
        "        JOB_NAME,\n",
        "        os.path.join(JOB_NAME, \"fasta\"),      # FASTA 파일 전용\n",
        "        os.path.join(JOB_NAME, \"pdb\"),        # PDB 파일 전용\n",
        "        os.path.join(JOB_NAME, \"results\"),    # 결과 파일\n",
        "        os.path.join(JOB_NAME, \"temp\")        # 임시 파일\n",
        "    ]\n",
        "\n",
        "    for folder in folders:\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    print(f\"✅ 프로젝트 폴더 구조 생성 완료: {JOB_NAME}\")\n",
        "    return folders\n",
        "\n",
        "create_project_structure()\n",
        "\n",
        "# 파일 경로 설정 (개선된 구조)\n",
        "PROTEIN_FASTA_PATH = os.path.join(JOB_NAME, \"fasta\", \"target_protein.fasta\")\n",
        "OUTPUT_FINAL_XLSX_PATH = os.path.join(JOB_NAME, \"results\", f\"final_ranking_{timestamp}.xlsx\")\n",
        "\n",
        "# 타겟 단백질 FASTA 파일 저장\n",
        "with open(PROTEIN_FASTA_PATH, \"w\") as f:\n",
        "    f.write(f\">target_protein\\n{TARGET_PROTEIN_SEQUENCE}\\n\")\n",
        "\n",
        "print(f\"📊 설정 요약:\")\n",
        "print(f\"   • 작업 폴더: {JOB_NAME}\")\n",
        "print(f\"   • 펩타이드 개수: {N_PEPTIDES}\")\n",
        "print(f\"   • 펩타이드 길이: {PEPTIDE_LENGTH}\")\n",
        "print(f\"   • 타겟 서열 길이: {len(TARGET_PROTEIN_SEQUENCE)}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: ESM-2 펩타이드 생성\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 2: ESM-2 펩타이드 생성\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# ESM-2 모델 로드\n",
        "model_name = \"facebook/esm2_t12_35M_UR50D\"\n",
        "print(f\"ESM-2 모델 로딩: {model_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 펩타이드 생성\n",
        "formatted_target = \" \".join(list(TARGET_PROTEIN_SEQUENCE))\n",
        "mask_tokens = \" \".join([tokenizer.mask_token] * PEPTIDE_LENGTH)\n",
        "prompt = f\"{tokenizer.cls_token} {formatted_target} {tokenizer.eos_token} {mask_tokens}\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "mask_token_indices = (input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
        "\n",
        "peptides = []\n",
        "peptide_fasta_paths = []\n",
        "\n",
        "print(\"\\n🧬 펩타이드 생성 중...\")\n",
        "with torch.no_grad():\n",
        "    for i in range(N_PEPTIDES):\n",
        "        current_ids = input_ids.clone().to(model.device)\n",
        "        shuffled_mask_indices = mask_token_indices[torch.randperm(len(mask_token_indices))]\n",
        "\n",
        "        for mask_idx in shuffled_mask_indices:\n",
        "            outputs = model(input_ids=current_ids)\n",
        "            logits = outputs.logits[0, mask_idx, :] / 1.0  # temperature\n",
        "            top_k_values, top_k_indices = torch.topk(logits, min(50, tokenizer.vocab_size))\n",
        "            filter_tensor = torch.full_like(logits, -float('Inf'))\n",
        "            filter_tensor.scatter_(0, top_k_indices, top_k_values)\n",
        "            probs = F.softmax(filter_tensor, dim=-1)\n",
        "            predicted_token_id = torch.multinomial(probs, num_samples=1)\n",
        "            current_ids[0, mask_idx] = predicted_token_id.item()\n",
        "\n",
        "        generated_token_ids = current_ids[0, mask_token_indices]\n",
        "        sequence = \"\".join(tokenizer.decode(generated_token_ids, skip_special_tokens=True).split())\n",
        "        peptides.append(sequence)\n",
        "\n",
        "        # 📁 FASTA 폴더에 저장\n",
        "        fasta_path = os.path.join(JOB_NAME, \"fasta\", f\"peptide_{i}.fasta\")\n",
        "        with open(fasta_path, \"w\") as f:\n",
        "            f.write(f\">peptide_{i}\\n{sequence}\\n\")\n",
        "        peptide_fasta_paths.append(fasta_path)\n",
        "        print(f\"  [{i+1:2d}/{N_PEPTIDES}] {sequence}\")\n",
        "\n",
        "print(f\"\\n✅ {N_PEPTIDES}개 펩타이드 생성 완료\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: ColabFold 구조 예측\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 3: ColabFold 3D 구조 예측\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 배치 CSV 파일 생성\n",
        "batch_csv_path = os.path.join(JOB_NAME, \"temp\", \"batch_complexes.csv\")\n",
        "with open(batch_csv_path, \"w\") as f:\n",
        "    f.write(\"id,sequence\\n\")\n",
        "    for i, peptide_seq in enumerate(peptides):\n",
        "        complex_sequence = f\"{TARGET_PROTEIN_SEQUENCE}:{peptide_seq}\"\n",
        "        f.write(f\"complex_{i},{complex_sequence}\\n\")\n",
        "\n",
        "# ColabFold 실행\n",
        "output_dir = os.path.join(JOB_NAME, \"pdb\")  # 📁 PDB 폴더에 직접 저장\n",
        "log_file = os.path.join(JOB_NAME, \"temp\", \"colabfold.log\")\n",
        "\n",
        "print(f\"ColabFold 실행 중... (예상 시간: 10-30분)\")\n",
        "colabfold_cmd = (f\"colabfold_batch \"\n",
        "                f\"--num-recycle 1 \"\n",
        "                f\"--model-type alphafold2_multimer_v3 \"\n",
        "                f\"--rank ptm \"\n",
        "                f\"--max-msa 32:128 \"\n",
        "                f\"--num-models 1 \"\n",
        "                f\"--stop-at-score 0.5 \"\n",
        "                f\"{batch_csv_path} {output_dir} > {log_file} 2>&1\")\n",
        "\n",
        "result = os.system(colabfold_cmd)\n",
        "\n",
        "# PDB 파일 수집\n",
        "predicted_pdb_files = []\n",
        "for i in range(N_PEPTIDES):\n",
        "    pdb_pattern = os.path.join(output_dir, f\"complex_{i}_unrelaxed_rank_001*.pdb\")\n",
        "    pdb_files = sorted(glob.glob(pdb_pattern))\n",
        "    if pdb_files:\n",
        "        predicted_pdb_files.append(pdb_files[0])\n",
        "        print(f\"  ✅ 복합체 {i}: {os.path.basename(pdb_files[0])}\")\n",
        "\n",
        "print(f\"\\n✅ {len(predicted_pdb_files)}개 구조 예측 완료\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3.5: ColabFold 결과에서 pTM/ipTM JSON 생성 (ranking_debug.json 보장)\n",
        "#  - 위치: STEP 3(구조 예측) 직후, STEP 4 직전에 추가\n",
        "#  - 전제: output_dir = os.path.join(JOB_NAME, \"pdb\")  # PRED_ROOT는 output_dir\n",
        "# ==============================================================================\n",
        "\n",
        "# 너의 코드에서 이미 이렇게 되어있음:\n",
        "# output_dir = os.path.join(JOB_NAME, \"pdb\")\n",
        "PRED_ROOT = output_dir\n",
        "\n",
        "assert os.path.isdir(PRED_ROOT), f\"ColabFold 출력 폴더가 없음: {PRED_ROOT}\"\n",
        "\n",
        "def _to_float(x):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def _load_metrics_from_any(path_like):\n",
        "    \"\"\"\n",
        "    디렉터리 또는 파일 경로를 받아 iptm/ptm을 추출.\n",
        "    우선순위:\n",
        "      1) ranking_debug.json\n",
        "      2) result_model_*_multimer*.json\n",
        "      3) result_model_*_multimer*.pkl\n",
        "    반환: (iptm, ptm, source_path or None)\n",
        "    \"\"\"\n",
        "    to_try = []\n",
        "\n",
        "    if os.path.isdir(path_like):\n",
        "        to_try.append(os.path.join(path_like, \"ranking_debug.json\"))\n",
        "        to_try += glob.glob(os.path.join(path_like, \"result_model_*_multimer*.json\"))\n",
        "        to_try += glob.glob(os.path.join(path_like, \"result_model_*_multimer*.pkl\"))\n",
        "    else:\n",
        "        to_try.append(path_like)\n",
        "\n",
        "    for p in to_try:\n",
        "        if not os.path.exists(p):\n",
        "            continue\n",
        "        try:\n",
        "            if p.endswith(\".json\"):\n",
        "                with open(p, \"r\") as f:\n",
        "                    data = json.load(f)\n",
        "                rc = data.get(\"ranking_confidences\", {})\n",
        "                iptm = _to_float(data.get(\"iptm\") or rc.get(\"iptm\") or rc.get(\"iptm+ptm\") or data.get(\"iptm_score\"))\n",
        "                ptm  = _to_float(data.get(\"ptm\")  or rc.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "                if iptm is not None or ptm is not None:\n",
        "                    return iptm, ptm, p\n",
        "            elif p.endswith(\".pkl\"):\n",
        "                with open(p, \"rb\") as f:\n",
        "                    data = pickle.load(f)\n",
        "                iptm = _to_float(data.get(\"iptm\") or data.get(\"iptm_score\"))\n",
        "                ptm  = _to_float(data.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "                if iptm is None or ptm is None:\n",
        "                    mc = data.get(\"model_confidence\", {}) or data.get(\"ranking_confidences\", {})\n",
        "                    iptm = _to_float(iptm if iptm is not None else (mc.get(\"iptm\") or mc.get(\"iptm+ptm\")))\n",
        "                    ptm  = _to_float(ptm  if ptm  is not None else mc.get(\"ptm\"))\n",
        "                if iptm is not None or ptm is not None:\n",
        "                    return iptm, ptm, p\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return None, None, None\n",
        "\n",
        "def _ensure_ranking_debug_json(dir_path, iptm, ptm, source=None):\n",
        "    \"\"\"\n",
        "    dir_path는 반드시 '폴더'여야 함. 없으면 만든 뒤 ranking_debug.json 생성/갱신.\n",
        "    \"\"\"\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    out_path = os.path.join(dir_path, \"ranking_debug.json\")\n",
        "    payload = {\n",
        "        \"iptm\": iptm if iptm is not None else 0.0,\n",
        "        \"ptm\":  ptm  if ptm  is not None else 0.0,\n",
        "        \"ranking_confidences\": {\n",
        "            \"iptm\": iptm if iptm is not None else 0.0,\n",
        "            \"ptm\":  ptm  if ptm  is not None else 0.0,\n",
        "            \"iptm+ptm\": ((iptm or 0.0) + (ptm or 0.0))/2.0\n",
        "        },\n",
        "        \"_generated_from\": source or \"unknown\"\n",
        "    }\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(payload, f, indent=2)\n",
        "    return out_path\n",
        "\n",
        "def _collect_complex_ids(root):\n",
        "    \"\"\"\n",
        "    평면(.a3m/.pdb) + 폴더 둘 다에서 complex ID를 수집\n",
        "    \"\"\"\n",
        "    ids = set()\n",
        "\n",
        "    # 폴더 이름에서 추출 (진짜 폴더만)\n",
        "    for d in glob.glob(os.path.join(root, \"complex_*\")):\n",
        "        if os.path.isdir(d):\n",
        "            m = re.search(r\"complex_(\\d+)\", os.path.basename(d))\n",
        "            if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    # 평면 파일(.a3m)에서 추출\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*.a3m\")):\n",
        "        m = re.search(r\"complex_(\\d+)\\.a3m$\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    # 평면 파일(.pdb)에서 추출\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*_unrelaxed_rank_*.pdb\")):\n",
        "        m = re.search(r\"complex_(\\d+)_\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    return sorted(ids)\n",
        "\n",
        "created, reused = 0, 0\n",
        "complex_ids = _collect_complex_ids(PRED_ROOT)\n",
        "\n",
        "if complex_ids:\n",
        "    for cid in complex_ids:\n",
        "        # 대상 디렉터리(보장 폴더): PRED_ROOT/complex_{cid:03d}\n",
        "        cdir = os.path.join(PRED_ROOT, f\"complex_{cid:03d}\")\n",
        "\n",
        "        # 먼저 cdir 내부에서 시도 (이미 폴더 구조가 있으면)\n",
        "        iptm, ptm, src = _load_metrics_from_any(cdir)\n",
        "\n",
        "        # 없으면 루트(PRED_ROOT)에서 해당 complex 관련 파일들로 시도\n",
        "        if iptm is None and ptm is None:\n",
        "            # ranking_debug.json / result_model_* in root\n",
        "            # (일부 환경은 root에만 떨어짐 → 같은 값을 복제)\n",
        "            for pat in [\n",
        "                os.path.join(PRED_ROOT, \"ranking_debug.json\"),\n",
        "                os.path.join(PRED_ROOT, \"result_model_*_multimer*.json\"),\n",
        "                os.path.join(PRED_ROOT, \"result_model_*_multimer*.pkl\"),\n",
        "            ]:\n",
        "                for p in glob.glob(pat):\n",
        "                    iptm, ptm, src = _load_metrics_from_any(p)\n",
        "                    if iptm is not None or ptm is not None:\n",
        "                        break\n",
        "                if iptm is not None or ptm is not None:\n",
        "                    break\n",
        "\n",
        "        # 최종적으로 폴더를 만들고 ranking_debug.json을 보장 생성\n",
        "        rd_path = os.path.join(cdir, \"ranking_debug.json\")\n",
        "        need_create = (not os.path.isfile(rd_path)) or (iptm is None and ptm is None)\n",
        "\n",
        "        if need_create:\n",
        "            outp = _ensure_ranking_debug_json(cdir, iptm, ptm, source=src)\n",
        "            print(f\"🆕 ranking_debug 생성: {outp} (from: {src or 'no source → zeros'})\")\n",
        "            created += 1\n",
        "        else:\n",
        "            reused += 1\n",
        "else:\n",
        "    # complex_* ID를 전혀 못 찾은 경우 → 루트 기준으로 하나 만들어 두기(최소 보장)\n",
        "    iptm, ptm, src = _load_metrics_from_any(PRED_ROOT)\n",
        "    outp = _ensure_ranking_debug_json(PRED_ROOT, iptm, ptm, source=src)\n",
        "    print(f\"🆕 ranking_debug 생성(루트): {outp} (from: {src or 'no source → zeros'})\")\n",
        "    created += 1\n",
        "\n",
        "print(f\"STEP 3.5 완료 → 생성 {created}개, 재사용 {reused}개 (검색 루트: {PRED_ROOT})\")\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: ColabFold 구조 예측\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 3: ColabFold 3D 구조 예측\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 배치 CSV 파일 생성\n",
        "batch_csv_path = os.path.join(JOB_NAME, \"temp\", \"batch_complexes.csv\")\n",
        "with open(batch_csv_path, \"w\") as f:\n",
        "    f.write(\"id,sequence\\n\")\n",
        "    for i, peptide_seq in enumerate(peptides):\n",
        "        complex_sequence = f\"{TARGET_PROTEIN_SEQUENCE}:{peptide_seq}\"\n",
        "        f.write(f\"complex_{i},{complex_sequence}\\n\")\n",
        "\n",
        "# ColabFold 실행\n",
        "output_dir = os.path.join(JOB_NAME, \"pdb\")  # 📁 PDB 폴더에 직접 저장\n",
        "log_file = os.path.join(JOB_NAME, \"temp\", \"colabfold.log\")\n",
        "\n",
        "print(f\"ColabFold 실행 중... (예상 시간: 10-30분)\")\n",
        "colabfold_cmd = (f\"colabfold_batch \"\n",
        "                f\"--num-recycle 1 \"\n",
        "                f\"--model-type alphafold2_multimer_v3 \"\n",
        "                f\"--rank ptm \"\n",
        "                f\"--max-msa 32:128 \"\n",
        "                f\"--num-models 1 \"\n",
        "                f\"--stop-at-score 0.5 \"\n",
        "                f\"{batch_csv_path} {output_dir} > {log_file} 2>&1\")\n",
        "\n",
        "result = os.system(colabfold_cmd)\n",
        "\n",
        "# PDB 파일 수집\n",
        "predicted_pdb_files = []\n",
        "for i in range(N_PEPTIDES):\n",
        "    pdb_pattern = os.path.join(output_dir, f\"complex_{i}_unrelaxed_rank_001*.pdb\")\n",
        "    pdb_files = sorted(glob.glob(pdb_pattern))\n",
        "    if pdb_files:\n",
        "        predicted_pdb_files.append(pdb_files[0])\n",
        "        print(f\"  ✅ 복합체 {i}: {os.path.basename(pdb_files[0])}\")\n",
        "\n",
        "print(f\"\\n✅ {len(predicted_pdb_files)}개 구조 예측 완료\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3.5: ColabFold 결과에서 pTM/ipTM JSON 생성 (ranking_debug.json 보장)\n",
        "#  - 전제: output_dir = os.path.join(JOB_NAME, \"pdb\")  # PRED_ROOT는 output_dir\n",
        "#  - 폴더 트리 가정: PRED_ROOT 루트에 complex_0_scores_rank_*.json 파일 존재 가능\n",
        "# ==============================================================================\n",
        "\n",
        "PRED_ROOT = output_dir  # = os.path.join(JOB_NAME, \"pdb\")\n",
        "assert os.path.isdir(PRED_ROOT), f\"ColabFold 출력 폴더가 없음: {PRED_ROOT}\"\n",
        "\n",
        "def _to_float(x):\n",
        "    try: return float(x)\n",
        "    except: return None\n",
        "\n",
        "def _load_metrics_from_any(path_like):\n",
        "    \"\"\"\n",
        "    디렉터리 또는 파일 경로를 받아 iptm/ptm을 추출.\n",
        "    우선순위:\n",
        "      1) ranking_debug.json\n",
        "      2) result_model_*_multimer*.json\n",
        "      3) result_model_*_multimer*.pkl\n",
        "      4) complex_*_scores_rank_*.json   <-- (신규) 루트 점수 JSON\n",
        "    반환: (iptm, ptm, source_path or None)\n",
        "    \"\"\"\n",
        "    def _try_json(fp):\n",
        "        try:\n",
        "            with open(fp, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "        except Exception:\n",
        "            return None, None\n",
        "        rc   = data.get(\"ranking_confidences\", {}) if isinstance(data, dict) else {}\n",
        "        iptm = _to_float(data.get(\"iptm\") or rc.get(\"iptm\") or rc.get(\"iptm+ptm\") or data.get(\"iptm_score\"))\n",
        "        ptm  = _to_float(data.get(\"ptm\")  or rc.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "        # ColabFold scores_rank JSON에 직접 'iptm','ptm' 키가 들어있는 경우가 많음\n",
        "        if iptm is None: iptm = _to_float(data.get(\"iptm\"))\n",
        "        if ptm  is None: ptm  = _to_float(data.get(\"ptm\"))\n",
        "        return iptm, ptm\n",
        "\n",
        "    def _try_pkl(fp):\n",
        "        try:\n",
        "            with open(fp, \"rb\") as f:\n",
        "                data = pickle.load(f)\n",
        "        except Exception:\n",
        "            return None, None\n",
        "        iptm = _to_float(data.get(\"iptm\") or data.get(\"iptm_score\"))\n",
        "        ptm  = _to_float(data.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "        if iptm is None or ptm is None:\n",
        "            mc = data.get(\"model_confidence\", {}) or data.get(\"ranking_confidences\", {})\n",
        "            if iptm is None: iptm = _to_float(mc.get(\"iptm\") or mc.get(\"iptm+ptm\"))\n",
        "            if ptm  is None: ptm  = _to_float(mc.get(\"ptm\"))\n",
        "        return iptm, ptm\n",
        "\n",
        "    # 1) 디렉터리라면 내부 우선 시도\n",
        "    if os.path.isdir(path_like):\n",
        "        rd = os.path.join(path_like, \"ranking_debug.json\")\n",
        "        if os.path.isfile(rd):\n",
        "            iptm, ptm = _try_json(rd)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, rd\n",
        "        for jp in glob.glob(os.path.join(path_like, \"result_model_*_multimer*.json\")):\n",
        "            iptm, ptm = _try_json(jp)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, jp\n",
        "        for pk in glob.glob(os.path.join(path_like, \"result_model_*_multimer*.pkl\")):\n",
        "            iptm, ptm = _try_pkl(pk)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, pk\n",
        "\n",
        "    # 2) 파일 경로라면 직접 시도\n",
        "    if os.path.isfile(path_like):\n",
        "        if path_like.endswith(\".json\"):\n",
        "            iptm, ptm = _try_json(path_like)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, path_like\n",
        "        elif path_like.endswith(\".pkl\"):\n",
        "            iptm, ptm = _try_pkl(path_like)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, path_like\n",
        "\n",
        "    return None, None, None\n",
        "\n",
        "def _ensure_ranking_debug_json(dir_path, iptm, ptm, source=None):\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    out_path = os.path.join(dir_path, \"ranking_debug.json\")\n",
        "    payload = {\n",
        "        \"iptm\": iptm if iptm is not None else 0.0,\n",
        "        \"ptm\":  ptm  if ptm  is not None else 0.0,\n",
        "        \"ranking_confidences\": {\n",
        "            \"iptm\": iptm if iptm is not None else 0.0,\n",
        "            \"ptm\":  ptm  if ptm  is not None else 0.0,\n",
        "            \"iptm+ptm\": ((iptm or 0.0) + (ptm or 0.0))/2.0\n",
        "        },\n",
        "        \"_generated_from\": source or \"unknown\"\n",
        "    }\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(payload, f, indent=2)\n",
        "    return out_path\n",
        "\n",
        "def _collect_complex_ids(root):\n",
        "    \"\"\"폴더/평면/점수 JSON에서 complex ID 모두 수집 (0, 1, ... → 정렬)\"\"\"\n",
        "    ids = set()\n",
        "\n",
        "    # 폴더\n",
        "    for d in glob.glob(os.path.join(root, \"complex_*\")):\n",
        "        if os.path.isdir(d):\n",
        "            m = re.search(r\"complex_(\\d+)$\", os.path.basename(d))\n",
        "            if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    # 평면 .a3m / .pdb\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*.a3m\")):\n",
        "        m = re.search(r\"complex_(\\d+)\\.a3m$\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*_unrelaxed_rank_*.pdb\")):\n",
        "        m = re.search(r\"complex_(\\d+)_\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    # ⬅️ 점수 JSON (네가 보여준 파일: complex_0_scores_rank_001_...json)\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*_scores_rank_*.json\")):\n",
        "        m = re.search(r\"complex_(\\d+)_scores_rank_\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    return sorted(ids)\n",
        "\n",
        "def _find_root_score_jsons_for_id(root, cid):\n",
        "    \"\"\"루트에 있는 이 ID용 점수 JSON 후보 목록\"\"\"\n",
        "    pats = [\n",
        "        os.path.join(root, f\"complex_{cid}_scores_rank_*.json\"),\n",
        "        os.path.join(root, f\"complex_{cid:03d}_scores_rank_*.json\"),\n",
        "    ]\n",
        "    out = []\n",
        "    for p in pats:\n",
        "        out += glob.glob(p)\n",
        "    return sorted(out)\n",
        "\n",
        "created, reused = 0, 0\n",
        "complex_ids = _collect_complex_ids(PRED_ROOT)\n",
        "\n",
        "for cid in complex_ids:\n",
        "    cdir = os.path.join(PRED_ROOT, f\"complex_{cid:03d}\")\n",
        "\n",
        "    # 1) 먼저 해당 폴더 안에서 시도\n",
        "    iptm, ptm, src = _load_metrics_from_any(cdir)\n",
        "\n",
        "    # 2) 실패하면 루트 점수 JSON( complex_{id}_scores_rank_*.json )에서 시도\n",
        "    if iptm is None and ptm is None:\n",
        "        for jf in _find_root_score_jsons_for_id(PRED_ROOT, cid):\n",
        "            iptm, ptm, src = _load_metrics_from_any(jf)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                break\n",
        "\n",
        "    # 3) 그래도 없으면 루트의 result_model* 시도(환경에 따라 있을 수 있음)\n",
        "    if iptm is None and ptm is None:\n",
        "        for pat in [\n",
        "            os.path.join(PRED_ROOT, \"result_model_*_multimer*.json\"),\n",
        "            os.path.join(PRED_ROOT, \"result_model_*_multimer*.pkl\"),\n",
        "        ]:\n",
        "            for p in glob.glob(pat):\n",
        "                iptm, ptm, src = _load_metrics_from_any(p)\n",
        "                if iptm is not None or ptm is not None:\n",
        "                    break\n",
        "            if iptm is not None or ptm is not None:\n",
        "                break\n",
        "\n",
        "    # 4) 최종적으로 폴더를 만들고 ranking_debug.json 보장 생성\n",
        "    rd_path = os.path.join(cdir, \"ranking_debug.json\")\n",
        "    need_create = (not os.path.isfile(rd_path)) or (iptm is None and ptm is None)\n",
        "    if need_create:\n",
        "        outp = _ensure_ranking_debug_json(cdir, iptm, ptm, source=src)\n",
        "        print(f\"🆕 ranking_debug 생성: {outp} (from: {src or 'no source → zeros'})\")\n",
        "        created += 1\n",
        "    else:\n",
        "        reused += 1\n",
        "\n",
        "print(f\"STEP 3.5 완료 → 생성 {created}개, 재사용 {reused}개 (검색 루트: {PRED_ROOT})\")\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: pTM/ipTM 점수 추출 (디렉터리 직접 순회 + 루트 점수 JSON 폴백)\n",
        "# ==============================================================================\n",
        "\n",
        "import os, re, glob, json\n",
        "\n",
        "PRED_ROOT = os.path.join(JOB_NAME, \"pdb\")\n",
        "\n",
        "print(\"\\nSTEP 4: pTM/ipTM 점수 추출\")\n",
        "print(\"=\"*80)\n",
        "print(f\"검색 루트: {PRED_ROOT}\")\n",
        "\n",
        "def _to_float(x):\n",
        "    try: return float(x)\n",
        "    except: return None\n",
        "\n",
        "def _read_json_scores(fp):\n",
        "    try:\n",
        "        with open(fp, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "    except Exception:\n",
        "        return None, None\n",
        "    rc   = data.get(\"ranking_confidences\", {}) if isinstance(data, dict) else {}\n",
        "    iptm = _to_float(data.get(\"iptm\") or rc.get(\"iptm\") or rc.get(\"iptm+ptm\") or data.get(\"iptm_score\"))\n",
        "    ptm  = _to_float(data.get(\"ptm\")  or rc.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "    if iptm is None: iptm = _to_float(data.get(\"iptm\"))\n",
        "    if ptm  is None: ptm  = _to_float(data.get(\"ptm\"))\n",
        "    return iptm, ptm\n",
        "\n",
        "ptm_scores_map = {}\n",
        "found_files = 0\n",
        "\n",
        "# 1) complex_*** 디렉터리를 직접 순회 (STEP 3.5가 생성해둠)\n",
        "complex_dirs = sorted([d for d in glob.glob(os.path.join(PRED_ROOT, \"complex_*\")) if os.path.isdir(d)])\n",
        "for cdir in complex_dirs:\n",
        "    m = re.search(r\"complex_(\\d+)$\", os.path.basename(cdir))\n",
        "    if not m:\n",
        "        continue\n",
        "    idx = int(m.group(1))\n",
        "    rd = os.path.join(cdir, \"ranking_debug.json\")\n",
        "    if not os.path.isfile(rd):\n",
        "        continue\n",
        "    iptm, ptm = _read_json_scores(rd)\n",
        "    if iptm is None and ptm is None:\n",
        "        continue\n",
        "    val = iptm if iptm is not None else ptm\n",
        "    val = 0.0 if val is None else float(val)\n",
        "\n",
        "    key = peptides[idx] if 0 <= idx < len(peptides) else f\"complex_{idx:03d}\"\n",
        "    ptm_scores_map[key] = round(val, 3)\n",
        "    found_files += 1\n",
        "\n",
        "# 2) (폴더가 없거나 누락된 경우) 루트의 complex_*_scores_rank_*.json도 읽어 매핑\n",
        "root_score_jsons = sorted(glob.glob(os.path.join(PRED_ROOT, \"complex_*_scores_rank_*.json\")))\n",
        "for fp in root_score_jsons:\n",
        "    m = re.search(r\"complex_(\\d+)_scores_rank_\", os.path.basename(fp))\n",
        "    if not m:\n",
        "        continue\n",
        "    idx = int(m.group(1))\n",
        "    iptm, ptm = _read_json_scores(fp)\n",
        "    if iptm is None and ptm is None:\n",
        "        continue\n",
        "    val = iptm if iptm is not None else ptm\n",
        "    val = 0.0 if val is None else float(val)\n",
        "\n",
        "    key = peptides[idx] if 0 <= idx < len(peptides) else f\"complex_{idx:03d}\"\n",
        "    # 디렉터리의 ranking_debug 값을 우선하고, 없을 때만 보충\n",
        "    if key not in ptm_scores_map:\n",
        "        ptm_scores_map[key] = round(val, 3)\n",
        "        found_files += 1\n",
        "\n",
        "print(f\"🔎 확인: complex_* 디렉터리 {len(complex_dirs)}개, 루트 점수 JSON {len(root_score_jsons)}개\")\n",
        "print(f\"✅ pTM/ipTM 점수 추출 완료: {len(ptm_scores_map)}개\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 5: PRODIGY(웹) 및 상호작용 분석 함수 (PLIP 우선 → 실패 시 대체)\n",
        "# ==============================================================================\n",
        "\n",
        "import re, requests, tempfile, xml.etree.ElementTree as ET\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "\n",
        "def _parse_prodigy_text(text: str):\n",
        "    \"\"\"PRODIGY HTML/텍스트에서 kcal/mol 값을 robust하게 추출\"\"\"\n",
        "    pats = [\n",
        "        r'Predicted\\s+binding\\s+affinity[^-+]*?([\\-+]?\\d+(?:\\.\\d+)?)\\s*kcal\\s*/\\s*mol',\n",
        "        r'(?:ΔG|DeltaG)\\s*[:=]\\s*([\\-+]?\\d+(?:\\.\\d+)?)\\s*kcal\\s*/\\s*mol',\n",
        "        r'([\\-+]?\\d+(?:\\.\\d+)?)\\s*kcal\\s*/\\s*mol'\n",
        "    ]\n",
        "    for p in pats:\n",
        "        m = re.search(p, text, flags=re.IGNORECASE)\n",
        "        if m:\n",
        "            try:\n",
        "                return float(m.group(1))\n",
        "            except:\n",
        "                pass\n",
        "    return None\n",
        "\n",
        "def _fallback_binding_energy_from_geometry(pdb_file_path: str) -> float:\n",
        "    \"\"\"\n",
        "    대체 결합 에너지 추정(간이): 최소 거리 + 접촉 수 기반\n",
        "    더 가까울수록/접촉 많을수록 더 음수(강한 결합)로 가중\n",
        "    \"\"\"\n",
        "    try:\n",
        "        chain_a_coords, chain_b_coords = [], []\n",
        "        with open(pdb_file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.startswith('ATOM'):\n",
        "                    chain = line[21]\n",
        "                    x, y, z = float(line[30:38]), float(line[38:46]), float(line[46:54])\n",
        "                    if chain == 'A':\n",
        "                        chain_a_coords.append((x, y, z))\n",
        "                    elif chain == 'B':\n",
        "                        chain_b_coords.append((x, y, z))\n",
        "\n",
        "        if not chain_a_coords or not chain_b_coords:\n",
        "            return 0.0\n",
        "\n",
        "        min_distance = float('inf')\n",
        "        contact_count = 0\n",
        "\n",
        "        # 연산량 감소를 위해 Chain A는 샘플링\n",
        "        a_samp = chain_a_coords[::5] if len(chain_a_coords) > 5 else chain_a_coords\n",
        "        b_arr = np.array(chain_b_coords)\n",
        "        for (ax, ay, az) in a_samp:\n",
        "            diffs = b_arr - np.array([ax, ay, az])\n",
        "            dists = np.sqrt((diffs**2).sum(axis=1))\n",
        "            min_distance = min(min_distance, float(dists.min()))\n",
        "            contact_count += int((dists < 5.0).sum())\n",
        "\n",
        "        if min_distance < float('inf'):\n",
        "            score = -5.0 - (10.0 / max(min_distance, 1.0)) - (contact_count * 0.1)\n",
        "            return max(score, -20.0)  # 하한 캡\n",
        "    except Exception as e:\n",
        "        print(f\"       대체 점수 계산 실패: {e}\")\n",
        "    return 0.0\n",
        "\n",
        "def predict_binding_affinity_with_prodigy(pdb_file_path: str, max_retries: int = 2) -> float:\n",
        "    \"\"\"\n",
        "    Colab 전용: PRODIGY는 '웹 모드'만 시도 → 실패 시 이 함수 내부에서 '대체 점수' 반환\n",
        "    (로컬 CLI는 Colab에서 불안정하므로 사용하지 않음)\n",
        "    \"\"\"\n",
        "    endpoints = [\n",
        "        \"https://rascar.science.uu.nl/prodigy/prediction\",\n",
        "        \"https://bianca.science.uu.nl/prodigy/prediction\"\n",
        "    ]\n",
        "    # 엔드포인트마다 폼 이름이 다를 수 있어 2종 시도\n",
        "    form_variants = [\n",
        "        {\"file_field\": \"file\", \"data\": {\"temperature\": \"25\", \"chain1\": \"A\", \"chain2\": \"B\"}},\n",
        "        {\"file_field\": \"pdbfile\", \"data\": {\"temp\": \"25\", \"chain1\": \"A\", \"chain2\": \"B\"}},\n",
        "    ]\n",
        "\n",
        "    for ep in endpoints:\n",
        "        for fv in form_variants:\n",
        "            try:\n",
        "                with open(pdb_file_path, \"rb\") as f:\n",
        "                    files = {fv[\"file_field\"]: (os.path.basename(pdb_file_path), f, \"application/octet-stream\")}\n",
        "                    resp = requests.post(ep, files=files, data=fv[\"data\"], timeout=60)\n",
        "                if resp.status_code == 200 and resp.text:\n",
        "                    txt = resp.text\n",
        "                    try:\n",
        "                        soup = BeautifulSoup(txt, \"html.parser\")\n",
        "                        txt += \"\\n\" + (soup.get_text(\"\\n\") or \"\")\n",
        "                    except:\n",
        "                        pass\n",
        "                    val = _parse_prodigy_text(txt)\n",
        "                    if val is not None:\n",
        "                        return float(val)\n",
        "            except Exception as e:\n",
        "                print(f\"       PRODIGY(웹:{ep}) 오류: {e}\")\n",
        "\n",
        "    # 웹 실패 시: 이 함수 내부에서 '대체 점수' 즉시 반환\n",
        "    alt = _fallback_binding_energy_from_geometry(pdb_file_path)\n",
        "    if alt != 0.0:\n",
        "        print(f\"       → PRODIGY 대체 점수 사용: {alt:.3f} kcal/mol\")\n",
        "    return alt\n",
        "\n",
        "def _calculate_interactions_with_plip(pdb_file: str):\n",
        "    \"\"\"\n",
        "    PLIP가 설치되어 있으면 PLIP로 상호작용 계산\n",
        "    실패/미설치면 상위에서 대체 계산 사용\n",
        "    \"\"\"\n",
        "    if not PLIP_AVAILABLE:\n",
        "        raise RuntimeError(\"PLIP not available\")\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as tmpd:\n",
        "        cmd = [\"plipcmd\", \"-f\", pdb_file, \"-o\", tmpd, \"-x\"]\n",
        "        # stderr를 숨기고 timeout 설정\n",
        "        import subprocess\n",
        "        subprocess.check_output(cmd, stderr=subprocess.STDOUT, universal_newlines=True, timeout=120)\n",
        "\n",
        "        report_xml = os.path.join(tmpd, \"report.xml\")\n",
        "        if not os.path.exists(report_xml):\n",
        "            raise RuntimeError(\"PLIP report.xml not found\")\n",
        "\n",
        "        tree = ET.parse(report_xml)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        def count_any(root, tag_substr):\n",
        "            return sum(1 for el in root.iter() if tag_substr in el.tag.lower())\n",
        "\n",
        "        h_bonds = count_any(root, \"hydrogen_bond\")\n",
        "        hydrophobic = count_any(root, \"hydrophobic_interaction\")\n",
        "        # salt_bridge를 정전기 상호작용으로 취급\n",
        "        electrostatic = count_any(root, \"salt_bridge\")\n",
        "\n",
        "        return {\n",
        "            \"h_bonds\": h_bonds,\n",
        "            \"hydrophobic\": hydrophobic,\n",
        "            \"electrostatic\": electrostatic,\n",
        "            \"total\": h_bonds + hydrophobic + electrostatic\n",
        "        }\n",
        "\n",
        "def calculate_interactions_advanced(pdb_file):\n",
        "    \"\"\"상호작용 계산: PLIP 우선 → 실패/미설치 시 대체(간이)\"\"\"\n",
        "    # 1) PLIP 시도\n",
        "    try:\n",
        "        return _calculate_interactions_with_plip(pdb_file)\n",
        "    except Exception as e:\n",
        "        if PLIP_AVAILABLE:\n",
        "            print(f\"    -> PLIP 실패, 대체 계산 사용: {e}\")\n",
        "        else:\n",
        "            print(\"    -> PLIP 미설치/미사용, 대체 계산 사용\")\n",
        "\n",
        "    # 2) 대체(기존 간이 계산)\n",
        "    try:\n",
        "        chain_a_atoms, chain_b_atoms = [], []\n",
        "        with open(pdb_file, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.startswith(('ATOM', 'HETATM')):\n",
        "                    chain = line[21]\n",
        "                    atom_type = line[12:16].strip()\n",
        "                    element = (line[76:78].strip() or atom_type[0]).upper()\n",
        "                    coords = (float(line[30:38]), float(line[38:46]), float(line[46:54]), atom_type, element)\n",
        "                    if chain == 'A':\n",
        "                        chain_a_atoms.append(coords)\n",
        "                    elif chain == 'B':\n",
        "                        chain_b_atoms.append(coords)\n",
        "\n",
        "        if not chain_a_atoms or not chain_b_atoms:\n",
        "            return {'h_bonds': 0, 'hydrophobic': 0, 'electrostatic': 0, 'total': 0}\n",
        "\n",
        "        h_bonds = hydrophobic = electrostatic = 0\n",
        "        for bx, by, bz, b_atom, b_element in chain_b_atoms:\n",
        "            for ax, ay, az, a_atom, a_element in chain_a_atoms:\n",
        "                distance = np.sqrt((bx-ax)**2 + (by-ay)**2 + (bz-az)**2)\n",
        "                # 수소결합\n",
        "                if distance <= 3.5 and ((a_element in ['N','O']) and (b_element in ['N','O'])):\n",
        "                    h_bonds += 1\n",
        "                # 소수성\n",
        "                if distance <= 4.5 and a_element == 'C' and b_element == 'C':\n",
        "                    hydrophobic += 1\n",
        "                # 간이 정전기\n",
        "                if distance <= 5.0:\n",
        "                    charged_pos = ['LYS', 'ARG', 'HIS']\n",
        "                    charged_neg = ['ASP', 'GLU']\n",
        "                    a_res, b_res = a_atom[:3], b_atom[:3]\n",
        "                    if ((a_res in charged_pos and b_res in charged_neg) or\n",
        "                        (a_res in charged_neg and b_res in charged_pos)):\n",
        "                        electrostatic += 1\n",
        "\n",
        "        return {\n",
        "            'h_bonds': h_bonds,\n",
        "            'hydrophobic': hydrophobic,\n",
        "            'electrostatic': electrostatic,\n",
        "            'total': h_bonds + hydrophobic + electrostatic\n",
        "        }\n",
        "    except:\n",
        "        return {'h_bonds': 0, 'hydrophobic': 0, 'electrostatic': 0, 'total': 0}\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 6: 결합력 평가 및 랭킹 (디버깅 강화 버전)\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 6: 결합력 평가 및 최종 랭킹\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results = []\n",
        "\n",
        "if predicted_pdb_files:\n",
        "    for idx, pred_pdb in enumerate(predicted_pdb_files):\n",
        "        print(f\"\\n평가 중 ({idx+1}/{len(predicted_pdb_files)}): {os.path.basename(pred_pdb)}\")\n",
        "\n",
        "        # PDB 파일 유효성 검사\n",
        "        if not os.path.exists(pred_pdb):\n",
        "            print(\"    -> PDB 파일 없음\")\n",
        "            continue\n",
        "\n",
        "        file_size = os.path.getsize(pred_pdb)\n",
        "        if file_size == 0:\n",
        "            print(\"    -> 빈 PDB 파일\")\n",
        "            continue\n",
        "\n",
        "        print(f\"    -> PDB 파일 크기: {file_size} bytes\")\n",
        "\n",
        "        # 펩타이드 서열 매핑\n",
        "        try:\n",
        "            peptide_index = int(re.search(r'complex_(\\d+)', os.path.basename(pred_pdb)).group(1))\n",
        "            peptide_seq = peptides[peptide_index]\n",
        "            print(f\"    -> 펩타이드: {peptide_seq}\")\n",
        "        except:\n",
        "            print(\"    -> 펩타이드 매핑 실패\")\n",
        "            continue\n",
        "\n",
        "        # PDB 파일 내용 간단 확인\n",
        "        try:\n",
        "            with open(pred_pdb, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            atom_lines = [line for line in lines if line.startswith('ATOM')]\n",
        "            chain_a_atoms = [line for line in atom_lines if line[21] == 'A']\n",
        "            chain_b_atoms = [line for line in atom_lines if line[21] == 'B']\n",
        "\n",
        "            print(f\"    -> Chain A 원자수: {len(chain_a_atoms)}\")\n",
        "            print(f\"    -> Chain B 원자수: {len(chain_b_atoms)}\")\n",
        "\n",
        "            if len(chain_a_atoms) == 0 or len(chain_b_atoms) == 0:\n",
        "                print(\"    -> 경고: Chain A 또는 B가 비어있음\")\n",
        "        except Exception as e:\n",
        "            print(f\"    -> PDB 파일 읽기 오류: {e}\")\n",
        "\n",
        "        print(\"    -> PRODIGY 분석 시작...\")\n",
        "        prodigy_score = predict_binding_affinity_with_prodigy(pred_pdb)\n",
        "\n",
        "        if prodigy_score != 0.0:\n",
        "            print(f\"    -> PRODIGY 결과: {prodigy_score:.3f} kcal/mol\")\n",
        "        else:\n",
        "            print(\"    -> PRODIGY 결과: 0.000 (웹/대체 모두 실패)\")\n",
        "\n",
        "            # 간단한 대체 점수 (상호작용 기반)\n",
        "            try:\n",
        "                with open(pred_pdb, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "\n",
        "                # 최소 거리 기반 간단한 결합 에너지 추정\n",
        "                chain_a_coords = []\n",
        "                chain_b_coords = []\n",
        "\n",
        "                for line in lines:\n",
        "                    if line.startswith('ATOM'):\n",
        "                        chain = line[21]\n",
        "                        x, y, z = float(line[30:38]), float(line[38:46]), float(line[46:54])\n",
        "                        if chain == 'A':\n",
        "                            chain_a_coords.append((x, y, z))\n",
        "                        elif chain == 'B':\n",
        "                            chain_b_coords.append((x, y, z))\n",
        "\n",
        "                if chain_a_coords and chain_b_coords:\n",
        "                    min_distance = float('inf')\n",
        "                    contact_count = 0\n",
        "\n",
        "                    # 샘플링으로 계산량 감소\n",
        "                    for i, (ax, ay, az) in enumerate(chain_a_coords[::5]):  # 5개마다 샘플링\n",
        "                        for j, (bx, by, bz) in enumerate(chain_b_coords):\n",
        "                            dist = np.sqrt((ax-bx)**2 + (ay-by)**2 + (az-bz)**2)\n",
        "                            min_distance = min(min_distance, dist)\n",
        "                            if dist < 5.0:  # 5Å 이내 접촉\n",
        "                                contact_count += 1\n",
        "\n",
        "                    # 거리 기반 에너지 추정\n",
        "                    if min_distance < float('inf'):\n",
        "                        # 가까울수록 더 음수 (안정한 결합)\n",
        "                        prodigy_score = -5.0 - (10.0 / max(min_distance, 1.0)) - (contact_count * 0.1)\n",
        "                        prodigy_score = max(prodigy_score, -20.0)  # 최대 -20 kcal/mol\n",
        "                        print(f\"    -> 대체 점수: {prodigy_score:.3f} kcal/mol (최소거리: {min_distance:.2f}Å, 접촉: {contact_count})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    -> 대체 점수 계산 실패: {e}\")\n",
        "                prodigy_score = -5.0  # 기본값\n",
        "\n",
        "        # 상호작용 분석\n",
        "        print(\"    -> 상호작용 분석 중...\")\n",
        "        interactions = calculate_interactions_advanced(pred_pdb)\n",
        "        print(f\"    -> H-bonds: {interactions['h_bonds']}, Hydrophobic: {interactions['hydrophobic']}, Electrostatic: {interactions['electrostatic']}\")\n",
        "\n",
        "        # pTM 점수 확인\n",
        "        ptm_score = ptm_scores_map.get(peptide_seq, 0.0)\n",
        "        print(f\"    -> pTM 점수: {ptm_score}\")\n",
        "\n",
        "        # 최종 점수 계산 (개선된 가중치)\n",
        "        final_score = (\n",
        "            abs(prodigy_score) * 0.5 +           # PRODIGY 점수 (절대값)\n",
        "            interactions['total'] * 0.3 +        # 상호작용 수\n",
        "            ptm_score * 15 * 0.2                 # pTM 점수 강화\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            \"Peptide_Sequence\": peptide_seq,\n",
        "            \"Final_Score\": round(final_score, 3),\n",
        "            \"pTM_Score\": ptm_score,\n",
        "            \"PRODIGY_Score\": round(prodigy_score, 3),\n",
        "            \"H_bonds\": interactions['h_bonds'],\n",
        "            \"Hydrophobic\": interactions['hydrophobic'],\n",
        "            \"Electrostatic\": interactions['electrostatic'],\n",
        "            \"Total_Interactions\": interactions['total'],\n",
        "            \"Source_PDB\": os.path.basename(pred_pdb)\n",
        "        })\n",
        "\n",
        "        print(f\"    -> 최종 점수: {final_score:.3f}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ 평가할 PDB 파일이 없습니다.\")\n",
        "\n",
        "print(f\"\\n✅ {len(results)}개 구조 평가 완료\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 7: 최종 결과 저장\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 7: 최종 결과 정리 및 저장\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if results:\n",
        "    import pandas as pd\n",
        "\n",
        "    # DataFrame 생성 및 정렬\n",
        "    df = pd.DataFrame(results)\n",
        "    df_sorted = df.sort_values(\"Final_Score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # 엑셀 저장\n",
        "    df_sorted.to_excel(OUTPUT_FINAL_XLSX_PATH, index=False)\n",
        "\n",
        "    print(\"🏆 최종 펩타이드 랭킹:\")\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"{'순위':<4} {'펩타이드':<12} {'종합점수':<8} {'pTM':<6} {'PRODIGY':<8} {'상호작용':<8}\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    for i, row in df_sorted.head(10).iterrows():\n",
        "        print(f\"{i+1:<4} {row['Peptide_Sequence']:<12} {row['Final_Score']:<8.3f} \"\n",
        "              f\"{row['pTM_Score']:<6.3f} {row['PRODIGY_Score']:<8.3f} {row['Total_Interactions']:<8}\")\n",
        "\n",
        "    print(f\"\\n💾 전체 결과 저장: {OUTPUT_FINAL_XLSX_PATH}\")\n",
        "else:\n",
        "    print(\"❌ 평가 결과가 없습니다.\")\n",
        "\n",
        "# 실행 시간 요약\n",
        "pipeline_end_time = time.time()\n",
        "total_duration = pipeline_end_time - pipeline_start_time\n",
        "\n",
        "hours = int(total_duration // 3600)\n",
        "minutes = int((total_duration % 3600) // 60)\n",
        "seconds = int(total_duration % 60)\n",
        "\n",
        "# 👉 조건에 따라 출력 형식 달리하기\n",
        "if hours > 0:\n",
        "    print(f\"\\n⏱️  총 실행 시간: {hours}시간 {minutes}분 {seconds}초\")\n",
        "else:\n",
        "    print(f\"\\n⏱️  총 실행 시간: {minutes}분 {seconds}초\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"🎉 펩타이드 발굴 파이프라인 완료!\")\n",
        "print(\"=\"*80)"
      ]
    }
  ]
}