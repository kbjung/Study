{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlmbP7btofks",
        "outputId": "c32dd17f-95a2-48a9-beee-0d32920a1498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "STEP 0: í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì¤‘ë³µ ë°©ì§€)\n",
            "================================================================================\n",
            "âœ… ì´ë¯¸ ì„¤ì¹˜ëœ í™˜ê²½ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¤ì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\n",
            "\n",
            "# ì„¤ì¹˜ëœ ë„êµ¬ë“¤ì˜ ìƒíƒœ ìš”ì•½\n",
            "   â€¢ AutoDock Vina: âš ï¸ ê°„ë‹¨í•œ ì¶”ì • ì‚¬ìš©\n",
            "   â€¢ PLIP: âš ï¸ ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "   â€¢ PRODIGY(Web): ğŸŒ ì›¹ ì‹œë„/ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì ìˆ˜\n",
            "================================================================================\n",
            "\n",
            "STEP 1: ë³€ìˆ˜ ì„¤ì • ë° í´ë” êµ¬ì¡° ìƒì„±\n",
            "================================================================================\n",
            "âœ… í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ: PDP_20250916_110743\n",
            "ğŸ“Š ì„¤ì • ìš”ì•½:\n",
            "   â€¢ ì‘ì—… í´ë”: PDP_20250916_110743\n",
            "   â€¢ í©íƒ€ì´ë“œ ê°œìˆ˜: 10\n",
            "   â€¢ í©íƒ€ì´ë“œ ê¸¸ì´: 4\n",
            "   â€¢ íƒ€ê²Ÿ ì„œì—´ ê¸¸ì´: 222\n",
            "================================================================================\n",
            "\n",
            "STEP 2: ESM-2 í©íƒ€ì´ë“œ ìƒì„±\n",
            "================================================================================\n",
            "ESM-2 ëª¨ë¸ ë¡œë”©: facebook/esm2_t12_35M_UR50D\n",
            "\n",
            "ğŸ§¬ í©íƒ€ì´ë“œ ìƒì„± ì¤‘...\n",
            "  [ 1/10] VAIH\n",
            "  [ 2/10] EQIL\n",
            "  [ 3/10] KATT\n",
            "  [ 4/10] DGWY\n",
            "  [ 5/10] IHNK\n",
            "  [ 6/10] RCSC\n",
            "  [ 7/10] PTLT\n",
            "  [ 8/10] VSPG\n",
            "  [ 9/10] VATD\n",
            "  [10/10] CNLL\n",
            "\n",
            "âœ… 10ê°œ í©íƒ€ì´ë“œ ìƒì„± ì™„ë£Œ\n",
            "================================================================================\n",
            "\n",
            "STEP 3: ColabFold 3D êµ¬ì¡° ì˜ˆì¸¡\n",
            "================================================================================\n",
            "ColabFold ì‹¤í–‰ ì¤‘... (ì˜ˆìƒ ì‹œê°„: 10-30ë¶„)\n",
            "  âœ… ë³µí•©ì²´ 0: complex_0_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 1: complex_1_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 2: complex_2_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 3: complex_3_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 4: complex_4_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 5: complex_5_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 6: complex_6_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 7: complex_7_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 8: complex_8_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 9: complex_9_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "\n",
            "âœ… 10ê°œ êµ¬ì¡° ì˜ˆì¸¡ ì™„ë£Œ\n",
            "================================================================================\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_000/ranking_debug.json (from: no source â†’ zeros)\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_001/ranking_debug.json (from: no source â†’ zeros)\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_002/ranking_debug.json (from: no source â†’ zeros)\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_003/ranking_debug.json (from: no source â†’ zeros)\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_004/ranking_debug.json (from: no source â†’ zeros)\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_005/ranking_debug.json (from: no source â†’ zeros)\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_006/ranking_debug.json (from: no source â†’ zeros)\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_007/ranking_debug.json (from: no source â†’ zeros)\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_008/ranking_debug.json (from: no source â†’ zeros)\n",
            "ğŸ†• ranking_debug ìƒì„±: PDP_20250916_110743/pdb/complex_009/ranking_debug.json (from: no source â†’ zeros)\n",
            "STEP 3.5 ì™„ë£Œ â†’ ìƒì„± 10ê°œ, ì¬ì‚¬ìš© 0ê°œ (ê²€ìƒ‰ ë£¨íŠ¸: PDP_20250916_110743/pdb)\n",
            "\n",
            "STEP 3: ColabFold 3D êµ¬ì¡° ì˜ˆì¸¡\n",
            "================================================================================\n",
            "ColabFold ì‹¤í–‰ ì¤‘... (ì˜ˆìƒ ì‹œê°„: 10-30ë¶„)\n",
            "  âœ… ë³µí•©ì²´ 0: complex_0_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 1: complex_1_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 2: complex_2_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 3: complex_3_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 4: complex_4_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 5: complex_5_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 6: complex_6_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 7: complex_7_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 8: complex_8_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "  âœ… ë³µí•©ì²´ 9: complex_9_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "\n",
            "âœ… 10ê°œ êµ¬ì¡° ì˜ˆì¸¡ ì™„ë£Œ\n",
            "================================================================================\n",
            "STEP 3.5 ì™„ë£Œ â†’ ìƒì„± 0ê°œ, ì¬ì‚¬ìš© 10ê°œ (ê²€ìƒ‰ ë£¨íŠ¸: PDP_20250916_110743/pdb)\n",
            "\n",
            "STEP 4: pTM/ipTM ì ìˆ˜ ì¶”ì¶œ\n",
            "================================================================================\n",
            "ê²€ìƒ‰ ë£¨íŠ¸: PDP_20250916_110743/pdb\n",
            "ğŸ” í™•ì¸: complex_* ë””ë ‰í„°ë¦¬ 30ê°œ, ë£¨íŠ¸ ì ìˆ˜ JSON 10ê°œ\n",
            "âœ… pTM/ipTM ì ìˆ˜ ì¶”ì¶œ ì™„ë£Œ: 10ê°œ\n",
            "================================================================================\n",
            "\n",
            "STEP 6: ê²°í•©ë ¥ í‰ê°€ ë° ìµœì¢… ë­í‚¹\n",
            "================================================================================\n",
            "\n",
            "í‰ê°€ ì¤‘ (1/10): complex_0_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 147339 bytes\n",
            "    -> í©íƒ€ì´ë“œ: VAIH\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 30\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -10.396 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -10.396 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 7, Hydrophobic: 8, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 9.698\n",
            "\n",
            "í‰ê°€ ì¤‘ (2/10): complex_1_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 147663 bytes\n",
            "    -> í©íƒ€ì´ë“œ: EQIL\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 34\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -20.000 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -20.000 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 27, Hydrophobic: 121, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 54.400\n",
            "\n",
            "í‰ê°€ ì¤‘ (3/10): complex_2_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 147177 bytes\n",
            "    -> í©íƒ€ì´ë“œ: KATT\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 28\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -20.000 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -20.000 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 18, Hydrophobic: 151, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 60.700\n",
            "\n",
            "í‰ê°€ ì¤‘ (4/10): complex_3_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 147987 bytes\n",
            "    -> í©íƒ€ì´ë“œ: DGWY\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 38\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -11.226 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -11.226 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 3, Hydrophobic: 52, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 22.113\n",
            "\n",
            "í‰ê°€ ì¤‘ (5/10): complex_4_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 147744 bytes\n",
            "    -> í©íƒ€ì´ë“œ: IHNK\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 35\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -14.214 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -14.214 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 6, Hydrophobic: 34, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 19.107\n",
            "\n",
            "í‰ê°€ ì¤‘ (6/10): complex_5_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 147258 bytes\n",
            "    -> í©íƒ€ì´ë“œ: RCSC\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 29\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -15.160 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -15.160 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 19, Hydrophobic: 79, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 36.980\n",
            "\n",
            "í‰ê°€ ì¤‘ (7/10): complex_6_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 147258 bytes\n",
            "    -> í©íƒ€ì´ë“œ: PTLT\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 29\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -11.902 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -11.902 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 1, Hydrophobic: 18, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 11.651\n",
            "\n",
            "í‰ê°€ ì¤‘ (8/10): complex_7_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 146853 bytes\n",
            "    -> í©íƒ€ì´ë“œ: VSPG\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 24\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -20.000 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -20.000 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 30, Hydrophobic: 166, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 68.800\n",
            "\n",
            "í‰ê°€ ì¤‘ (9/10): complex_8_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 147096 bytes\n",
            "    -> í©íƒ€ì´ë“œ: VATD\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 27\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -9.242 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -9.242 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 10, Hydrophobic: 13, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 11.521\n",
            "\n",
            "í‰ê°€ ì¤‘ (10/10): complex_9_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb\n",
            "    -> PDB íŒŒì¼ í¬ê¸°: 147339 bytes\n",
            "    -> í©íƒ€ì´ë“œ: CNLL\n",
            "    -> Chain A ì›ììˆ˜: 1784\n",
            "    -> Chain B ì›ììˆ˜: 30\n",
            "    -> PRODIGY ë¶„ì„ ì‹œì‘...\n",
            "       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: -10.374 kcal/mol\n",
            "    -> PRODIGY ê²°ê³¼: -10.374 kcal/mol\n",
            "    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\n",
            "    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
            "    -> H-bonds: 4, Hydrophobic: 6, Electrostatic: 0\n",
            "    -> pTM ì ìˆ˜: 0.0\n",
            "    -> ìµœì¢… ì ìˆ˜: 8.187\n",
            "\n",
            "âœ… 10ê°œ êµ¬ì¡° í‰ê°€ ì™„ë£Œ\n",
            "================================================================================\n",
            "\n",
            "STEP 7: ìµœì¢… ê²°ê³¼ ì •ë¦¬ ë° ì €ì¥\n",
            "================================================================================\n",
            "ğŸ† ìµœì¢… í©íƒ€ì´ë“œ ë­í‚¹:\n",
            "====================================================================================================\n",
            "ìˆœìœ„   í©íƒ€ì´ë“œ         ì¢…í•©ì ìˆ˜     pTM    PRODIGY  ìƒí˜¸ì‘ìš©    \n",
            "====================================================================================================\n",
            "1    VSPG         68.800   0.000  -20.000  196     \n",
            "2    KATT         60.700   0.000  -20.000  169     \n",
            "3    EQIL         54.400   0.000  -20.000  148     \n",
            "4    RCSC         36.980   0.000  -15.160  98      \n",
            "5    DGWY         22.113   0.000  -11.226  55      \n",
            "6    IHNK         19.107   0.000  -14.214  40      \n",
            "7    PTLT         11.651   0.000  -11.902  19      \n",
            "8    VATD         11.521   0.000  -9.242   23      \n",
            "9    VAIH         9.698    0.000  -10.396  15      \n",
            "10   CNLL         8.187    0.000  -10.374  10      \n",
            "\n",
            "ğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥: PDP_20250916_110743/results/final_ranking_20250916_110743.xlsx\n",
            "\n",
            "â±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: 34ë¶„ 40ì´ˆ\n",
            "================================================================================\n",
            "ğŸ‰ í©íƒ€ì´ë“œ ë°œêµ´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ##############################################################################\n",
        "#\n",
        "# í†µí•© í©íƒ€ì´ë“œ ë°œêµ´ íŒŒì´í”„ë¼ì¸ (PRODIGY ê°œì„  ë²„ì „)\n",
        "# - ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘ë³µ ë°©ì§€\n",
        "# - íŒŒì¼ êµ¬ì¡° ê°œì„  (fasta/, pdb/ í´ë” ë¶„ë¦¬)\n",
        "#\n",
        "# ##############################################################################\n",
        "\n",
        "# to do\n",
        "# pdbíŒŒì¼ í•œë²ˆì— ë‹¤ìš´ ë°›ì„ ìˆ˜ ìˆê²Œ results í´ë”ì— ì••ì¶•í•´ì„œ ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ ì¶”ê°€\n",
        "\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import site\n",
        "import subprocess\n",
        "import shutil\n",
        "import re, glob, json, pickle\n",
        "\n",
        "# íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
        "pipeline_start_time = time.time()\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 0: í†µí•© í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì¤‘ë³µ ë°©ì§€)\n",
        "# ==============================================================================\n",
        "\n",
        "def check_and_install_libraries():\n",
        "    \"\"\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  í•„ìš”í•œ ê²ƒë§Œ ì„¤ì¹˜\"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"STEP 0: í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì¤‘ë³µ ë°©ì§€)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # ì„¤ì¹˜ í”Œë˜ê·¸ íŒŒì¼\n",
        "    install_flag_file = \"peptide_pipeline_installed.flag\"\n",
        "\n",
        "    if os.path.exists(install_flag_file):\n",
        "        print(\"âœ… ì´ë¯¸ ì„¤ì¹˜ëœ í™˜ê²½ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¤ì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "        return True\n",
        "\n",
        "    print(\"ğŸ”§ ì²« ì‹¤í–‰ì…ë‹ˆë‹¤. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "    try:\n",
        "        # 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "        print(\"\\n[1/6] ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜...\")\n",
        "        os.system(\"pip install -q pytz requests beautifulsoup4 openpyxl\")\n",
        "\n",
        "        # 2. ColabFold ì„¤ì¹˜\n",
        "        print(\"\\n[2/6] ColabFold ì„¤ì¹˜...\")\n",
        "        os.system(\"pip uninstall -y tensorflow tensorboard tb-nightly tensorflow-estimator tensorflow-hub tensorflow-io > /dev/null 2>&1\")\n",
        "        os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "        os.system(\"pip install -q --no-warn-conflicts 'jax[cuda11_pip]' -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\")\n",
        "\n",
        "        # ColabFold íŒ¨ì¹˜\n",
        "        try:\n",
        "            dist_packages_path = site.getsitepackages()[0]\n",
        "            batch_py_path = os.path.join(dist_packages_path, 'colabfold', 'batch.py')\n",
        "            if os.path.exists(batch_py_path):\n",
        "                os.system(f\"sed -i 's/tf.get_logger().setLevel(logging.ERROR)/#tf.get_logger().setLevel(logging.ERROR)/g' {batch_py_path}\")\n",
        "                print(\"   > ColabFold íŒ¨ì¹˜ ì™„ë£Œ\")\n",
        "        except:\n",
        "            print(\"   > ColabFold íŒ¨ì¹˜ ê±´ë„ˆëœ€\")\n",
        "\n",
        "        # 3. í©íƒ€ì´ë“œ ìƒì„± ëª¨ë¸\n",
        "        print(\"\\n[3/6] Transformers ì„¤ì¹˜...\")\n",
        "        os.system(\"pip install -q --upgrade transformers sentencepiece\")\n",
        "\n",
        "        # 4. í™”í•™ ì •ë³´í•™ ë„êµ¬\n",
        "        print(\"\\n[4/6] í™”í•™ ì •ë³´í•™ ë„êµ¬ ì„¤ì¹˜...\")\n",
        "        os.system(\"apt-get update -qq > /dev/null 2>&1\")\n",
        "        os.system(\"apt-get install -y --quiet openbabel python3-openbabel libopenbabel-dev > /dev/null 2>&1\")\n",
        "        os.system(\"pip install -q openbabel-wheel rdkit-pypi biopython ProLIF MDAnalysis oddt scikit-learn plip\")\n",
        "\n",
        "        # 5. AutoDock Vina\n",
        "        print(\"\\n[5/6] AutoDock Vina ì„¤ì¹˜...\")\n",
        "        setup_vina_robust()\n",
        "\n",
        "        # 6. ì¶”ê°€ ë„êµ¬\n",
        "        print(\"\\n[6/6] ì¶”ê°€ ë„êµ¬ ì„¤ì¹˜...\")\n",
        "        os.system(\"pip install -q pymol-open-source meeko > /dev/null 2>&1\")\n",
        "\n",
        "        # ì„¤ì¹˜ ì™„ë£Œ í”Œë˜ê·¸ ìƒì„±\n",
        "        with open(install_flag_file, 'w') as f:\n",
        "            f.write(f\"Installed at: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        print(\"\\nâœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        return False\n",
        "\n",
        "def setup_vina_robust():\n",
        "    \"\"\"AutoDock Vina ì„¤ì¹˜\"\"\"\n",
        "    vina_dir = \"vina_1.2.3_linux_x86_64\"\n",
        "\n",
        "    if not os.path.exists(vina_dir):\n",
        "        download_commands = [\n",
        "            \"wget -q https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip\",\n",
        "            \"curl -L -o vina_1.2.3_linux_x86_64.zip https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip\"\n",
        "        ]\n",
        "\n",
        "        for cmd in download_commands:\n",
        "            if os.system(cmd) == 0:\n",
        "                break\n",
        "\n",
        "        os.system(\"unzip -q -o vina_1.2.3_linux_x86_64.zip\")\n",
        "\n",
        "        for executable in [f\"{vina_dir}/vina\", f\"{vina_dir}/bin/vina\"]:\n",
        "            if os.path.exists(executable):\n",
        "                os.chmod(executable, 0o755)\n",
        "\n",
        "    # Vina ì‹¤í–‰íŒŒì¼ ê²½ë¡œ ë°˜í™˜\n",
        "    for path in [f\"./{vina_dir}/vina\", f\"./{vina_dir}/bin/vina\", \"vina\"]:\n",
        "        if os.path.exists(path) and os.access(path, os.X_OK):\n",
        "            return os.path.abspath(path)\n",
        "    return None\n",
        "\n",
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì‹¤í–‰\n",
        "if not check_and_install_libraries():\n",
        "    print(\"âŒ ì„¤ì¹˜ ì‹¤íŒ¨. íŒŒì´í”„ë¼ì¸ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Vina ì‹¤í–‰íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "VINA_EXECUTABLE = setup_vina_robust()\n",
        "PLIP_AVAILABLE = (shutil.which(\"plipcmd\") is not None)\n",
        "\n",
        "print(\"\\n# ì„¤ì¹˜ëœ ë„êµ¬ë“¤ì˜ ìƒíƒœ ìš”ì•½\")\n",
        "print(f\"   â€¢ AutoDock Vina: {'âœ… ì„¤ì¹˜ë¨' if VINA_EXECUTABLE else 'âš ï¸ ê°„ë‹¨í•œ ì¶”ì • ì‚¬ìš©'}\")\n",
        "print(f\"   â€¢ PLIP: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if PLIP_AVAILABLE else 'âš ï¸ ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©'}\")\n",
        "print(f\"   â€¢ PRODIGY(Web): ğŸŒ ì›¹ ì‹œë„/ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì ìˆ˜\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 1: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë³€ìˆ˜ ì„¤ì • ë° í´ë” êµ¬ì¡° ìƒì„±\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 1: ë³€ìˆ˜ ì„¤ì • ë° í´ë” êµ¬ì¡° ìƒì„±\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# --- ì‚¬ìš©ì ì„¤ì • ---\n",
        "N_PEPTIDES = 10\n",
        "TARGET_PROTEIN_SEQUENCE = \"AFTVTVPKDLYVVEYGSNMTIECKFPVEKQLDLAALIVYWEMEDKNIIQFVHGEEDLKVQHSSYRQRARLLKDQLSLGNAALQITDVKLQDAGVYRCMISYGGADYKRITVKVNAPYNKINQRILVVDPVTSEHELTCQAEGYPKAEVIWTSSDHQVLSGKTTTTNSKREEKLFNVTSTLRINTTTNEIFYCTFRRLDPEENHTAELVIPELPLAHPPNERT\"\n",
        "PEPTIDE_LENGTH = 4\n",
        "BASE_FOLDER_PREFIX = \"PDP\"\n",
        "\n",
        "# í•œêµ­ ì‹œê°„ ê¸°ë°˜ í´ë”ëª… ìƒì„±\n",
        "kst = pytz.timezone('Asia/Seoul')\n",
        "now_kst = datetime.now(kst)\n",
        "timestamp = now_kst.strftime(\"%Y%m%d_%H%M%S\")\n",
        "JOB_NAME = f\"{BASE_FOLDER_PREFIX}_{timestamp}\"\n",
        "\n",
        "# ğŸ“ ê°œì„ ëœ í´ë” êµ¬ì¡° ìƒì„±\n",
        "def create_project_structure():\n",
        "    \"\"\"í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ìƒì„±\"\"\"\n",
        "    folders = [\n",
        "        JOB_NAME,\n",
        "        os.path.join(JOB_NAME, \"fasta\"),      # FASTA íŒŒì¼ ì „ìš©\n",
        "        os.path.join(JOB_NAME, \"pdb\"),        # PDB íŒŒì¼ ì „ìš©\n",
        "        os.path.join(JOB_NAME, \"results\"),    # ê²°ê³¼ íŒŒì¼\n",
        "        os.path.join(JOB_NAME, \"temp\")        # ì„ì‹œ íŒŒì¼\n",
        "    ]\n",
        "\n",
        "    for folder in folders:\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    print(f\"âœ… í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ: {JOB_NAME}\")\n",
        "    return folders\n",
        "\n",
        "create_project_structure()\n",
        "\n",
        "# íŒŒì¼ ê²½ë¡œ ì„¤ì • (ê°œì„ ëœ êµ¬ì¡°)\n",
        "PROTEIN_FASTA_PATH = os.path.join(JOB_NAME, \"fasta\", \"target_protein.fasta\")\n",
        "OUTPUT_FINAL_XLSX_PATH = os.path.join(JOB_NAME, \"results\", f\"final_ranking_{timestamp}.xlsx\")\n",
        "\n",
        "# íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ FASTA íŒŒì¼ ì €ì¥\n",
        "with open(PROTEIN_FASTA_PATH, \"w\") as f:\n",
        "    f.write(f\">target_protein\\n{TARGET_PROTEIN_SEQUENCE}\\n\")\n",
        "\n",
        "print(f\"ğŸ“Š ì„¤ì • ìš”ì•½:\")\n",
        "print(f\"   â€¢ ì‘ì—… í´ë”: {JOB_NAME}\")\n",
        "print(f\"   â€¢ í©íƒ€ì´ë“œ ê°œìˆ˜: {N_PEPTIDES}\")\n",
        "print(f\"   â€¢ í©íƒ€ì´ë“œ ê¸¸ì´: {PEPTIDE_LENGTH}\")\n",
        "print(f\"   â€¢ íƒ€ê²Ÿ ì„œì—´ ê¸¸ì´: {len(TARGET_PROTEIN_SEQUENCE)}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: ESM-2 í©íƒ€ì´ë“œ ìƒì„±\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 2: ESM-2 í©íƒ€ì´ë“œ ìƒì„±\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# ESM-2 ëª¨ë¸ ë¡œë“œ\n",
        "model_name = \"facebook/esm2_t12_35M_UR50D\"\n",
        "print(f\"ESM-2 ëª¨ë¸ ë¡œë”©: {model_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# í©íƒ€ì´ë“œ ìƒì„±\n",
        "formatted_target = \" \".join(list(TARGET_PROTEIN_SEQUENCE))\n",
        "mask_tokens = \" \".join([tokenizer.mask_token] * PEPTIDE_LENGTH)\n",
        "prompt = f\"{tokenizer.cls_token} {formatted_target} {tokenizer.eos_token} {mask_tokens}\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "mask_token_indices = (input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
        "\n",
        "peptides = []\n",
        "peptide_fasta_paths = []\n",
        "\n",
        "print(\"\\nğŸ§¬ í©íƒ€ì´ë“œ ìƒì„± ì¤‘...\")\n",
        "with torch.no_grad():\n",
        "    for i in range(N_PEPTIDES):\n",
        "        current_ids = input_ids.clone().to(model.device)\n",
        "        shuffled_mask_indices = mask_token_indices[torch.randperm(len(mask_token_indices))]\n",
        "\n",
        "        for mask_idx in shuffled_mask_indices:\n",
        "            outputs = model(input_ids=current_ids)\n",
        "            logits = outputs.logits[0, mask_idx, :] / 1.0  # temperature\n",
        "            top_k_values, top_k_indices = torch.topk(logits, min(50, tokenizer.vocab_size))\n",
        "            filter_tensor = torch.full_like(logits, -float('Inf'))\n",
        "            filter_tensor.scatter_(0, top_k_indices, top_k_values)\n",
        "            probs = F.softmax(filter_tensor, dim=-1)\n",
        "            predicted_token_id = torch.multinomial(probs, num_samples=1)\n",
        "            current_ids[0, mask_idx] = predicted_token_id.item()\n",
        "\n",
        "        generated_token_ids = current_ids[0, mask_token_indices]\n",
        "        sequence = \"\".join(tokenizer.decode(generated_token_ids, skip_special_tokens=True).split())\n",
        "        peptides.append(sequence)\n",
        "\n",
        "        # ğŸ“ FASTA í´ë”ì— ì €ì¥\n",
        "        fasta_path = os.path.join(JOB_NAME, \"fasta\", f\"peptide_{i}.fasta\")\n",
        "        with open(fasta_path, \"w\") as f:\n",
        "            f.write(f\">peptide_{i}\\n{sequence}\\n\")\n",
        "        peptide_fasta_paths.append(fasta_path)\n",
        "        print(f\"  [{i+1:2d}/{N_PEPTIDES}] {sequence}\")\n",
        "\n",
        "print(f\"\\nâœ… {N_PEPTIDES}ê°œ í©íƒ€ì´ë“œ ìƒì„± ì™„ë£Œ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: ColabFold êµ¬ì¡° ì˜ˆì¸¡\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 3: ColabFold 3D êµ¬ì¡° ì˜ˆì¸¡\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ë°°ì¹˜ CSV íŒŒì¼ ìƒì„±\n",
        "batch_csv_path = os.path.join(JOB_NAME, \"temp\", \"batch_complexes.csv\")\n",
        "with open(batch_csv_path, \"w\") as f:\n",
        "    f.write(\"id,sequence\\n\")\n",
        "    for i, peptide_seq in enumerate(peptides):\n",
        "        complex_sequence = f\"{TARGET_PROTEIN_SEQUENCE}:{peptide_seq}\"\n",
        "        f.write(f\"complex_{i},{complex_sequence}\\n\")\n",
        "\n",
        "# ColabFold ì‹¤í–‰\n",
        "output_dir = os.path.join(JOB_NAME, \"pdb\")  # ğŸ“ PDB í´ë”ì— ì§ì ‘ ì €ì¥\n",
        "log_file = os.path.join(JOB_NAME, \"temp\", \"colabfold.log\")\n",
        "\n",
        "print(f\"ColabFold ì‹¤í–‰ ì¤‘... (ì˜ˆìƒ ì‹œê°„: 10-30ë¶„)\")\n",
        "colabfold_cmd = (f\"colabfold_batch \"\n",
        "                f\"--num-recycle 1 \"\n",
        "                f\"--model-type alphafold2_multimer_v3 \"\n",
        "                f\"--rank ptm \"\n",
        "                f\"--max-msa 32:128 \"\n",
        "                f\"--num-models 1 \"\n",
        "                f\"--stop-at-score 0.5 \"\n",
        "                f\"{batch_csv_path} {output_dir} > {log_file} 2>&1\")\n",
        "\n",
        "result = os.system(colabfold_cmd)\n",
        "\n",
        "# PDB íŒŒì¼ ìˆ˜ì§‘\n",
        "predicted_pdb_files = []\n",
        "for i in range(N_PEPTIDES):\n",
        "    pdb_pattern = os.path.join(output_dir, f\"complex_{i}_unrelaxed_rank_001*.pdb\")\n",
        "    pdb_files = sorted(glob.glob(pdb_pattern))\n",
        "    if pdb_files:\n",
        "        predicted_pdb_files.append(pdb_files[0])\n",
        "        print(f\"  âœ… ë³µí•©ì²´ {i}: {os.path.basename(pdb_files[0])}\")\n",
        "\n",
        "print(f\"\\nâœ… {len(predicted_pdb_files)}ê°œ êµ¬ì¡° ì˜ˆì¸¡ ì™„ë£Œ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3.5: ColabFold ê²°ê³¼ì—ì„œ pTM/ipTM JSON ìƒì„± (ranking_debug.json ë³´ì¥)\n",
        "#  - ìœ„ì¹˜: STEP 3(êµ¬ì¡° ì˜ˆì¸¡) ì§í›„, STEP 4 ì§ì „ì— ì¶”ê°€\n",
        "#  - ì „ì œ: output_dir = os.path.join(JOB_NAME, \"pdb\")  # PRED_ROOTëŠ” output_dir\n",
        "# ==============================================================================\n",
        "\n",
        "# ë„ˆì˜ ì½”ë“œì—ì„œ ì´ë¯¸ ì´ë ‡ê²Œ ë˜ì–´ìˆìŒ:\n",
        "# output_dir = os.path.join(JOB_NAME, \"pdb\")\n",
        "PRED_ROOT = output_dir\n",
        "\n",
        "assert os.path.isdir(PRED_ROOT), f\"ColabFold ì¶œë ¥ í´ë”ê°€ ì—†ìŒ: {PRED_ROOT}\"\n",
        "\n",
        "def _to_float(x):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def _load_metrics_from_any(path_like):\n",
        "    \"\"\"\n",
        "    ë””ë ‰í„°ë¦¬ ë˜ëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ iptm/ptmì„ ì¶”ì¶œ.\n",
        "    ìš°ì„ ìˆœìœ„:\n",
        "      1) ranking_debug.json\n",
        "      2) result_model_*_multimer*.json\n",
        "      3) result_model_*_multimer*.pkl\n",
        "    ë°˜í™˜: (iptm, ptm, source_path or None)\n",
        "    \"\"\"\n",
        "    to_try = []\n",
        "\n",
        "    if os.path.isdir(path_like):\n",
        "        to_try.append(os.path.join(path_like, \"ranking_debug.json\"))\n",
        "        to_try += glob.glob(os.path.join(path_like, \"result_model_*_multimer*.json\"))\n",
        "        to_try += glob.glob(os.path.join(path_like, \"result_model_*_multimer*.pkl\"))\n",
        "    else:\n",
        "        to_try.append(path_like)\n",
        "\n",
        "    for p in to_try:\n",
        "        if not os.path.exists(p):\n",
        "            continue\n",
        "        try:\n",
        "            if p.endswith(\".json\"):\n",
        "                with open(p, \"r\") as f:\n",
        "                    data = json.load(f)\n",
        "                rc = data.get(\"ranking_confidences\", {})\n",
        "                iptm = _to_float(data.get(\"iptm\") or rc.get(\"iptm\") or rc.get(\"iptm+ptm\") or data.get(\"iptm_score\"))\n",
        "                ptm  = _to_float(data.get(\"ptm\")  or rc.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "                if iptm is not None or ptm is not None:\n",
        "                    return iptm, ptm, p\n",
        "            elif p.endswith(\".pkl\"):\n",
        "                with open(p, \"rb\") as f:\n",
        "                    data = pickle.load(f)\n",
        "                iptm = _to_float(data.get(\"iptm\") or data.get(\"iptm_score\"))\n",
        "                ptm  = _to_float(data.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "                if iptm is None or ptm is None:\n",
        "                    mc = data.get(\"model_confidence\", {}) or data.get(\"ranking_confidences\", {})\n",
        "                    iptm = _to_float(iptm if iptm is not None else (mc.get(\"iptm\") or mc.get(\"iptm+ptm\")))\n",
        "                    ptm  = _to_float(ptm  if ptm  is not None else mc.get(\"ptm\"))\n",
        "                if iptm is not None or ptm is not None:\n",
        "                    return iptm, ptm, p\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return None, None, None\n",
        "\n",
        "def _ensure_ranking_debug_json(dir_path, iptm, ptm, source=None):\n",
        "    \"\"\"\n",
        "    dir_pathëŠ” ë°˜ë“œì‹œ 'í´ë”'ì—¬ì•¼ í•¨. ì—†ìœ¼ë©´ ë§Œë“  ë’¤ ranking_debug.json ìƒì„±/ê°±ì‹ .\n",
        "    \"\"\"\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    out_path = os.path.join(dir_path, \"ranking_debug.json\")\n",
        "    payload = {\n",
        "        \"iptm\": iptm if iptm is not None else 0.0,\n",
        "        \"ptm\":  ptm  if ptm  is not None else 0.0,\n",
        "        \"ranking_confidences\": {\n",
        "            \"iptm\": iptm if iptm is not None else 0.0,\n",
        "            \"ptm\":  ptm  if ptm  is not None else 0.0,\n",
        "            \"iptm+ptm\": ((iptm or 0.0) + (ptm or 0.0))/2.0\n",
        "        },\n",
        "        \"_generated_from\": source or \"unknown\"\n",
        "    }\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(payload, f, indent=2)\n",
        "    return out_path\n",
        "\n",
        "def _collect_complex_ids(root):\n",
        "    \"\"\"\n",
        "    í‰ë©´(.a3m/.pdb) + í´ë” ë‘˜ ë‹¤ì—ì„œ complex IDë¥¼ ìˆ˜ì§‘\n",
        "    \"\"\"\n",
        "    ids = set()\n",
        "\n",
        "    # í´ë” ì´ë¦„ì—ì„œ ì¶”ì¶œ (ì§„ì§œ í´ë”ë§Œ)\n",
        "    for d in glob.glob(os.path.join(root, \"complex_*\")):\n",
        "        if os.path.isdir(d):\n",
        "            m = re.search(r\"complex_(\\d+)\", os.path.basename(d))\n",
        "            if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    # í‰ë©´ íŒŒì¼(.a3m)ì—ì„œ ì¶”ì¶œ\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*.a3m\")):\n",
        "        m = re.search(r\"complex_(\\d+)\\.a3m$\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    # í‰ë©´ íŒŒì¼(.pdb)ì—ì„œ ì¶”ì¶œ\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*_unrelaxed_rank_*.pdb\")):\n",
        "        m = re.search(r\"complex_(\\d+)_\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    return sorted(ids)\n",
        "\n",
        "created, reused = 0, 0\n",
        "complex_ids = _collect_complex_ids(PRED_ROOT)\n",
        "\n",
        "if complex_ids:\n",
        "    for cid in complex_ids:\n",
        "        # ëŒ€ìƒ ë””ë ‰í„°ë¦¬(ë³´ì¥ í´ë”): PRED_ROOT/complex_{cid:03d}\n",
        "        cdir = os.path.join(PRED_ROOT, f\"complex_{cid:03d}\")\n",
        "\n",
        "        # ë¨¼ì € cdir ë‚´ë¶€ì—ì„œ ì‹œë„ (ì´ë¯¸ í´ë” êµ¬ì¡°ê°€ ìˆìœ¼ë©´)\n",
        "        iptm, ptm, src = _load_metrics_from_any(cdir)\n",
        "\n",
        "        # ì—†ìœ¼ë©´ ë£¨íŠ¸(PRED_ROOT)ì—ì„œ í•´ë‹¹ complex ê´€ë ¨ íŒŒì¼ë“¤ë¡œ ì‹œë„\n",
        "        if iptm is None and ptm is None:\n",
        "            # ranking_debug.json / result_model_* in root\n",
        "            # (ì¼ë¶€ í™˜ê²½ì€ rootì—ë§Œ ë–¨ì–´ì§ â†’ ê°™ì€ ê°’ì„ ë³µì œ)\n",
        "            for pat in [\n",
        "                os.path.join(PRED_ROOT, \"ranking_debug.json\"),\n",
        "                os.path.join(PRED_ROOT, \"result_model_*_multimer*.json\"),\n",
        "                os.path.join(PRED_ROOT, \"result_model_*_multimer*.pkl\"),\n",
        "            ]:\n",
        "                for p in glob.glob(pat):\n",
        "                    iptm, ptm, src = _load_metrics_from_any(p)\n",
        "                    if iptm is not None or ptm is not None:\n",
        "                        break\n",
        "                if iptm is not None or ptm is not None:\n",
        "                    break\n",
        "\n",
        "        # ìµœì¢…ì ìœ¼ë¡œ í´ë”ë¥¼ ë§Œë“¤ê³  ranking_debug.jsonì„ ë³´ì¥ ìƒì„±\n",
        "        rd_path = os.path.join(cdir, \"ranking_debug.json\")\n",
        "        need_create = (not os.path.isfile(rd_path)) or (iptm is None and ptm is None)\n",
        "\n",
        "        if need_create:\n",
        "            outp = _ensure_ranking_debug_json(cdir, iptm, ptm, source=src)\n",
        "            print(f\"ğŸ†• ranking_debug ìƒì„±: {outp} (from: {src or 'no source â†’ zeros'})\")\n",
        "            created += 1\n",
        "        else:\n",
        "            reused += 1\n",
        "else:\n",
        "    # complex_* IDë¥¼ ì „í˜€ ëª» ì°¾ì€ ê²½ìš° â†’ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ í•˜ë‚˜ ë§Œë“¤ì–´ ë‘ê¸°(ìµœì†Œ ë³´ì¥)\n",
        "    iptm, ptm, src = _load_metrics_from_any(PRED_ROOT)\n",
        "    outp = _ensure_ranking_debug_json(PRED_ROOT, iptm, ptm, source=src)\n",
        "    print(f\"ğŸ†• ranking_debug ìƒì„±(ë£¨íŠ¸): {outp} (from: {src or 'no source â†’ zeros'})\")\n",
        "    created += 1\n",
        "\n",
        "print(f\"STEP 3.5 ì™„ë£Œ â†’ ìƒì„± {created}ê°œ, ì¬ì‚¬ìš© {reused}ê°œ (ê²€ìƒ‰ ë£¨íŠ¸: {PRED_ROOT})\")\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: ColabFold êµ¬ì¡° ì˜ˆì¸¡\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 3: ColabFold 3D êµ¬ì¡° ì˜ˆì¸¡\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ë°°ì¹˜ CSV íŒŒì¼ ìƒì„±\n",
        "batch_csv_path = os.path.join(JOB_NAME, \"temp\", \"batch_complexes.csv\")\n",
        "with open(batch_csv_path, \"w\") as f:\n",
        "    f.write(\"id,sequence\\n\")\n",
        "    for i, peptide_seq in enumerate(peptides):\n",
        "        complex_sequence = f\"{TARGET_PROTEIN_SEQUENCE}:{peptide_seq}\"\n",
        "        f.write(f\"complex_{i},{complex_sequence}\\n\")\n",
        "\n",
        "# ColabFold ì‹¤í–‰\n",
        "output_dir = os.path.join(JOB_NAME, \"pdb\")  # ğŸ“ PDB í´ë”ì— ì§ì ‘ ì €ì¥\n",
        "log_file = os.path.join(JOB_NAME, \"temp\", \"colabfold.log\")\n",
        "\n",
        "print(f\"ColabFold ì‹¤í–‰ ì¤‘... (ì˜ˆìƒ ì‹œê°„: 10-30ë¶„)\")\n",
        "colabfold_cmd = (f\"colabfold_batch \"\n",
        "                f\"--num-recycle 1 \"\n",
        "                f\"--model-type alphafold2_multimer_v3 \"\n",
        "                f\"--rank ptm \"\n",
        "                f\"--max-msa 32:128 \"\n",
        "                f\"--num-models 1 \"\n",
        "                f\"--stop-at-score 0.5 \"\n",
        "                f\"{batch_csv_path} {output_dir} > {log_file} 2>&1\")\n",
        "\n",
        "result = os.system(colabfold_cmd)\n",
        "\n",
        "# PDB íŒŒì¼ ìˆ˜ì§‘\n",
        "predicted_pdb_files = []\n",
        "for i in range(N_PEPTIDES):\n",
        "    pdb_pattern = os.path.join(output_dir, f\"complex_{i}_unrelaxed_rank_001*.pdb\")\n",
        "    pdb_files = sorted(glob.glob(pdb_pattern))\n",
        "    if pdb_files:\n",
        "        predicted_pdb_files.append(pdb_files[0])\n",
        "        print(f\"  âœ… ë³µí•©ì²´ {i}: {os.path.basename(pdb_files[0])}\")\n",
        "\n",
        "print(f\"\\nâœ… {len(predicted_pdb_files)}ê°œ êµ¬ì¡° ì˜ˆì¸¡ ì™„ë£Œ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3.5: ColabFold ê²°ê³¼ì—ì„œ pTM/ipTM JSON ìƒì„± (ranking_debug.json ë³´ì¥)\n",
        "#  - ì „ì œ: output_dir = os.path.join(JOB_NAME, \"pdb\")  # PRED_ROOTëŠ” output_dir\n",
        "#  - í´ë” íŠ¸ë¦¬ ê°€ì •: PRED_ROOT ë£¨íŠ¸ì— complex_0_scores_rank_*.json íŒŒì¼ ì¡´ì¬ ê°€ëŠ¥\n",
        "# ==============================================================================\n",
        "\n",
        "PRED_ROOT = output_dir  # = os.path.join(JOB_NAME, \"pdb\")\n",
        "assert os.path.isdir(PRED_ROOT), f\"ColabFold ì¶œë ¥ í´ë”ê°€ ì—†ìŒ: {PRED_ROOT}\"\n",
        "\n",
        "def _to_float(x):\n",
        "    try: return float(x)\n",
        "    except: return None\n",
        "\n",
        "def _load_metrics_from_any(path_like):\n",
        "    \"\"\"\n",
        "    ë””ë ‰í„°ë¦¬ ë˜ëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ iptm/ptmì„ ì¶”ì¶œ.\n",
        "    ìš°ì„ ìˆœìœ„:\n",
        "      1) ranking_debug.json\n",
        "      2) result_model_*_multimer*.json\n",
        "      3) result_model_*_multimer*.pkl\n",
        "      4) complex_*_scores_rank_*.json   <-- (ì‹ ê·œ) ë£¨íŠ¸ ì ìˆ˜ JSON\n",
        "    ë°˜í™˜: (iptm, ptm, source_path or None)\n",
        "    \"\"\"\n",
        "    def _try_json(fp):\n",
        "        try:\n",
        "            with open(fp, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "        except Exception:\n",
        "            return None, None\n",
        "        rc   = data.get(\"ranking_confidences\", {}) if isinstance(data, dict) else {}\n",
        "        iptm = _to_float(data.get(\"iptm\") or rc.get(\"iptm\") or rc.get(\"iptm+ptm\") or data.get(\"iptm_score\"))\n",
        "        ptm  = _to_float(data.get(\"ptm\")  or rc.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "        # ColabFold scores_rank JSONì— ì§ì ‘ 'iptm','ptm' í‚¤ê°€ ë“¤ì–´ìˆëŠ” ê²½ìš°ê°€ ë§ìŒ\n",
        "        if iptm is None: iptm = _to_float(data.get(\"iptm\"))\n",
        "        if ptm  is None: ptm  = _to_float(data.get(\"ptm\"))\n",
        "        return iptm, ptm\n",
        "\n",
        "    def _try_pkl(fp):\n",
        "        try:\n",
        "            with open(fp, \"rb\") as f:\n",
        "                data = pickle.load(f)\n",
        "        except Exception:\n",
        "            return None, None\n",
        "        iptm = _to_float(data.get(\"iptm\") or data.get(\"iptm_score\"))\n",
        "        ptm  = _to_float(data.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "        if iptm is None or ptm is None:\n",
        "            mc = data.get(\"model_confidence\", {}) or data.get(\"ranking_confidences\", {})\n",
        "            if iptm is None: iptm = _to_float(mc.get(\"iptm\") or mc.get(\"iptm+ptm\"))\n",
        "            if ptm  is None: ptm  = _to_float(mc.get(\"ptm\"))\n",
        "        return iptm, ptm\n",
        "\n",
        "    # 1) ë””ë ‰í„°ë¦¬ë¼ë©´ ë‚´ë¶€ ìš°ì„  ì‹œë„\n",
        "    if os.path.isdir(path_like):\n",
        "        rd = os.path.join(path_like, \"ranking_debug.json\")\n",
        "        if os.path.isfile(rd):\n",
        "            iptm, ptm = _try_json(rd)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, rd\n",
        "        for jp in glob.glob(os.path.join(path_like, \"result_model_*_multimer*.json\")):\n",
        "            iptm, ptm = _try_json(jp)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, jp\n",
        "        for pk in glob.glob(os.path.join(path_like, \"result_model_*_multimer*.pkl\")):\n",
        "            iptm, ptm = _try_pkl(pk)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, pk\n",
        "\n",
        "    # 2) íŒŒì¼ ê²½ë¡œë¼ë©´ ì§ì ‘ ì‹œë„\n",
        "    if os.path.isfile(path_like):\n",
        "        if path_like.endswith(\".json\"):\n",
        "            iptm, ptm = _try_json(path_like)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, path_like\n",
        "        elif path_like.endswith(\".pkl\"):\n",
        "            iptm, ptm = _try_pkl(path_like)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                return iptm, ptm, path_like\n",
        "\n",
        "    return None, None, None\n",
        "\n",
        "def _ensure_ranking_debug_json(dir_path, iptm, ptm, source=None):\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    out_path = os.path.join(dir_path, \"ranking_debug.json\")\n",
        "    payload = {\n",
        "        \"iptm\": iptm if iptm is not None else 0.0,\n",
        "        \"ptm\":  ptm  if ptm  is not None else 0.0,\n",
        "        \"ranking_confidences\": {\n",
        "            \"iptm\": iptm if iptm is not None else 0.0,\n",
        "            \"ptm\":  ptm  if ptm  is not None else 0.0,\n",
        "            \"iptm+ptm\": ((iptm or 0.0) + (ptm or 0.0))/2.0\n",
        "        },\n",
        "        \"_generated_from\": source or \"unknown\"\n",
        "    }\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(payload, f, indent=2)\n",
        "    return out_path\n",
        "\n",
        "def _collect_complex_ids(root):\n",
        "    \"\"\"í´ë”/í‰ë©´/ì ìˆ˜ JSONì—ì„œ complex ID ëª¨ë‘ ìˆ˜ì§‘ (0, 1, ... â†’ ì •ë ¬)\"\"\"\n",
        "    ids = set()\n",
        "\n",
        "    # í´ë”\n",
        "    for d in glob.glob(os.path.join(root, \"complex_*\")):\n",
        "        if os.path.isdir(d):\n",
        "            m = re.search(r\"complex_(\\d+)$\", os.path.basename(d))\n",
        "            if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    # í‰ë©´ .a3m / .pdb\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*.a3m\")):\n",
        "        m = re.search(r\"complex_(\\d+)\\.a3m$\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*_unrelaxed_rank_*.pdb\")):\n",
        "        m = re.search(r\"complex_(\\d+)_\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    # â¬…ï¸ ì ìˆ˜ JSON (ë„¤ê°€ ë³´ì—¬ì¤€ íŒŒì¼: complex_0_scores_rank_001_...json)\n",
        "    for f in glob.glob(os.path.join(root, \"complex_*_scores_rank_*.json\")):\n",
        "        m = re.search(r\"complex_(\\d+)_scores_rank_\", os.path.basename(f))\n",
        "        if m: ids.add(int(m.group(1)))\n",
        "\n",
        "    return sorted(ids)\n",
        "\n",
        "def _find_root_score_jsons_for_id(root, cid):\n",
        "    \"\"\"ë£¨íŠ¸ì— ìˆëŠ” ì´ IDìš© ì ìˆ˜ JSON í›„ë³´ ëª©ë¡\"\"\"\n",
        "    pats = [\n",
        "        os.path.join(root, f\"complex_{cid}_scores_rank_*.json\"),\n",
        "        os.path.join(root, f\"complex_{cid:03d}_scores_rank_*.json\"),\n",
        "    ]\n",
        "    out = []\n",
        "    for p in pats:\n",
        "        out += glob.glob(p)\n",
        "    return sorted(out)\n",
        "\n",
        "created, reused = 0, 0\n",
        "complex_ids = _collect_complex_ids(PRED_ROOT)\n",
        "\n",
        "for cid in complex_ids:\n",
        "    cdir = os.path.join(PRED_ROOT, f\"complex_{cid:03d}\")\n",
        "\n",
        "    # 1) ë¨¼ì € í•´ë‹¹ í´ë” ì•ˆì—ì„œ ì‹œë„\n",
        "    iptm, ptm, src = _load_metrics_from_any(cdir)\n",
        "\n",
        "    # 2) ì‹¤íŒ¨í•˜ë©´ ë£¨íŠ¸ ì ìˆ˜ JSON( complex_{id}_scores_rank_*.json )ì—ì„œ ì‹œë„\n",
        "    if iptm is None and ptm is None:\n",
        "        for jf in _find_root_score_jsons_for_id(PRED_ROOT, cid):\n",
        "            iptm, ptm, src = _load_metrics_from_any(jf)\n",
        "            if iptm is not None or ptm is not None:\n",
        "                break\n",
        "\n",
        "    # 3) ê·¸ë˜ë„ ì—†ìœ¼ë©´ ë£¨íŠ¸ì˜ result_model* ì‹œë„(í™˜ê²½ì— ë”°ë¼ ìˆì„ ìˆ˜ ìˆìŒ)\n",
        "    if iptm is None and ptm is None:\n",
        "        for pat in [\n",
        "            os.path.join(PRED_ROOT, \"result_model_*_multimer*.json\"),\n",
        "            os.path.join(PRED_ROOT, \"result_model_*_multimer*.pkl\"),\n",
        "        ]:\n",
        "            for p in glob.glob(pat):\n",
        "                iptm, ptm, src = _load_metrics_from_any(p)\n",
        "                if iptm is not None or ptm is not None:\n",
        "                    break\n",
        "            if iptm is not None or ptm is not None:\n",
        "                break\n",
        "\n",
        "    # 4) ìµœì¢…ì ìœ¼ë¡œ í´ë”ë¥¼ ë§Œë“¤ê³  ranking_debug.json ë³´ì¥ ìƒì„±\n",
        "    rd_path = os.path.join(cdir, \"ranking_debug.json\")\n",
        "    need_create = (not os.path.isfile(rd_path)) or (iptm is None and ptm is None)\n",
        "    if need_create:\n",
        "        outp = _ensure_ranking_debug_json(cdir, iptm, ptm, source=src)\n",
        "        print(f\"ğŸ†• ranking_debug ìƒì„±: {outp} (from: {src or 'no source â†’ zeros'})\")\n",
        "        created += 1\n",
        "    else:\n",
        "        reused += 1\n",
        "\n",
        "print(f\"STEP 3.5 ì™„ë£Œ â†’ ìƒì„± {created}ê°œ, ì¬ì‚¬ìš© {reused}ê°œ (ê²€ìƒ‰ ë£¨íŠ¸: {PRED_ROOT})\")\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: pTM/ipTM ì ìˆ˜ ì¶”ì¶œ (ë””ë ‰í„°ë¦¬ ì§ì ‘ ìˆœíšŒ + ë£¨íŠ¸ ì ìˆ˜ JSON í´ë°±)\n",
        "# ==============================================================================\n",
        "\n",
        "import os, re, glob, json\n",
        "\n",
        "PRED_ROOT = os.path.join(JOB_NAME, \"pdb\")\n",
        "\n",
        "print(\"\\nSTEP 4: pTM/ipTM ì ìˆ˜ ì¶”ì¶œ\")\n",
        "print(\"=\"*80)\n",
        "print(f\"ê²€ìƒ‰ ë£¨íŠ¸: {PRED_ROOT}\")\n",
        "\n",
        "def _to_float(x):\n",
        "    try: return float(x)\n",
        "    except: return None\n",
        "\n",
        "def _read_json_scores(fp):\n",
        "    try:\n",
        "        with open(fp, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "    except Exception:\n",
        "        return None, None\n",
        "    rc   = data.get(\"ranking_confidences\", {}) if isinstance(data, dict) else {}\n",
        "    iptm = _to_float(data.get(\"iptm\") or rc.get(\"iptm\") or rc.get(\"iptm+ptm\") or data.get(\"iptm_score\"))\n",
        "    ptm  = _to_float(data.get(\"ptm\")  or rc.get(\"ptm\")  or data.get(\"ptm_score\"))\n",
        "    if iptm is None: iptm = _to_float(data.get(\"iptm\"))\n",
        "    if ptm  is None: ptm  = _to_float(data.get(\"ptm\"))\n",
        "    return iptm, ptm\n",
        "\n",
        "ptm_scores_map = {}\n",
        "found_files = 0\n",
        "\n",
        "# 1) complex_*** ë””ë ‰í„°ë¦¬ë¥¼ ì§ì ‘ ìˆœíšŒ (STEP 3.5ê°€ ìƒì„±í•´ë‘ )\n",
        "complex_dirs = sorted([d for d in glob.glob(os.path.join(PRED_ROOT, \"complex_*\")) if os.path.isdir(d)])\n",
        "for cdir in complex_dirs:\n",
        "    m = re.search(r\"complex_(\\d+)$\", os.path.basename(cdir))\n",
        "    if not m:\n",
        "        continue\n",
        "    idx = int(m.group(1))\n",
        "    rd = os.path.join(cdir, \"ranking_debug.json\")\n",
        "    if not os.path.isfile(rd):\n",
        "        continue\n",
        "    iptm, ptm = _read_json_scores(rd)\n",
        "    if iptm is None and ptm is None:\n",
        "        continue\n",
        "    val = iptm if iptm is not None else ptm\n",
        "    val = 0.0 if val is None else float(val)\n",
        "\n",
        "    key = peptides[idx] if 0 <= idx < len(peptides) else f\"complex_{idx:03d}\"\n",
        "    ptm_scores_map[key] = round(val, 3)\n",
        "    found_files += 1\n",
        "\n",
        "# 2) (í´ë”ê°€ ì—†ê±°ë‚˜ ëˆ„ë½ëœ ê²½ìš°) ë£¨íŠ¸ì˜ complex_*_scores_rank_*.jsonë„ ì½ì–´ ë§¤í•‘\n",
        "root_score_jsons = sorted(glob.glob(os.path.join(PRED_ROOT, \"complex_*_scores_rank_*.json\")))\n",
        "for fp in root_score_jsons:\n",
        "    m = re.search(r\"complex_(\\d+)_scores_rank_\", os.path.basename(fp))\n",
        "    if not m:\n",
        "        continue\n",
        "    idx = int(m.group(1))\n",
        "    iptm, ptm = _read_json_scores(fp)\n",
        "    if iptm is None and ptm is None:\n",
        "        continue\n",
        "    val = iptm if iptm is not None else ptm\n",
        "    val = 0.0 if val is None else float(val)\n",
        "\n",
        "    key = peptides[idx] if 0 <= idx < len(peptides) else f\"complex_{idx:03d}\"\n",
        "    # ë””ë ‰í„°ë¦¬ì˜ ranking_debug ê°’ì„ ìš°ì„ í•˜ê³ , ì—†ì„ ë•Œë§Œ ë³´ì¶©\n",
        "    if key not in ptm_scores_map:\n",
        "        ptm_scores_map[key] = round(val, 3)\n",
        "        found_files += 1\n",
        "\n",
        "print(f\"ğŸ” í™•ì¸: complex_* ë””ë ‰í„°ë¦¬ {len(complex_dirs)}ê°œ, ë£¨íŠ¸ ì ìˆ˜ JSON {len(root_score_jsons)}ê°œ\")\n",
        "print(f\"âœ… pTM/ipTM ì ìˆ˜ ì¶”ì¶œ ì™„ë£Œ: {len(ptm_scores_map)}ê°œ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 5: PRODIGY(ì›¹) ë° ìƒí˜¸ì‘ìš© ë¶„ì„ í•¨ìˆ˜ (PLIP ìš°ì„  â†’ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´)\n",
        "# ==============================================================================\n",
        "\n",
        "import re, requests, tempfile, xml.etree.ElementTree as ET\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "\n",
        "def _parse_prodigy_text(text: str):\n",
        "    \"\"\"PRODIGY HTML/í…ìŠ¤íŠ¸ì—ì„œ kcal/mol ê°’ì„ robustí•˜ê²Œ ì¶”ì¶œ\"\"\"\n",
        "    pats = [\n",
        "        r'Predicted\\s+binding\\s+affinity[^-+]*?([\\-+]?\\d+(?:\\.\\d+)?)\\s*kcal\\s*/\\s*mol',\n",
        "        r'(?:Î”G|DeltaG)\\s*[:=]\\s*([\\-+]?\\d+(?:\\.\\d+)?)\\s*kcal\\s*/\\s*mol',\n",
        "        r'([\\-+]?\\d+(?:\\.\\d+)?)\\s*kcal\\s*/\\s*mol'\n",
        "    ]\n",
        "    for p in pats:\n",
        "        m = re.search(p, text, flags=re.IGNORECASE)\n",
        "        if m:\n",
        "            try:\n",
        "                return float(m.group(1))\n",
        "            except:\n",
        "                pass\n",
        "    return None\n",
        "\n",
        "def _fallback_binding_energy_from_geometry(pdb_file_path: str) -> float:\n",
        "    \"\"\"\n",
        "    ëŒ€ì²´ ê²°í•© ì—ë„ˆì§€ ì¶”ì •(ê°„ì´): ìµœì†Œ ê±°ë¦¬ + ì ‘ì´‰ ìˆ˜ ê¸°ë°˜\n",
        "    ë” ê°€ê¹Œìš¸ìˆ˜ë¡/ì ‘ì´‰ ë§ì„ìˆ˜ë¡ ë” ìŒìˆ˜(ê°•í•œ ê²°í•©)ë¡œ ê°€ì¤‘\n",
        "    \"\"\"\n",
        "    try:\n",
        "        chain_a_coords, chain_b_coords = [], []\n",
        "        with open(pdb_file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.startswith('ATOM'):\n",
        "                    chain = line[21]\n",
        "                    x, y, z = float(line[30:38]), float(line[38:46]), float(line[46:54])\n",
        "                    if chain == 'A':\n",
        "                        chain_a_coords.append((x, y, z))\n",
        "                    elif chain == 'B':\n",
        "                        chain_b_coords.append((x, y, z))\n",
        "\n",
        "        if not chain_a_coords or not chain_b_coords:\n",
        "            return 0.0\n",
        "\n",
        "        min_distance = float('inf')\n",
        "        contact_count = 0\n",
        "\n",
        "        # ì—°ì‚°ëŸ‰ ê°ì†Œë¥¼ ìœ„í•´ Chain AëŠ” ìƒ˜í”Œë§\n",
        "        a_samp = chain_a_coords[::5] if len(chain_a_coords) > 5 else chain_a_coords\n",
        "        b_arr = np.array(chain_b_coords)\n",
        "        for (ax, ay, az) in a_samp:\n",
        "            diffs = b_arr - np.array([ax, ay, az])\n",
        "            dists = np.sqrt((diffs**2).sum(axis=1))\n",
        "            min_distance = min(min_distance, float(dists.min()))\n",
        "            contact_count += int((dists < 5.0).sum())\n",
        "\n",
        "        if min_distance < float('inf'):\n",
        "            score = -5.0 - (10.0 / max(min_distance, 1.0)) - (contact_count * 0.1)\n",
        "            return max(score, -20.0)  # í•˜í•œ ìº¡\n",
        "    except Exception as e:\n",
        "        print(f\"       ëŒ€ì²´ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}\")\n",
        "    return 0.0\n",
        "\n",
        "def predict_binding_affinity_with_prodigy(pdb_file_path: str, max_retries: int = 2) -> float:\n",
        "    \"\"\"\n",
        "    Colab ì „ìš©: PRODIGYëŠ” 'ì›¹ ëª¨ë“œ'ë§Œ ì‹œë„ â†’ ì‹¤íŒ¨ ì‹œ ì´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ 'ëŒ€ì²´ ì ìˆ˜' ë°˜í™˜\n",
        "    (ë¡œì»¬ CLIëŠ” Colabì—ì„œ ë¶ˆì•ˆì •í•˜ë¯€ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)\n",
        "    \"\"\"\n",
        "    endpoints = [\n",
        "        \"https://rascar.science.uu.nl/prodigy/prediction\",\n",
        "        \"https://bianca.science.uu.nl/prodigy/prediction\"\n",
        "    ]\n",
        "    # ì—”ë“œí¬ì¸íŠ¸ë§ˆë‹¤ í¼ ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ 2ì¢… ì‹œë„\n",
        "    form_variants = [\n",
        "        {\"file_field\": \"file\", \"data\": {\"temperature\": \"25\", \"chain1\": \"A\", \"chain2\": \"B\"}},\n",
        "        {\"file_field\": \"pdbfile\", \"data\": {\"temp\": \"25\", \"chain1\": \"A\", \"chain2\": \"B\"}},\n",
        "    ]\n",
        "\n",
        "    for ep in endpoints:\n",
        "        for fv in form_variants:\n",
        "            try:\n",
        "                with open(pdb_file_path, \"rb\") as f:\n",
        "                    files = {fv[\"file_field\"]: (os.path.basename(pdb_file_path), f, \"application/octet-stream\")}\n",
        "                    resp = requests.post(ep, files=files, data=fv[\"data\"], timeout=60)\n",
        "                if resp.status_code == 200 and resp.text:\n",
        "                    txt = resp.text\n",
        "                    try:\n",
        "                        soup = BeautifulSoup(txt, \"html.parser\")\n",
        "                        txt += \"\\n\" + (soup.get_text(\"\\n\") or \"\")\n",
        "                    except:\n",
        "                        pass\n",
        "                    val = _parse_prodigy_text(txt)\n",
        "                    if val is not None:\n",
        "                        return float(val)\n",
        "            except Exception as e:\n",
        "                print(f\"       PRODIGY(ì›¹:{ep}) ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "    # ì›¹ ì‹¤íŒ¨ ì‹œ: ì´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ 'ëŒ€ì²´ ì ìˆ˜' ì¦‰ì‹œ ë°˜í™˜\n",
        "    alt = _fallback_binding_energy_from_geometry(pdb_file_path)\n",
        "    if alt != 0.0:\n",
        "        print(f\"       â†’ PRODIGY ëŒ€ì²´ ì ìˆ˜ ì‚¬ìš©: {alt:.3f} kcal/mol\")\n",
        "    return alt\n",
        "\n",
        "def _calculate_interactions_with_plip(pdb_file: str):\n",
        "    \"\"\"\n",
        "    PLIPê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ PLIPë¡œ ìƒí˜¸ì‘ìš© ê³„ì‚°\n",
        "    ì‹¤íŒ¨/ë¯¸ì„¤ì¹˜ë©´ ìƒìœ„ì—ì„œ ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\n",
        "    \"\"\"\n",
        "    if not PLIP_AVAILABLE:\n",
        "        raise RuntimeError(\"PLIP not available\")\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as tmpd:\n",
        "        cmd = [\"plipcmd\", \"-f\", pdb_file, \"-o\", tmpd, \"-x\"]\n",
        "        # stderrë¥¼ ìˆ¨ê¸°ê³  timeout ì„¤ì •\n",
        "        import subprocess\n",
        "        subprocess.check_output(cmd, stderr=subprocess.STDOUT, universal_newlines=True, timeout=120)\n",
        "\n",
        "        report_xml = os.path.join(tmpd, \"report.xml\")\n",
        "        if not os.path.exists(report_xml):\n",
        "            raise RuntimeError(\"PLIP report.xml not found\")\n",
        "\n",
        "        tree = ET.parse(report_xml)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        def count_any(root, tag_substr):\n",
        "            return sum(1 for el in root.iter() if tag_substr in el.tag.lower())\n",
        "\n",
        "        h_bonds = count_any(root, \"hydrogen_bond\")\n",
        "        hydrophobic = count_any(root, \"hydrophobic_interaction\")\n",
        "        # salt_bridgeë¥¼ ì •ì „ê¸° ìƒí˜¸ì‘ìš©ìœ¼ë¡œ ì·¨ê¸‰\n",
        "        electrostatic = count_any(root, \"salt_bridge\")\n",
        "\n",
        "        return {\n",
        "            \"h_bonds\": h_bonds,\n",
        "            \"hydrophobic\": hydrophobic,\n",
        "            \"electrostatic\": electrostatic,\n",
        "            \"total\": h_bonds + hydrophobic + electrostatic\n",
        "        }\n",
        "\n",
        "def calculate_interactions_advanced(pdb_file):\n",
        "    \"\"\"ìƒí˜¸ì‘ìš© ê³„ì‚°: PLIP ìš°ì„  â†’ ì‹¤íŒ¨/ë¯¸ì„¤ì¹˜ ì‹œ ëŒ€ì²´(ê°„ì´)\"\"\"\n",
        "    # 1) PLIP ì‹œë„\n",
        "    try:\n",
        "        return _calculate_interactions_with_plip(pdb_file)\n",
        "    except Exception as e:\n",
        "        if PLIP_AVAILABLE:\n",
        "            print(f\"    -> PLIP ì‹¤íŒ¨, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©: {e}\")\n",
        "        else:\n",
        "            print(\"    -> PLIP ë¯¸ì„¤ì¹˜/ë¯¸ì‚¬ìš©, ëŒ€ì²´ ê³„ì‚° ì‚¬ìš©\")\n",
        "\n",
        "    # 2) ëŒ€ì²´(ê¸°ì¡´ ê°„ì´ ê³„ì‚°)\n",
        "    try:\n",
        "        chain_a_atoms, chain_b_atoms = [], []\n",
        "        with open(pdb_file, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.startswith(('ATOM', 'HETATM')):\n",
        "                    chain = line[21]\n",
        "                    atom_type = line[12:16].strip()\n",
        "                    element = (line[76:78].strip() or atom_type[0]).upper()\n",
        "                    coords = (float(line[30:38]), float(line[38:46]), float(line[46:54]), atom_type, element)\n",
        "                    if chain == 'A':\n",
        "                        chain_a_atoms.append(coords)\n",
        "                    elif chain == 'B':\n",
        "                        chain_b_atoms.append(coords)\n",
        "\n",
        "        if not chain_a_atoms or not chain_b_atoms:\n",
        "            return {'h_bonds': 0, 'hydrophobic': 0, 'electrostatic': 0, 'total': 0}\n",
        "\n",
        "        h_bonds = hydrophobic = electrostatic = 0\n",
        "        for bx, by, bz, b_atom, b_element in chain_b_atoms:\n",
        "            for ax, ay, az, a_atom, a_element in chain_a_atoms:\n",
        "                distance = np.sqrt((bx-ax)**2 + (by-ay)**2 + (bz-az)**2)\n",
        "                # ìˆ˜ì†Œê²°í•©\n",
        "                if distance <= 3.5 and ((a_element in ['N','O']) and (b_element in ['N','O'])):\n",
        "                    h_bonds += 1\n",
        "                # ì†Œìˆ˜ì„±\n",
        "                if distance <= 4.5 and a_element == 'C' and b_element == 'C':\n",
        "                    hydrophobic += 1\n",
        "                # ê°„ì´ ì •ì „ê¸°\n",
        "                if distance <= 5.0:\n",
        "                    charged_pos = ['LYS', 'ARG', 'HIS']\n",
        "                    charged_neg = ['ASP', 'GLU']\n",
        "                    a_res, b_res = a_atom[:3], b_atom[:3]\n",
        "                    if ((a_res in charged_pos and b_res in charged_neg) or\n",
        "                        (a_res in charged_neg and b_res in charged_pos)):\n",
        "                        electrostatic += 1\n",
        "\n",
        "        return {\n",
        "            'h_bonds': h_bonds,\n",
        "            'hydrophobic': hydrophobic,\n",
        "            'electrostatic': electrostatic,\n",
        "            'total': h_bonds + hydrophobic + electrostatic\n",
        "        }\n",
        "    except:\n",
        "        return {'h_bonds': 0, 'hydrophobic': 0, 'electrostatic': 0, 'total': 0}\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 6: ê²°í•©ë ¥ í‰ê°€ ë° ë­í‚¹ (ë””ë²„ê¹… ê°•í™” ë²„ì „)\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 6: ê²°í•©ë ¥ í‰ê°€ ë° ìµœì¢… ë­í‚¹\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results = []\n",
        "\n",
        "if predicted_pdb_files:\n",
        "    for idx, pred_pdb in enumerate(predicted_pdb_files):\n",
        "        print(f\"\\ní‰ê°€ ì¤‘ ({idx+1}/{len(predicted_pdb_files)}): {os.path.basename(pred_pdb)}\")\n",
        "\n",
        "        # PDB íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬\n",
        "        if not os.path.exists(pred_pdb):\n",
        "            print(\"    -> PDB íŒŒì¼ ì—†ìŒ\")\n",
        "            continue\n",
        "\n",
        "        file_size = os.path.getsize(pred_pdb)\n",
        "        if file_size == 0:\n",
        "            print(\"    -> ë¹ˆ PDB íŒŒì¼\")\n",
        "            continue\n",
        "\n",
        "        print(f\"    -> PDB íŒŒì¼ í¬ê¸°: {file_size} bytes\")\n",
        "\n",
        "        # í©íƒ€ì´ë“œ ì„œì—´ ë§¤í•‘\n",
        "        try:\n",
        "            peptide_index = int(re.search(r'complex_(\\d+)', os.path.basename(pred_pdb)).group(1))\n",
        "            peptide_seq = peptides[peptide_index]\n",
        "            print(f\"    -> í©íƒ€ì´ë“œ: {peptide_seq}\")\n",
        "        except:\n",
        "            print(\"    -> í©íƒ€ì´ë“œ ë§¤í•‘ ì‹¤íŒ¨\")\n",
        "            continue\n",
        "\n",
        "        # PDB íŒŒì¼ ë‚´ìš© ê°„ë‹¨ í™•ì¸\n",
        "        try:\n",
        "            with open(pred_pdb, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            atom_lines = [line for line in lines if line.startswith('ATOM')]\n",
        "            chain_a_atoms = [line for line in atom_lines if line[21] == 'A']\n",
        "            chain_b_atoms = [line for line in atom_lines if line[21] == 'B']\n",
        "\n",
        "            print(f\"    -> Chain A ì›ììˆ˜: {len(chain_a_atoms)}\")\n",
        "            print(f\"    -> Chain B ì›ììˆ˜: {len(chain_b_atoms)}\")\n",
        "\n",
        "            if len(chain_a_atoms) == 0 or len(chain_b_atoms) == 0:\n",
        "                print(\"    -> ê²½ê³ : Chain A ë˜ëŠ” Bê°€ ë¹„ì–´ìˆìŒ\")\n",
        "        except Exception as e:\n",
        "            print(f\"    -> PDB íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "        print(\"    -> PRODIGY ë¶„ì„ ì‹œì‘...\")\n",
        "        prodigy_score = predict_binding_affinity_with_prodigy(pred_pdb)\n",
        "\n",
        "        if prodigy_score != 0.0:\n",
        "            print(f\"    -> PRODIGY ê²°ê³¼: {prodigy_score:.3f} kcal/mol\")\n",
        "        else:\n",
        "            print(\"    -> PRODIGY ê²°ê³¼: 0.000 (ì›¹/ëŒ€ì²´ ëª¨ë‘ ì‹¤íŒ¨)\")\n",
        "\n",
        "            # ê°„ë‹¨í•œ ëŒ€ì²´ ì ìˆ˜ (ìƒí˜¸ì‘ìš© ê¸°ë°˜)\n",
        "            try:\n",
        "                with open(pred_pdb, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "\n",
        "                # ìµœì†Œ ê±°ë¦¬ ê¸°ë°˜ ê°„ë‹¨í•œ ê²°í•© ì—ë„ˆì§€ ì¶”ì •\n",
        "                chain_a_coords = []\n",
        "                chain_b_coords = []\n",
        "\n",
        "                for line in lines:\n",
        "                    if line.startswith('ATOM'):\n",
        "                        chain = line[21]\n",
        "                        x, y, z = float(line[30:38]), float(line[38:46]), float(line[46:54])\n",
        "                        if chain == 'A':\n",
        "                            chain_a_coords.append((x, y, z))\n",
        "                        elif chain == 'B':\n",
        "                            chain_b_coords.append((x, y, z))\n",
        "\n",
        "                if chain_a_coords and chain_b_coords:\n",
        "                    min_distance = float('inf')\n",
        "                    contact_count = 0\n",
        "\n",
        "                    # ìƒ˜í”Œë§ìœ¼ë¡œ ê³„ì‚°ëŸ‰ ê°ì†Œ\n",
        "                    for i, (ax, ay, az) in enumerate(chain_a_coords[::5]):  # 5ê°œë§ˆë‹¤ ìƒ˜í”Œë§\n",
        "                        for j, (bx, by, bz) in enumerate(chain_b_coords):\n",
        "                            dist = np.sqrt((ax-bx)**2 + (ay-by)**2 + (az-bz)**2)\n",
        "                            min_distance = min(min_distance, dist)\n",
        "                            if dist < 5.0:  # 5Ã… ì´ë‚´ ì ‘ì´‰\n",
        "                                contact_count += 1\n",
        "\n",
        "                    # ê±°ë¦¬ ê¸°ë°˜ ì—ë„ˆì§€ ì¶”ì •\n",
        "                    if min_distance < float('inf'):\n",
        "                        # ê°€ê¹Œìš¸ìˆ˜ë¡ ë” ìŒìˆ˜ (ì•ˆì •í•œ ê²°í•©)\n",
        "                        prodigy_score = -5.0 - (10.0 / max(min_distance, 1.0)) - (contact_count * 0.1)\n",
        "                        prodigy_score = max(prodigy_score, -20.0)  # ìµœëŒ€ -20 kcal/mol\n",
        "                        print(f\"    -> ëŒ€ì²´ ì ìˆ˜: {prodigy_score:.3f} kcal/mol (ìµœì†Œê±°ë¦¬: {min_distance:.2f}Ã…, ì ‘ì´‰: {contact_count})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    -> ëŒ€ì²´ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}\")\n",
        "                prodigy_score = -5.0  # ê¸°ë³¸ê°’\n",
        "\n",
        "        # ìƒí˜¸ì‘ìš© ë¶„ì„\n",
        "        print(\"    -> ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...\")\n",
        "        interactions = calculate_interactions_advanced(pred_pdb)\n",
        "        print(f\"    -> H-bonds: {interactions['h_bonds']}, Hydrophobic: {interactions['hydrophobic']}, Electrostatic: {interactions['electrostatic']}\")\n",
        "\n",
        "        # pTM ì ìˆ˜ í™•ì¸\n",
        "        ptm_score = ptm_scores_map.get(peptide_seq, 0.0)\n",
        "        print(f\"    -> pTM ì ìˆ˜: {ptm_score}\")\n",
        "\n",
        "        # ìµœì¢… ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ê°€ì¤‘ì¹˜)\n",
        "        final_score = (\n",
        "            abs(prodigy_score) * 0.5 +           # PRODIGY ì ìˆ˜ (ì ˆëŒ€ê°’)\n",
        "            interactions['total'] * 0.3 +        # ìƒí˜¸ì‘ìš© ìˆ˜\n",
        "            ptm_score * 15 * 0.2                 # pTM ì ìˆ˜ ê°•í™”\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            \"Peptide_Sequence\": peptide_seq,\n",
        "            \"Final_Score\": round(final_score, 3),\n",
        "            \"pTM_Score\": ptm_score,\n",
        "            \"PRODIGY_Score\": round(prodigy_score, 3),\n",
        "            \"H_bonds\": interactions['h_bonds'],\n",
        "            \"Hydrophobic\": interactions['hydrophobic'],\n",
        "            \"Electrostatic\": interactions['electrostatic'],\n",
        "            \"Total_Interactions\": interactions['total'],\n",
        "            \"Source_PDB\": os.path.basename(pred_pdb)\n",
        "        })\n",
        "\n",
        "        print(f\"    -> ìµœì¢… ì ìˆ˜: {final_score:.3f}\")\n",
        "\n",
        "else:\n",
        "    print(\"âŒ í‰ê°€í•  PDB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(f\"\\nâœ… {len(results)}ê°œ êµ¬ì¡° í‰ê°€ ì™„ë£Œ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 7: ìµœì¢… ê²°ê³¼ ì €ì¥\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nSTEP 7: ìµœì¢… ê²°ê³¼ ì •ë¦¬ ë° ì €ì¥\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if results:\n",
        "    import pandas as pd\n",
        "\n",
        "    # DataFrame ìƒì„± ë° ì •ë ¬\n",
        "    df = pd.DataFrame(results)\n",
        "    df_sorted = df.sort_values(\"Final_Score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # ì—‘ì…€ ì €ì¥\n",
        "    df_sorted.to_excel(OUTPUT_FINAL_XLSX_PATH, index=False)\n",
        "\n",
        "    print(\"ğŸ† ìµœì¢… í©íƒ€ì´ë“œ ë­í‚¹:\")\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"{'ìˆœìœ„':<4} {'í©íƒ€ì´ë“œ':<12} {'ì¢…í•©ì ìˆ˜':<8} {'pTM':<6} {'PRODIGY':<8} {'ìƒí˜¸ì‘ìš©':<8}\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    for i, row in df_sorted.head(10).iterrows():\n",
        "        print(f\"{i+1:<4} {row['Peptide_Sequence']:<12} {row['Final_Score']:<8.3f} \"\n",
        "              f\"{row['pTM_Score']:<6.3f} {row['PRODIGY_Score']:<8.3f} {row['Total_Interactions']:<8}\")\n",
        "\n",
        "    print(f\"\\nğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥: {OUTPUT_FINAL_XLSX_PATH}\")\n",
        "else:\n",
        "    print(\"âŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ì‹¤í–‰ ì‹œê°„ ìš”ì•½\n",
        "pipeline_end_time = time.time()\n",
        "total_duration = pipeline_end_time - pipeline_start_time\n",
        "\n",
        "hours = int(total_duration // 3600)\n",
        "minutes = int((total_duration % 3600) // 60)\n",
        "seconds = int(total_duration % 60)\n",
        "\n",
        "# ğŸ‘‰ ì¡°ê±´ì— ë”°ë¼ ì¶œë ¥ í˜•ì‹ ë‹¬ë¦¬í•˜ê¸°\n",
        "if hours > 0:\n",
        "    print(f\"\\nâ±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„ {seconds}ì´ˆ\")\n",
        "else:\n",
        "    print(f\"\\nâ±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {minutes}ë¶„ {seconds}ì´ˆ\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ğŸ‰ í©íƒ€ì´ë“œ ë°œêµ´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
        "print(\"=\"*80)"
      ]
    }
  ]
}