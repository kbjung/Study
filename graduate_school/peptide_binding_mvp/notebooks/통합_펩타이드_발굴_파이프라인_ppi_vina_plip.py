# %%
# ##############################################################################
#
# í†µí•© í©íƒ€ì´ë“œ ë°œêµ´ íŒŒì´í”„ë¼ì¸ (Single-Notebook Peptide Discovery Pipeline)
#
# Google Colab Pro/Pro+ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê¶Œì¥
# ëŸ°íƒ€ì„ ìœ í˜•: GPU, ë†’ì€ RAM ì„¤ì •
#
# ##############################################################################

import time
# íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹œê°„ ê¸°ë¡
pipeline_start_time = time.time()

# ==============================================================================
# STEP 0: í™˜ê²½ ì„¤ì • ë° í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# ==============================================================================

print("="*80)
print("STEP 0: í™˜ê²½ ì„¤ì • ë° í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜")
print("="*80)

import os
import sys
import site
import subprocess
import shutil

# ì‹œê°„ëŒ€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
print("\n   > ì‹œê°„ëŒ€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ (pytz) ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q pytz")
print("   > pytz ì„¤ì¹˜ ì™„ë£Œ")

# ColabFold (AlphaFold2) ì„¤ì¹˜
print("\n[1/5] ColabFold (AlphaFold2) ì„¤ì¹˜ ì¤‘...")
print("   > ê¸°ì¡´ TensorFlow íŒ¨í‚¤ì§€ë¥¼ ì œê±°í•˜ì—¬ ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤...")
os.system("pip uninstall -y tensorflow tensorboard tb-nightly tensorflow-estimator tensorflow-hub tensorflow-io > /dev/null 2>&1")
os.system("pip install -q --no-warn-conflicts 'colabfold[alphafold] @ git+https://github.com/sokrypton/ColabFold'")
os.system("pip install -q --no-warn-conflicts 'jax[cuda11_pip]' -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html")

# ColabFold ìŠ¤í¬ë¦½íŠ¸ íŒ¨ì¹˜
print("   > ColabFold ìŠ¤í¬ë¦½íŠ¸ íŒ¨ì¹˜ ì ìš© ì¤‘...")
try:
    dist_packages_path = site.getsitepackages()[0]
    batch_py_path = os.path.join(dist_packages_path, 'colabfold', 'batch.py')
    if os.path.exists(batch_py_path):
        os.system(f"sed -i 's/tf.get_logger().setLevel(logging.ERROR)/#tf.get_logger().setLevel(logging.ERROR)/g' {batch_py_path}")
        os.system(f"sed -i \\\"s/tf.config.set_visible_devices(\\\\\\\\[\\\\\\\\], 'GPU')/#tf.config.set_visible_devices(\\\\\\\\[\\\\\\\\], 'GPU')/g\\\" {batch_py_path}")
        print("   > íŒ¨ì¹˜ ì ìš© ì™„ë£Œ.")
    else:
        print(f"   > ê²½ê³ : {batch_py_path}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ íŒ¨ì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
except Exception as e:
    print(f"   > ê²½ê³ : ColabFold íŒ¨ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")

# í©íƒ€ì´ë“œ ìƒì„± ëª¨ë¸ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
print("\n[2/5] í©íƒ€ì´ë“œ ìƒì„± ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Transformers) ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q --upgrade transformers sentencepiece")

# ê²°í•©ë ¥ í‰ê°€ ë„êµ¬ ì„¤ì¹˜
print("\n[3/5] ê²°í•©ë ¥ í‰ê°€ ë„êµ¬ ì„¤ì¹˜ ì¤‘...")

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ë° ì„¤ì¹˜
print("   > ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ì¤‘...")
os.system("apt-get update -qq > /dev/null 2>&1")

# OpenBabel ì„¤ì¹˜
print("   > OpenBabel ì„¤ì¹˜ ì¤‘...")
os.system("apt-get install -y --quiet openbabel python3-openbabel libopenbabel-dev")
os.system("pip install -q openbabel-wheel")
print("   > OpenBabel ì„¤ì¹˜ ì™„ë£Œ")

# RDKit ì„¤ì¹˜ (í™”í•™ êµ¬ì¡° ì²˜ë¦¬ìš©)
print("   > RDKit ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q rdkit-pypi")
print("   > RDKit ì„¤ì¹˜ ì™„ë£Œ")

# PLIP ì„¤ì¹˜
print("   > PLIP ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q plip")
os.system("pip install -q biopython ProLIF MDAnalysis")
print("   > PLIP ë° ëŒ€ì²´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ")

# ODDT ë° ê¸°íƒ€ í™”í•™ ì •ë³´í•™ ë„êµ¬ ì„¤ì¹˜
print("   > í™”í•™ ì •ë³´í•™ ë„êµ¬ (ODDT, scikit-learn) ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q oddt scikit-learn")
print("   > ODDT ì„¤ì¹˜ ì™„ë£Œ")

# Excel íŒŒì¼ ì¶œë ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
print("   > Excel íŒŒì¼ ì§€ì› ë¼ì´ë¸ŒëŸ¬ë¦¬ (openpyxl) ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q openpyxl")
print("   > openpyxl ì„¤ì¹˜ ì™„ë£Œ")

# AutoDock Vina ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜
print("\n[4/5] AutoDock Vina ì„¤ì¹˜ ì¤‘...")

def setup_vina_robust():
    """Vina ì„¤ì¹˜ í•¨ìˆ˜"""
    vina_dir = "vina_1.2.3_linux_x86_64"

    if not os.path.exists(vina_dir):
        print("   > Vina ë‹¤ìš´ë¡œë“œ ì¤‘...")
        download_commands = [
            "wget -q https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip",
            "curl -L -o vina_1.2.3_linux_x86_64.zip https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip"
        ]

        for cmd in download_commands:
            if os.system(cmd) == 0:
                break
        else:
            print("   > Vina ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            return False

        # ì••ì¶• í•´ì œ
        os.system("unzip -q -o vina_1.2.3_linux_x86_64.zip")

        # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
        vina_executables = [
            f"{vina_dir}/vina",
            f"{vina_dir}/bin/vina",
        ]

        for executable in vina_executables:
            if os.path.exists(executable):
                os.chmod(executable, 0o755)
                print(f"   > ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬: {executable}")

    # Vina ì‹¤í–‰íŒŒì¼ ì°¾ê¸°
    possible_paths = [
        f"./{vina_dir}/vina",
        f"./{vina_dir}/bin/vina",
        "vina",
        "/usr/local/bin/vina"
    ]

    for path in possible_paths:
        if os.path.exists(path) and os.access(path, os.X_OK):
            print(f"   > Vina ì‹¤í–‰íŒŒì¼ ë°œê²¬: {path}")
            return os.path.abspath(path)

    print("   > Vina ì‹¤í–‰íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    return None

VINA_EXECUTABLE = setup_vina_robust()

# ì¶”ê°€ ë„êµ¬ ì„¤ì¹˜
print("\n[5/5] ì¶”ê°€ ë¶„ì ë„í‚¹ ë„êµ¬ ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q pymol-open-source > /dev/null 2>&1")
os.system("pip install -q meeko > /dev/null 2>&1")
print("   > ì¶”ê°€ ë„êµ¬ ì„¤ì¹˜ ì™„ë£Œ")

print("   > ì›¹ API í˜¸ì¶œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...")
os.system("pip install -q requests")
print("   > requests ì„¤ì¹˜ ì™„ë£Œ")

print("\nëª¨ë“  ì„¤ì¹˜ ì™„ë£Œ!")
print("="*80)
print("âœ… STEP 0: í™˜ê²½ ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
print("="*80)

# ==============================================================================
# STEP 1: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ìœ„í•œ ë³€ìˆ˜ ì„¤ì •
# ==============================================================================

print("\n" + "="*80)
print("STEP 1: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ìœ„í•œ ë³€ìˆ˜ ì„¤ì •")
print("="*80)

import torch
from datetime import datetime
import pytz

# --- ì‚¬ìš©ì ì„¤ì • ì˜ì—­ ---

# 1. ìƒì„±í•  í©íƒ€ì´ë“œ í›„ë³´ì˜ ê°œìˆ˜
N_PEPTIDES = 5

# 2. íƒ€ê²Ÿ ë‹¨ë°±ì§ˆì˜ ì•„ë¯¸ë…¸ì‚° ì„œì—´ (FASTA í˜•ì‹, í•œ ì¤„ë¡œ ì…ë ¥)
TARGET_PROTEIN_SEQUENCE = "PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK"

# 3. ìƒì„±í•  í©íƒ€ì´ë“œì˜ ê¸¸ì´
PEPTIDE_LENGTH = 10

# 4. ê²°ê³¼ í´ë”ì˜ ê¸°ë³¸ ì´ë¦„ ì ‘ë‘ì‚¬
BASE_FOLDER_PREFIX = "PDP"

# í•œêµ­ ì‹œê°„(KST)ì„ ê¸°ì¤€ìœ¼ë¡œ ë™ì  í´ë” ë° íŒŒì¼ ì´ë¦„ ìƒì„±
kst = pytz.timezone('Asia/Seoul')
now_kst = datetime.now(kst)
timestamp = now_kst.strftime("%Y%m%d_%H%M%S")

# ìµœì¢… ê²°ê³¼ í´ë”ëª…
JOB_NAME = f"{BASE_FOLDER_PREFIX}_{timestamp}"

# ì„¤ì •ê°’ í™•ì¸ ë° ë””ë ‰í† ë¦¬/íŒŒì¼ ê²½ë¡œ ìƒì„±
os.makedirs(JOB_NAME, exist_ok=True)
PROTEIN_FASTA_PATH = os.path.join(JOB_NAME, "target_protein.fasta")
OUTPUT_FINAL_XLSX_PATH = os.path.join(JOB_NAME, f"final_peptide_ranking_{timestamp}.xlsx")

with open(PROTEIN_FASTA_PATH, "w") as f:
    f.write(f">target_protein\n{TARGET_PROTEIN_SEQUENCE}\n")

print(f"âœ”ï¸ ì‘ì—… í´ë”: {JOB_NAME}")
print(f"âœ”ï¸ ìƒì„±í•  í©íƒ€ì´ë“œ ê°œìˆ˜: {N_PEPTIDES}")
print(f"âœ”ï¸ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ ì„œì—´ ê¸¸ì´: {len(TARGET_PROTEIN_SEQUENCE)}")
print(f"âœ”ï¸ ìƒì„±í•  í©íƒ€ì´ë“œ ê¸¸ì´: {PEPTIDE_LENGTH}")
print(f"âœ”ï¸ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ FASTA íŒŒì¼ ì €ì¥: {PROTEIN_FASTA_PATH}")
print(f"âœ”ï¸ ìµœì¢… ê²°ê³¼ íŒŒì¼ ì €ì¥ ê²½ë¡œ: {OUTPUT_FINAL_XLSX_PATH}")
print("="*80)
print("âœ… STEP 1: ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
print("="*80)

# ==============================================================================
# STEP 2: PepMLM (ESM-2)ì„ ì´ìš©í•œ íƒ€ê²Ÿ íŠ¹ì´ì  í©íƒ€ì´ë“œ í›„ë³´ ìƒì„±
# ==============================================================================

print("\n" + "="*80)
print("STEP 2: PepMLM (ESM-2)ì„ ì´ìš©í•œ íƒ€ê²Ÿ íŠ¹ì´ì  í©íƒ€ì´ë“œ í›„ë³´ ìƒì„±")
print("="*80)

import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForMaskedLM

# ESM-2 ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model_name = "facebook/esm2_t12_35M_UR50D"
print(f"'{model_name}' ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤...")
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForMaskedLM.from_pretrained(model_name).to("cuda" if torch.cuda.is_available() else "cpu")
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# ìƒì„± íŒŒë¼ë¯¸í„°
temperature = 1.0
top_k = 50

# ëª¨ë¸ ì…ë ¥ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
formatted_target = " ".join(list(TARGET_PROTEIN_SEQUENCE))
mask_tokens = " ".join([tokenizer.mask_token] * PEPTIDE_LENGTH)
prompt = f"{tokenizer.cls_token} {formatted_target} {tokenizer.eos_token} {mask_tokens}"
input_ids = tokenizer(prompt, return_tensors="pt").input_ids

mask_token_indices = (input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]

peptides = []
peptide_fasta_paths = []

print("\ní©íƒ€ì´ë“œ ì„œì—´ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
with torch.no_grad():
    for i in range(N_PEPTIDES):
        current_ids = input_ids.clone().to(model.device)
        shuffled_mask_indices = mask_token_indices[torch.randperm(len(mask_token_indices))]

        for mask_idx in shuffled_mask_indices:
            outputs = model(input_ids=current_ids)
            logits = outputs.logits
            mask_logits = logits[0, mask_idx, :]
            filtered_logits = mask_logits / temperature
            effective_top_k = min(top_k, tokenizer.vocab_size)
            top_k_values, top_k_indices = torch.topk(filtered_logits, effective_top_k)
            filter_tensor = torch.full_like(filtered_logits, -float('Inf'))
            filter_tensor.scatter_(0, top_k_indices, top_k_values)
            probs = F.softmax(filter_tensor, dim=-1)
            predicted_token_id = torch.multinomial(probs, num_samples=1)
            current_ids[0, mask_idx] = predicted_token_id.item()

        generated_token_ids = current_ids[0, mask_token_indices]
        sequence_part = tokenizer.decode(generated_token_ids, skip_special_tokens=True)
        sequence = "".join(sequence_part.split())
        peptides.append(sequence)

        fasta_path = os.path.join(JOB_NAME, f"peptide_{i}.fasta")
        with open(fasta_path, "w") as f:
            f.write(f">peptide_{i}\n{sequence}\n")
        peptide_fasta_paths.append(fasta_path)
        print(f"  [{i+1}/{N_PEPTIDES}] ìƒì„± ì™„ë£Œ: {sequence} (ê¸¸ì´: {len(sequence)})")

print("\n--- ìƒì„±ëœ í©íƒ€ì´ë“œ í›„ë³´ ëª©ë¡ ---")
for i, seq in enumerate(peptides):
    print(f"  - í›„ë³´ {i+1}: {seq}")
print("="*80)
print(f"âœ… STEP 2: ì´ {N_PEPTIDES}ê°œì˜ í©íƒ€ì´ë“œ í›„ë³´ ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
print("="*80)

# ==============================================================================
# STEP 3: ë‹¨ë°±ì§ˆ-í©íƒ€ì´ë“œ ë³µí•©ì²´ 3D êµ¬ì¡° ì˜ˆì¸¡ (ColabFold) ë° ì‹ ë¢°ë„ í™•ì¸
# ==============================================================================

import glob
import json
import pandas as pd
from IPython.display import display
import re

print("\n" + "="*80)
print("STEP 3: ë‹¨ë°±ì§ˆ-í©íƒ€ì´ë“œ ë³µí•©ì²´ 3D êµ¬ì¡° ì˜ˆì¸¡ (ColabFold) ë° ì‹ ë¢°ë„ í™•ì¸")
print("="*80)

predicted_pdb_files = []

# ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³µí•©ì²´ CSV íŒŒì¼ ìƒì„±
print("\në°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³µí•©ì²´ CSV íŒŒì¼ ìƒì„± ì¤‘...")
batch_csv_path = os.path.join(JOB_NAME, "batch_complexes.csv")
with open(batch_csv_path, "w") as f:
    f.write("id,sequence\n")
    for i in range(N_PEPTIDES):
        peptide_seq = peptides[i]
        complex_sequence = f"{TARGET_PROTEIN_SEQUENCE}:{peptide_seq}"
        f.write(f"complex_{i},{complex_sequence}\n")

print(f"âœ… ë°°ì¹˜ íŒŒì¼ ìƒì„± ì™„ë£Œ: {batch_csv_path}")

# ColabFold ë°°ì¹˜ ì‹¤í–‰
output_dir = os.path.join(JOB_NAME, "colabfold_batch_output")
os.makedirs(output_dir, exist_ok=True)
log_file = os.path.join(output_dir, "colabfold_batch.log")

print(f"\nColabFold ë°°ì¹˜ ì‹¤í–‰ ì‹œì‘... (ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir})")
print("â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 10-30ë¶„ (ë³µí•©ì²´ ê°œìˆ˜ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤)")

# Colab í™˜ê²½ì— ìµœì í™”ëœ ì˜µì…˜ ì‚¬ìš©
colabfold_cmd = (f"colabfold_batch "
                f"--num-recycle 1 "
                f"--model-type alphafold2_multimer_v3 "
                f"--rank ptm "
                f"--max-msa 32:128 "
                f"--num-models 1 "
                f"--stop-at-score 0.5 "
                f"{batch_csv_path} {output_dir} > {log_file} 2>&1")

print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {colabfold_cmd}")
result = os.system(colabfold_cmd)

# ê²°ê³¼ í™•ì¸
print(f"\nColabFold ì‹¤í–‰ ì™„ë£Œ (ì¢…ë£Œ ì½”ë“œ: {result})")

# ìƒì„±ëœ PDB íŒŒì¼ ì°¾ê¸°
for i in range(N_PEPTIDES):
    pdb_pattern = os.path.join(output_dir, f"complex_{i}_unrelaxed_rank_001*.pdb")
    pdb_files = sorted(glob.glob(pdb_pattern))

    if pdb_files:
        predicted_pdb_files.append(pdb_files[0])
        print(f"  âœ… ë³µí•©ì²´ {i}: {os.path.basename(pdb_files[0])}")
    else:
        print(f"  âŒ ë³µí•©ì²´ {i}: PDB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

# ì‹¤íŒ¨ ì‹œ ë¡œê·¸ íŒŒì¼ ë‚´ìš© ì¶œë ¥
if len(predicted_pdb_files) < N_PEPTIDES and os.path.exists(log_file):
    print("\n" + "="*50)
    print("âš ï¸ ì¼ë¶€ ì˜ˆì¸¡ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. COLABFOLD ì‹¤í–‰ ë¡œê·¸:")
    print("="*50)
    with open(log_file, 'r') as f:
        print(f.read()[-2000:])
    print("="*50)

# êµ¬ì¡° ì˜ˆì¸¡ ì‹ ë¢°ë„ ì ìˆ˜(pTM) í™•ì¸
print("\nêµ¬ì¡° ì˜ˆì¸¡ ì‹ ë¢°ë„ ì ìˆ˜(pTM) í™•ì¸ ì¤‘...")

scores_info = []
ptm_scores_map = {}

# ë‹¤ì–‘í•œ ì ìˆ˜ íŒŒì¼ íŒ¨í„´ ì‹œë„
score_file_patterns = [
    os.path.join(output_dir, "*_scores.json"),
    os.path.join(output_dir, "complex_*_scores.json"),
    os.path.join(output_dir, "*_rank_001_*.json"),
    os.path.join(output_dir, "*_score*.json")
]

all_score_files = []
for pattern in score_file_patterns:
    files = sorted(glob.glob(pattern))
    all_score_files.extend(files)

# ì¤‘ë³µ ì œê±°
all_score_files = list(set(all_score_files))

print(f"ì°¾ì€ ì ìˆ˜ íŒŒì¼ë“¤: {len(all_score_files)}ê°œ")

if not all_score_files:
    print("âš ï¸ ColabFold ì ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pTM ì ìˆ˜ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
else:
    print(f"ì´ {len(all_score_files)}ê°œì˜ ì ìˆ˜ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤...")

    for score_file in all_score_files:
        try:
            basename = os.path.basename(score_file)
            match = re.search(r'complex_(\d+)', basename)
            if not match:
                continue

            peptide_index = int(match.group(1))
            with open(score_file, 'r') as f:
                data = json.load(f)

            ptm_score = data.get('ptm', data.get('iptm', 0.0))
            if isinstance(ptm_score, list):
                ptm_score = ptm_score[0] if ptm_score else 0.0

            if peptide_index < len(peptides):
                peptide_seq = peptides[peptide_index]
                ptm_scores_map[peptide_seq] = round(float(ptm_score), 3)
                print(f"  ë³µí•©ì²´ {peptide_index} ({peptide_seq}): pTM = {ptm_scores_map[peptide_seq]}")

        except Exception as e:
            print(f"ì˜¤ë¥˜: {score_file} ì²˜ë¦¬ ì¤‘ ë¬¸ì œ ë°œìƒ - {e}")
            continue

print("="*80)
print(f"âœ… STEP 3: ì´ {len(predicted_pdb_files)}ê°œì˜ 3D êµ¬ì¡° ì˜ˆì¸¡ ë° pTM ì ìˆ˜ í™•ì¸ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
print("="*80)

# ==============================================================================
# STEP 4: ê²°í•©ë ¥ í‰ê°€ ë° ìµœì¢… ë­í‚¹ ê³„ì‚°
# ==============================================================================

print("\n" + "="*80)
print("STEP 4: ê²°í•©ë ¥ í‰ê°€ ë° ìµœì¢… ë­í‚¹ ê³„ì‚°")
print("="*80)

import re
import subprocess
import glob
import numpy as np
import requests
import json
import time

# ============= PPI-Affinity í•¨ìˆ˜ë“¤ =============

def predict_ppi_affinity_web(protein_seq, peptide_seq, max_retries=3):
    """PPI-Affinity ì›¹ ì„œë¹„ìŠ¤ë¥¼ í†µí•œ ê²°í•© ì¹œí™”ë„ ì˜ˆì¸¡"""

    services = [
        {
            "name": "PPI-Affinity HKU",
            "url": "https://ppi-affinity.hkucc.hku.hk/api/predict",
            "method": "hku"
        },
        {
            "name": "ProtParam Alternative",
            "url": "https://web.expasy.org/cgi-bin/protparam/protparam1",
            "method": "expasy"
        }
    ]

    for service in services:
        try:
            print(f"    -> {service['name']} ì„œë¹„ìŠ¤ ì‹œë„ ì¤‘...")

            if service['method'] == 'hku':
                score = call_hku_ppi_service(protein_seq, peptide_seq)
            elif service['method'] == 'expasy':
                score = call_expasy_service(protein_seq, peptide_seq)
            else:
                continue

            if score is not None and score > 0:
                print(f"       ì„±ê³µ! ì˜ˆì¸¡ ì ìˆ˜: {score:.3f}")
                return score

        except Exception as e:
            print(f"       {service['name']} ì‹¤íŒ¨: {e}")
            continue

    # ëª¨ë“  ì›¹ì„œë¹„ìŠ¤ ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ì¶”ì • í•¨ìˆ˜ ì‚¬ìš©
    print("    -> ì›¹ì„œë¹„ìŠ¤ ì‹¤íŒ¨, ë¡œì»¬ ì¶”ì • í•¨ìˆ˜ ì‚¬ìš©")
    return predict_ppi_affinity_local(protein_seq, peptide_seq)

def call_hku_ppi_service(protein_seq, peptide_seq):
    """HKU PPI-Affinity ì„œë¹„ìŠ¤ í˜¸ì¶œ"""
    try:
        data = {
            "sequence1": protein_seq,
            "sequence2": peptide_seq,
            "format": "json"
        }

        headers = {
            "Content-Type": "application/json",
            "User-Agent": "PeptidePipeline/1.0"
        }

        response = requests.post(
            "https://ppi-affinity.hkucc.hku.hk/api/predict",
            json=data,
            headers=headers,
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            return float(result.get('binding_affinity', 0))
        else:
            return None

    except Exception as e:
        print(f"       HKU API ì˜¤ë¥˜: {e}")
        return None

def call_expasy_service(protein_seq, peptide_seq):
    """ExPASy ê¸°ë°˜ ë‹¨ë°±ì§ˆ íŠ¹ì„± ë¶„ì„ í›„ ì¹œí™”ë„ ì¶”ì •"""
    try:
        protein_features = analyze_sequence_properties(protein_seq)
        peptide_features = analyze_sequence_properties(peptide_seq)

        hydrophobic_match = abs(protein_features['hydrophobicity'] - peptide_features['hydrophobicity'])
        charge_interaction = protein_features['charge'] * peptide_features['charge']
        size_factor = min(len(protein_seq), len(peptide_seq)) / max(len(protein_seq), len(peptide_seq))

        affinity_score = (
            (1.0 - hydrophobic_match / 10.0) * 4.0 +
            abs(charge_interaction) * 2.0 +
            size_factor * 2.0 +
            (peptide_features['flexibility'] * 2.0)
        )

        return min(max(affinity_score, 0.0), 10.0)

    except Exception as e:
        print(f"       ExPASy ê¸°ë°˜ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

def analyze_sequence_properties(sequence):
    """ì•„ë¯¸ë…¸ì‚° ì„œì—´ì˜ ë¬¼ë¦¬í™”í•™ì  íŠ¹ì„± ë¶„ì„"""

    aa_properties = {
        'A': {'hydro': 1.8, 'charge': 0, 'flex': 0.3},   'R': {'hydro': -4.5, 'charge': 1, 'flex': 0.9},
        'N': {'hydro': -3.5, 'charge': 0, 'flex': 0.6},  'D': {'hydro': -3.5, 'charge': -1, 'flex': 0.6},
        'C': {'hydro': 2.5, 'charge': 0, 'flex': 0.3},   'Q': {'hydro': -3.5, 'charge': 0, 'flex': 0.7},
        'E': {'hydro': -3.5, 'charge': -1, 'flex': 0.7}, 'G': {'hydro': -0.4, 'charge': 0, 'flex': 0.9},
        'H': {'hydro': -3.2, 'charge': 0.5, 'flex': 0.7},'I': {'hydro': 4.5, 'charge': 0, 'flex': 0.3},
        'L': {'hydro': 3.8, 'charge': 0, 'flex': 0.3},   'K': {'hydro': -3.9, 'charge': 1, 'flex': 0.8},
        'M': {'hydro': 1.9, 'charge': 0, 'flex': 0.5},   'F': {'hydro': 2.8, 'charge': 0, 'flex': 0.3},
        'P': {'hydro': -1.6, 'charge': 0, 'flex': 0.1},  'S': {'hydro': -0.8, 'charge': 0, 'flex': 0.5},
        'T': {'hydro': -0.7, 'charge': 0, 'flex': 0.4},  'W': {'hydro': -0.9, 'charge': 0, 'flex': 0.3},
        'Y': {'hydro': -1.3, 'charge': 0, 'flex': 0.4},  'V': {'hydro': 4.2, 'charge': 0, 'flex': 0.2}
    }

    if not sequence:
        return {'hydrophobicity': 0, 'charge': 0, 'flexibility': 0}

    total_hydro = sum(aa_properties.get(aa, {'hydro': 0})['hydro'] for aa in sequence)
    total_charge = sum(aa_properties.get(aa, {'charge': 0})['charge'] for aa in sequence)
    total_flex = sum(aa_properties.get(aa, {'flex': 0.5})['flex'] for aa in sequence)

    return {
        'hydrophobicity': total_hydro / len(sequence),
        'charge': total_charge,
        'flexibility': total_flex / len(sequence)
    }

def predict_ppi_affinity_local(protein_seq, peptide_seq):
    """ë¡œì»¬ PPI ì¹œí™”ë„ ì¶”ì • í•¨ìˆ˜"""
    try:
        protein_props = analyze_sequence_properties(protein_seq)
        peptide_props = analyze_sequence_properties(peptide_seq)

        charge_score = 0
        if protein_props['charge'] * peptide_props['charge'] < 0:
            charge_score = min(abs(protein_props['charge'] * peptide_props['charge']), 5.0)

        hydro_diff = abs(protein_props['hydrophobicity'] - peptide_props['hydrophobicity'])
        hydro_score = max(3.0 - hydro_diff * 0.5, 0)

        length_ratio = len(peptide_seq) / len(protein_seq)
        size_score = 2.0 * (1.0 - abs(length_ratio - 0.1))

        flex_score = peptide_props['flexibility'] * 2.0

        complexity_score = len(set(peptide_seq)) / 20.0 * 1.5

        final_score = charge_score + hydro_score + size_score + flex_score + complexity_score
        return min(max(final_score, 0.0), 10.0)

    except Exception as e:
        print(f"       ë¡œì»¬ PPI ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return 5.0

# ============= ë¶„ìê°„ ìƒí˜¸ì‘ìš© ê³„ì‚° í•¨ìˆ˜ =============

def calculate_interactions_advanced(pdb_file):
    """ë¶„ìê°„ ìƒí˜¸ì‘ìš© ê³„ì‚°"""
    try:
        chain_a_atoms, chain_b_atoms = [], []

        with open(pdb_file, 'r') as f:
            for line in f:
                if line.startswith(('ATOM', 'HETATM')):
                    chain = line[21]
                    atom_type = line[12:16].strip()
                    element = line[76:78].strip() or atom_type[0]
                    coords = (
                        float(line[30:38]),
                        float(line[38:46]),
                        float(line[46:54]),
                        atom_type,
                        element
                    )

                    if chain == 'A':
                        chain_a_atoms.append(coords)
                    elif chain == 'B':
                        chain_b_atoms.append(coords)

        if not chain_a_atoms or not chain_b_atoms:
            return {'h_bonds': 0, 'hydrophobic': 0, 'electrostatic': 0, 'total': 0}

        h_bonds = 0
        hydrophobic = 0
        electrostatic = 0

        for bx, by, bz, b_atom, b_element in chain_b_atoms:
            for ax, ay, az, a_atom, a_element in chain_a_atoms:
                distance = np.sqrt((bx-ax)**2 + (by-ay)**2 + (bz-az)**2)

                # ìˆ˜ì†Œê²°í•© (N, O ì›ìê°„ 3.5Ã… ì´ë‚´)
                if distance <= 3.5:
                    if ((a_element in ['N', 'O'] and b_element in ['N', 'O']) or
                        ('N' in a_atom and 'O' in b_atom) or
                        ('O' in a_atom and 'N' in b_atom)):
                        h_bonds += 1

                # ì†Œìˆ˜ì„± ìƒí˜¸ì‘ìš© (íƒ„ì†Œ ì›ìê°„ 4.5Ã… ì´ë‚´)
                if distance <= 4.5:
                    if a_element == 'C' and b_element == 'C':
                        hydrophobic += 1

                # ì •ì „ê¸°ì  ìƒí˜¸ì‘ìš© (í•˜ì „ ì›ìê°„ 5.0Ã… ì´ë‚´)
                if distance <= 5.0:
                    charged_atoms_pos = ['LYS', 'ARG', 'HIS']
                    charged_atoms_neg = ['ASP', 'GLU']

                    a_residue = a_atom[:3] if len(a_atom) >= 3 else ''
                    b_residue = b_atom[:3] if len(b_atom) >= 3 else ''

                    if ((a_residue in charged_atoms_pos and b_residue in charged_atoms_neg) or
                        (a_residue in charged_atoms_neg and b_residue in charged_atoms_pos)):
                        electrostatic += 1

        total_interactions = h_bonds + hydrophobic + electrostatic
        return {
            'h_bonds': h_bonds,
            'hydrophobic': hydrophobic,
            'electrostatic': electrostatic,
            'total': total_interactions
        }

    except Exception as e:
        print(f"       ìƒí˜¸ì‘ìš© ê³„ì‚° ì˜¤ë¥˜: {e}")
        return {'h_bonds': 0, 'hydrophobic': 0, 'electrostatic': 0, 'total': 0}

def split_pdb_and_get_center(pdb_file, base_name):
    """PDB íŒŒì¼ì„ Receptor(Chain A)ì™€ Ligand(Chain B)ë¡œ ë¶„ë¦¬í•˜ê³ , Ligandì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    receptor_path = f"{base_name}_receptor.pdb"
    ligand_path = f"{base_name}_ligand.pdb"

    chain_b_coords = []
    with open(pdb_file, 'r') as f_in, open(receptor_path, 'w') as f_receptor, open(ligand_path, 'w') as f_ligand:
        for line in f_in:
            if line.startswith(('ATOM', 'HETATM')):
                chain_id = line[21]
                if chain_id == 'A':
                    f_receptor.write(line)
                elif chain_id == 'B':
                    f_ligand.write(line)
                    x = float(line[30:38])
                    y = float(line[38:46])
                    z = float(line[46:54])
                    chain_b_coords.append([x, y, z])

    center = [0.0, 0.0, 0.0]
    if chain_b_coords:
        center = np.mean(chain_b_coords, axis=0).tolist()

    return receptor_path, ligand_path, center

def run_vina_docking(receptor_pdb, ligand_pdb, center, vina_executable):
    """AutoDock Vinaë¥¼ ì‚¬ìš©í•˜ì—¬ ë„í‚¹ì„ ìˆ˜í–‰í•˜ê³  ê²°í•© ì—ë„ˆì§€ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        receptor_pdbqt = receptor_pdb.replace('.pdb', '.pdbqt')
        ligand_pdbqt = ligand_pdb.replace('.pdb', '.pdbqt')

        os.system(f"mk_prepare_receptor -i {receptor_pdb} -o {receptor_pdbqt} > /dev/null 2>&1")
        os.system(f"mk_prepare_ligand -i {ligand_pdb} -o {ligand_pdbqt} --rigid > /dev/null 2>&1")

        if not os.path.exists(receptor_pdbqt) or not os.path.exists(ligand_pdbqt):
            print("       PDBQT íŒŒì¼ ìƒì„± ì‹¤íŒ¨. OpenBabelë¡œ ëŒ€ì²´ ì‹œë„.")
            os.system(f"obabel {receptor_pdb} -O {receptor_pdbqt} -xr > /dev/null 2>&1")
            os.system(f"obabel {ligand_pdb} -O {ligand_pdbqt} > /dev/null 2>&1")
            if not os.path.exists(receptor_pdbqt) or not os.path.exists(ligand_pdbqt):
                 print("       ëŒ€ì²´ ë°©ë²•ë„ ì‹¤íŒ¨. Vina ë„í‚¹ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                 return 0.0

        output_pdbqt = ligand_pdb.replace('.pdb', '_vina_out.pdbqt')
        log_file = ligand_pdb.replace('.pdb', '_vina.log')

        cmd = [
            vina_executable,
            '--receptor', receptor_pdbqt,
            '--ligand', ligand_pdbqt,
            '--center_x', str(center[0]),
            '--center_y', str(center[1]),
            '--center_z', str(center[2]),
            '--size_x', '30',
            '--size_y', '30',
            '--size_z', '30',
            '--exhaustiveness', '16',
            '--out', output_pdbqt,
            '--log', log_file
        ]

        subprocess.run(cmd, check=True, capture_output=True, text=True)

        with open(log_file, 'r') as f:
            for line in f:
                if line.strip().startswith('1'):
                    parts = line.split()
                    return float(parts[1])
        return 0.0
    except Exception as e:
        print(f"       Vina ë„í‚¹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 0.0

# ============= ë©”ì¸ í‰ê°€ ë£¨í”„ =============

results = []

if not predicted_pdb_files:
    print("í‰ê°€í•  PDB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    print(f"ì´ {len(predicted_pdb_files)}ê°œì˜ êµ¬ì¡°ì— ëŒ€í•´ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    for idx, pred_pdb in enumerate(predicted_pdb_files):
        print(f"\n  í‰ê°€ ì¤‘ ({idx+1}/{len(predicted_pdb_files)}): {os.path.basename(pred_pdb)}")

        base_name = os.path.join(JOB_NAME, f"eval_{idx}")

        if not os.path.exists(pred_pdb) or os.path.getsize(pred_pdb) == 0:
            print("    -> PDB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            continue

        # í©íƒ€ì´ë“œ ì„œì—´ í™•ì¸
        try:
            peptide_index = int(re.search(r'complex_(\d+)', os.path.basename(pred_pdb)).group(1))
            peptide_seq = peptides[peptide_index]
        except (AttributeError, IndexError, ValueError):
            peptide_seq = f"Unknown_{idx}"

        # PPI-Affinity ì˜ˆì¸¡
        print("    -> PPI-Affinity ê²°í•© ì¹œí™”ë„ ì˜ˆì¸¡ ì¤‘...")
        ppi_affinity_score = predict_ppi_affinity_web(TARGET_PROTEIN_SEQUENCE, peptide_seq)
        print(f"       PPI-Affinity ì ìˆ˜: {ppi_affinity_score:.3f}")

        # PDB íŒŒì¼ ë¶„ë¦¬
        receptor_pdb, ligand_pdb, center = split_pdb_and_get_center(pred_pdb, base_name)
        print(f"    -> PDB ë¶„ë¦¬ ì™„ë£Œ: Receptor={os.path.basename(receptor_pdb)}, Ligand={os.path.basename(ligand_pdb)}")

        # Vina ë„í‚¹ ì ìˆ˜ ê³„ì‚°
        vina_score = 0.0
        if VINA_EXECUTABLE and os.path.exists(VINA_EXECUTABLE) and center:
            print("    -> Vina ë„í‚¹ ì‹¤í–‰ ì¤‘...")
            vina_score = run_vina_docking(receptor_pdb, ligand_pdb, center, VINA_EXECUTABLE)
            print(f"       Vina ì ìˆ˜: {vina_score:.3f} kcal/mol")
        else:
            print("    -> Vinaë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê°„ë‹¨í•œ ì¶”ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
            try:
                with open(receptor_pdb, 'r') as f:
                    receptor_lines = [line for line in f if line.startswith(('ATOM', 'HETATM'))]
                with open(ligand_pdb, 'r') as f:
                    ligand_lines = [line for line in f if line.startswith(('ATOM', 'HETATM'))]

                if receptor_lines and ligand_lines:
                    min_dist = float('inf')
                    for r_line in receptor_lines[::10]:
                        rx = float(r_line[30:38])
                        ry = float(r_line[38:46])
                        rz = float(r_line[46:54])
                        for l_line in ligand_lines:
                            lx = float(l_line[30:38])
                            ly = float(l_line[38:46])
                            lz = float(l_line[46:54])
                            dist = np.sqrt((rx-lx)**2 + (ry-ly)**2 + (rz-lz)**2)
                            min_dist = min(min_dist, dist)

                    if min_dist < float('inf'):
                        vina_score = max(-1.0 * (15.0 / max(min_dist, 0.1)), -15.0)

            except Exception as e:
                print(f"       ê°„ë‹¨í•œ ì¶”ì • ì‹¤íŒ¨: {e}")
                vina_score = -5.0

        # ìƒí˜¸ì‘ìš© ë¶„ì„
        print("    -> ë¶„ìê°„ ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...")
        interactions = calculate_interactions_advanced(pred_pdb)
        print(f"       ìƒí˜¸ì‘ìš©: H-bonds={interactions['h_bonds']}, "
              f"Hydrophobic={interactions['hydrophobic']}, "
              f"Electrostatic={interactions['electrostatic']}")

        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        print("    -> ìµœì¢… ì ìˆ˜ ê³„ì‚° ì¤‘...")

        final_score = (
            abs(vina_score) * 0.25 +
            ppi_affinity_score * 0.5 +
            interactions['total'] * 0.15 +
            ptm_scores_map.get(peptide_seq, 0.0) * 10 * 0.1
        )

        # ê²°ê³¼ ì €ì¥
        results.append({
            "Peptide Sequence": peptide_seq,
            "pTM Score": ptm_scores_map.get(peptide_seq, 0.0),
            "Vina Score (kcal/mol)": round(vina_score, 3),
            "PPI-Affinity Score": round(ppi_affinity_score, 3),
            "H-bonds": interactions['h_bonds'],
            "Hydrophobic": interactions['hydrophobic'],
            "Electrostatic": interactions['electrostatic'],
            "Total Interactions": interactions['total'],
            "Final Score": round(final_score, 3),
            "Source PDB": os.path.basename(pred_pdb)
        })

        print(f"    -> í‰ê°€ ì™„ë£Œ: Final Score = {final_score:.3f}")

print("="*80)
print("âœ… STEP 4: ëª¨ë“  êµ¬ì¡°ì— ëŒ€í•œ í‰ê°€ ë° ì ìˆ˜ ê³„ì‚°ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
print("="*80)

# ==============================================================================
# STEP 5: ìµœì¢… ê²°ê³¼ í™•ì¸ ë° ì €ì¥
# ==============================================================================

print("\n" + "="*80)
print("STEP 5: ìµœì¢… ê²°ê³¼ í™•ì¸ ë° ì €ì¥")
print("="*80)

if results:
    import pandas as pd
    from IPython.display import display

    df = pd.DataFrame(results)

    column_order = [
        "Peptide Sequence", "Final Score", "pTM Score",
        "PPI-Affinity Score",
        "Vina Score (kcal/mol)",
        "H-bonds", "Hydrophobic", "Electrostatic", "Total Interactions",
        "Source PDB"
    ]

    df_sorted = df.sort_values("Final Score", ascending=False).reset_index(drop=True)
    df_final = df_sorted[[col for col in column_order if col in df_sorted.columns]]

    # Excel íŒŒì¼ë¡œ ì €ì¥
    df_final.to_excel(OUTPUT_FINAL_XLSX_PATH, index=False)

    print("\nğŸ† ìµœì¢… í©íƒ€ì´ë“œ í›„ë³´ ë­í‚¹:")
    display(df_final)

    print(f"\nğŸ’¾ ì „ì²´ ê²°ê³¼ê°€ Excel íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {OUTPUT_FINAL_XLSX_PATH}")
    print("   (Colab ì™¼ìª½ì˜ íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")

    print("\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
    print(f"   â€¢ ì´ í‰ê°€ëœ í©íƒ€ì´ë“œ: {len(results)}ê°œ")
    print(f"   â€¢ ìµœê³  ì ìˆ˜ í©íƒ€ì´ë“œ: {df_final.iloc[0]['Peptide Sequence']} (ì ìˆ˜: {df_final.iloc[0]['Final Score']:.3f})")
    print(f"   â€¢ í‰ê·  pTM ì ìˆ˜: {df_final['pTM Score'].mean():.3f}")
    print(f"   â€¢ í‰ê·  PPI-Affinity ì ìˆ˜: {df_final['PPI-Affinity Score'].mean():.3f}")
    print(f"   â€¢ í‰ê·  ìƒí˜¸ì‘ìš© ìˆ˜: {df_final['Total Interactions'].mean():.1f}")

else:
    print("\nâŒ ìµœì¢… ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ì¤‘ê°„ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

print("="*80)
print("ğŸ‰ ëª¨ë“  íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print("="*80)

print("\nğŸ“‹ ì„¤ì¹˜ëœ ë„êµ¬ ìƒíƒœ:")
print(f"   â€¢ ColabFold: âœ… ì„¤ì¹˜ë¨")
print(f"   â€¢ ESM-2 (Transformers): âœ… ì„¤ì¹˜ë¨")
print(f"   â€¢ PPI-Affinity: âœ… ì›¹ API í†µí•©")
print(f"   â€¢ OpenBabel: âœ… ì„¤ì¹˜ë¨")
print(f"   â€¢ AutoDock Vina: {'âœ… ì„¤ì¹˜ë¨' if VINA_EXECUTABLE else 'âš ï¸ ê°„ë‹¨í•œ ì¶”ì • ì‚¬ìš©'}")
print(f"   â€¢ PLIP ëŒ€ì²´ í•¨ìˆ˜: âœ… êµ¬í˜„ë¨")
print("="*80)

# ì´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚° ë° ì¶œë ¥
pipeline_end_time = time.time()
total_duration_seconds = pipeline_end_time - pipeline_start_time

# ì‹œê°„, ë¶„, ì´ˆ ë‹¨ìœ„ë¡œ ê³„ì‚°
total_hours = int(total_duration_seconds // 3600)
remaining_seconds = total_duration_seconds % 3600
total_minutes = int(remaining_seconds // 60)
total_seconds = int(remaining_seconds % 60)

# ì‹¤í–‰ ì‹œê°„ í‘œì‹œ (1ì‹œê°„ ì´ìƒì¸ ê²½ìš° ì‹œê°„ í¬í•¨)
if total_hours > 0:
    print(f"\nâ±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {total_hours}ì‹œê°„ {total_minutes}ë¶„ {total_seconds}ì´ˆ")
else:
    print(f"\nâ±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {total_minutes}ë¶„ {total_seconds}ì´ˆ")
print("="*80)


