{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e561408",
   "metadata": {},
   "source": [
    "# ğŸ§¬ ë‹¤ì¤‘ í©íƒ€ì´ë“œ í›„ë³´ ê¸°ë°˜ ë‹¨ë°±ì§ˆ ê²°í•©ë ¥ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸\n",
    "ProtGPT2ë¡œ ì—¬ëŸ¬ í©íƒ€ì´ë“œ í›„ë³´ë¥¼ ìƒì„±í•˜ê³ , ê° í›„ë³´ì— ëŒ€í•´ êµ¬ì¡° ì˜ˆì¸¡, ë„í‚¹, ìƒí˜¸ì‘ìš© ë¶„ì„ ë° ê²°í•©ë ¥ ì˜ˆì¸¡(Pafnucy)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f57549",
   "metadata": {},
   "source": [
    "## 0. Google Drive ë§ˆìš´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cde7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "work_dir = \"/content/drive/MyDrive/peptide_docking_pipeline_multi\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "print(f\"Working directory: {work_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10f3b1",
   "metadata": {},
   "source": [
    "## 1. ProtGPT2ë¡œ í©íƒ€ì´ë“œ í›„ë³´ ë‹¤ì¤‘ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentencepiece\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nferruz/ProtGPT2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"nferruz/ProtGPT2\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "N = 5  # ìƒì„±í•  í›„ë³´ ìˆ˜\n",
    "peptides = []\n",
    "\n",
    "for _ in range(N):\n",
    "    input_ids = tokenizer(\"generate:\", return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    output = model.generate(input_ids, max_length=30, num_return_sequences=1, do_sample=True, top_k=950, top_p=0.96)\n",
    "    sequence = tokenizer.decode(output[0], skip_special_tokens=True).replace(\"generate:\", \"\").strip()\n",
    "    peptides.append(sequence)\n",
    "\n",
    "# íŒŒì¼ ì €ì¥\n",
    "for i, pep in enumerate(peptides):\n",
    "    with open(f\"peptide_{i}.fasta\", \"w\") as f:\n",
    "        f.write(f\">pep{i}\\n{pep}\\n\")\n",
    "\n",
    "print(\"âœ… ìƒì„±ëœ í©íƒ€ì´ë“œ í›„ë³´:\")\n",
    "for i, seq in enumerate(peptides):\n",
    "    print(f\"[{i}] {seq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55efae9e",
   "metadata": {},
   "source": [
    "## 2. ë‹¨ë°±ì§ˆ ì„œì—´ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7260da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ìê°€ ë‹¨ë°±ì§ˆ ì„œì—´ì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "protein_sequence = \"MSEQNNTEMTFQIQRIYTKDISFEAPNAPHVFQKDWLD...\"\n",
    "with open(\"protein.fasta\", \"w\") as f:\n",
    "    f.write(\">protein\\n\" + protein_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e239d62",
   "metadata": {},
   "source": [
    "## 3. êµ¬ì¡° ì˜ˆì¸¡ (ColabFold/AlphaFold-Multimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184805f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q colabfold batchfold\n",
    "!colabfold_download\n",
    "\n",
    "merged_files = []\n",
    "for i in range(N):\n",
    "    fname = f\"complex_{i}.fasta\"\n",
    "    with open(fname, \"w\") as out, open(\"protein.fasta\") as pro, open(f\"peptide_{i}.fasta\") as pep:\n",
    "        out.writelines(pro.readlines())\n",
    "        out.writelines(pep.readlines())\n",
    "    merged_files.append(fname)\n",
    "\n",
    "for f in merged_files:\n",
    "    !colabfold_batch {f} prediction_{f.split(\".\")[0]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b7230",
   "metadata": {},
   "source": [
    "## 4. êµ¬ì¡° ì˜ˆì¸¡ ê²°ê³¼ ì¤€ë¹„ ë° í‰ê°€ìš© ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for i in range(N):\n",
    "    pred_path = f\"prediction_complex_{i}/complex_{i}_0.pdb\"\n",
    "    if os.path.exists(pred_path):\n",
    "        print(f\"[{i}] êµ¬ì¡° ì˜ˆì¸¡ ì™„ë£Œ: {pred_path}\")\n",
    "    else:\n",
    "        print(f\"[{i}] âŒ ì˜ˆì¸¡ ì‹¤íŒ¨ ë˜ëŠ” ëˆ„ë½\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c256212",
   "metadata": {},
   "source": [
    "## 5. ë„í‚¹, PLIP, Pafnucyë¥¼ í†µí•œ ê²°í•©ë ¥ í‰ê°€ ë° ì ìˆ˜ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y openbabel\n",
    "!pip install -q plip\n",
    "!git clone https://github.com/oddt/pafnucy.git\n",
    "%cd pafnucy\n",
    "!pip install -q -r requirements.txt\n",
    "%cd ..\n",
    "\n",
    "from plip.structure.preparation import PDBComplex\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(N):\n",
    "    pred_pdb = f\"prediction_complex_{i}/complex_{i}_0.pdb\"\n",
    "    if not os.path.exists(pred_pdb):\n",
    "        continue\n",
    "\n",
    "    os.system(f\"obabel {pred_pdb} -O receptor_{i}.pdbqt\")\n",
    "    os.system(f\"cp receptor_{i}.pdbqt ligand_{i}.pdbqt\")\n",
    "\n",
    "    # AutoDock Vina ë‹¤ìš´ë¡œë“œ ë° ì‹¤í–‰\n",
    "    if not os.path.exists(\"vina_1.2.3_linux_x86_64/vina\"):\n",
    "        !wget -q https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.3/vina_1.2.3_linux_x86_64.zip\n",
    "        !unzip -q vina_1.2.3_linux_x86_64.zip\n",
    "        !chmod +x vina_1.2.3_linux_x86_64/vina\n",
    "\n",
    "    vina_cmd = f\"./vina_1.2.3_linux_x86_64/vina --receptor receptor_{i}.pdbqt --ligand ligand_{i}.pdbqt --center_x 0 --center_y 0 --center_z 0 --size_x 20 --size_y 20 --size_z 20 --out output_{i}.pdbqt --log log_{i}.txt\"\n",
    "    os.system(vina_cmd)\n",
    "\n",
    "    vina_score = None\n",
    "    with open(f\"log_{i}.txt\") as f:\n",
    "        for line in f:\n",
    "            if \"REMARK VINA RESULT\" in line:\n",
    "                vina_score = float(line.strip().split()[3])\n",
    "                break\n",
    "\n",
    "    # PLIP ìƒí˜¸ì‘ìš© ë¶„ì„\n",
    "    structure = PDBComplex()\n",
    "    structure.load_pdb(f\"output_{i}.pdbqt\")\n",
    "    structure.analyze()\n",
    "    interaction_count = 0\n",
    "    for ligand in structure.ligands:\n",
    "        inter = structure.interaction_sets[ligand]\n",
    "        interaction_count += len(inter.hbonds) + len(inter.hydrophobic_contacts) + len(inter.saltbridge_ligands)\n",
    "\n",
    "    # Pafnucy í‰ê°€\n",
    "    os.system(f\"obabel output_{i}.pdbqt -O complex_final_{i}.pdb\")\n",
    "    os.system(f\"python pafnucy/predict.py --pdb complex_final_{i}.pdb --out affinity_{i}.csv\")\n",
    "    pafnucy_df = pd.read_csv(f\"affinity_{i}.csv\")\n",
    "    pafnucy_affinity = float(pafnucy_df['predicted_affinity'].iloc[0])\n",
    "\n",
    "    final_score = (-1 * vina_score) + (-1 * pafnucy_affinity) + (0.5 * interaction_count)\n",
    "    results.append({\n",
    "        \"index\": i,\n",
    "        \"peptide\": peptides[i],\n",
    "        \"vina_score\": vina_score,\n",
    "        \"pafnucy\": pafnucy_affinity,\n",
    "        \"interaction\": interaction_count,\n",
    "        \"final_score\": final_score\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df_sorted = df.sort_values(\"final_score\", ascending=False)\n",
    "df_sorted.to_csv(\"peptide_binding_rank.csv\", index=False)\n",
    "df_sorted\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
